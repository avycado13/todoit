{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 4, "column": 0}, "map": {"version":3,"sources":["file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/replicache/src/format-version-enum.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/shared/src/valita.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/replicache/src/dag/store.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/replicache/src/with-transactions.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/replicache/src/dag/chunk.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/shared/src/random-uint64.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/replicache/src/hash.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/replicache/src/index-defs.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/replicache/src/persist/client-groups.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/shared/src/json.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/replicache/src/size-of-value.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/replicache/src/btree/node.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/shared/src/binary-search.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/shared/src/iterables.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/replicache/src/btree/splice.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/replicache/src/btree/read.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/shared/src/string-compare.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/replicache/src/cookies.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/replicache/src/db/meta-type-enum.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/replicache/src/db/commit.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/replicache/src/db/index-operation-enum.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/replicache/src/db/index.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/replicache/src/db/read.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/replicache/src/async-iterable-to-array.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/replicache/src/btree/diff.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/replicache/src/btree/write.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/replicache/src/lazy.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/replicache/src/sync/diff.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/replicache/src/db/write.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/replicache/src/sync/ids.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/replicache/src/persist/make-client-id.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/replicache/src/persist/clients.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/shared/src/objects.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/shared/src/must.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/zql/src/ivm/data.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/zql/src/ivm/view-apply-change.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/zql/src/query/ttl.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/shared/src/json-schema.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/shared/src/tdigest-schema.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/zero-protocol/src/ast.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/shared/src/arrays.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/zero-protocol/src/data.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/zero-protocol/src/inspect-down.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/shared/src/random-values.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/zero-client/src/util/nanoid.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/shared/src/hash.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/zero-protocol/src/primary-key.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/zero-client/src/client/keys.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/shared/src/centroid.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/shared/src/tdigest.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/zero-schema/src/table-schema.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/zql/src/query/query.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/zql/src/query/query-impl.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/zero-protocol/src/query-hash.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/zql/src/ivm/filter-operators.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/zql/src/ivm/operator.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/zql/src/ivm/stream.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/zql/src/ivm/exists.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/zql/src/ivm/fan-in.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/zql/src/ivm/fan-out.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/zql/src/ivm/maybe-split-and-push-edit-change.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/zql/src/ivm/filter-push.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/zql/src/ivm/filter.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/zql/src/ivm/join.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/zql/src/ivm/skip.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/zql/src/ivm/take.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/zql/src/query/expression.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/zql/src/builder/like.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/zql/src/builder/filter.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/zql/src/builder/builder.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/zql/src/error.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/zql/src/ivm/array-view.ts","file:///Users/avy/Code/todoit/node_modules/.pnpm/%40rocicorp%2Bzero%400.23.2025090100_%40opentelemetry%2Bcore%402.1.0_%40opentelemetry%2Bapi%401.9.0__typescript%405.9.3/node_modules/%40rocicorp/zql/src/query/assert-no-not-exists.ts"],"sourcesContent":["/* eslint-disable @typescript-eslint/naming-convention */\n\nexport const SDD = 4;\nexport const DD31 = 5;\n// V6 added refreshHashes and persistHash to Client to fix ChunkNotFound errors\nexport const V6 = 6;\n// V7 added sizeOfEntry to the BTree chunk data.\nexport const V7 = 7;\nexport const Latest = V7;\n\nexport type SDD = typeof SDD;\nexport type DD31 = typeof DD31;\nexport type V6 = typeof V6;\nexport type V7 = typeof V7;\nexport type Latest = typeof Latest;\n","import * as v from '@badrap/valita';\n\nexport * from '@badrap/valita';\n\nfunction toDisplay(value: unknown): string {\n  switch (typeof value) {\n    case 'string':\n    case 'number':\n    case 'boolean':\n      return JSON.stringify(value);\n    case 'undefined':\n      return 'undefined';\n    case 'bigint':\n      return value.toString() + 'n';\n    default:\n      if (value === null) {\n        return 'null';\n      }\n      if (Array.isArray(value)) {\n        return 'array';\n      }\n      return typeof value;\n  }\n}\n\ntype Key = string | number;\n\nfunction toDisplayAtPath(v: unknown, path: Key[] | undefined): string {\n  if (!path?.length) {\n    return toDisplay(v);\n  }\n\n  let cur = v;\n  for (const p of path) {\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    cur = (cur as any)[p];\n  }\n  return toDisplay(cur);\n}\n\nfunction displayList<T>(\n  word: string,\n  expected: T[],\n  toDisplay: (x: T) => string | number = x => String(x),\n): string | number {\n  if (expected.length === 1) {\n    return toDisplay(expected[0]);\n  }\n\n  const suffix = `${toDisplay(\n    expected[expected.length - 2],\n  )} ${word} ${toDisplay(expected[expected.length - 1])}`;\n  if (expected.length === 2) {\n    return suffix;\n  }\n  return `${expected.slice(0, -2).map(toDisplay).join(', ')}, ${suffix}`;\n}\n\nfunction getMessage(\n  err: v.Err | v.ValitaError,\n  v: unknown,\n  schema: v.Type | v.Optional,\n  mode: ParseOptionsMode | undefined,\n): string {\n  const firstIssue = err.issues[0];\n  const {path} = firstIssue;\n  const atPath = path?.length ? ` at ${path.join('.')}` : '';\n\n  switch (firstIssue.code) {\n    case 'invalid_type':\n      return `Expected ${displayList(\n        'or',\n        firstIssue.expected,\n      )}${atPath}. Got ${toDisplayAtPath(v, path)}`;\n    case 'missing_value': {\n      const atPath =\n        path && path.length > 1 ? ` at ${path.slice(0, -1).join('.')}` : '';\n\n      if (firstIssue.path?.length) {\n        return `Missing property ${firstIssue.path.at(-1)}${atPath}`;\n      }\n      return `TODO Unknown missing property${atPath}`;\n    }\n\n    case 'invalid_literal':\n      return `Expected literal value ${displayList(\n        'or',\n        firstIssue.expected,\n        toDisplay,\n      )}${atPath} Got ${toDisplayAtPath(v, path)}`;\n\n    case 'invalid_length': {\n      return `Expected array with length ${\n        firstIssue.minLength === firstIssue.maxLength\n          ? firstIssue.minLength\n          : `between ${firstIssue.minLength} and ${firstIssue.maxLength}`\n      }${atPath}. Got array with length ${(v as {length: number}).length}`;\n    }\n\n    case 'unrecognized_keys':\n      if (firstIssue.keys.length === 1) {\n        return `Unexpected property ${firstIssue.keys[0]}${atPath}`;\n      }\n      return `Unexpected properties ${displayList(\n        'and',\n        firstIssue.keys,\n      )}${atPath}`;\n\n    case 'invalid_union':\n      return schema.name === 'union'\n        ? getDeepestUnionParseError(v, schema as v.UnionType, mode ?? 'strict')\n        : `Invalid union value${atPath}`;\n\n    case 'custom_error': {\n      const {error} = firstIssue;\n      const message = !error\n        ? 'unknown'\n        : typeof error === 'string'\n          ? error\n          : (error.message ?? 'unknown');\n      return `${message}${atPath}. Got ${toDisplayAtPath(v, path)}`;\n    }\n  }\n}\n\ntype FailedType = {type: v.Type; err: v.Err};\n\nfunction getDeepestUnionParseError(\n  value: unknown,\n  schema: v.UnionType,\n  mode: ParseOptionsMode,\n): string {\n  const failures: FailedType[] = [];\n  for (const type of schema.options) {\n    const r = type.try(value, {mode});\n    if (!r.ok) {\n      failures.push({type, err: r});\n    }\n  }\n  if (failures.length) {\n    // compare the first and second longest-path errors\n    failures.sort(pathCmp);\n    if (failures.length === 1 || pathCmp(failures[0], failures[1]) < 0) {\n      return getMessage(failures[0].err, value, failures[0].type, mode);\n    }\n  }\n  // paths are equivalent\n  try {\n    const str = JSON.stringify(value);\n    return `Invalid union value: ${str}`;\n  } catch (e) {\n    // fallback if the value could not be stringified\n    return `Invalid union value`;\n  }\n}\n\n// Descending-order comparison of Issue paths.\n// * [1, 'a'] sorts before [1]\n// * [1] sorts before [0]  (i.e. errors later in the tuple sort before earlier errors)\nfunction pathCmp(a: FailedType, b: FailedType) {\n  const aPath = a.err.issues[0].path;\n  const bPath = b.err.issues[0].path;\n  if (aPath.length !== bPath.length) {\n    return bPath.length - aPath.length;\n  }\n  for (let i = 0; i < aPath.length; i++) {\n    if (bPath[i] > aPath[i]) {\n      return -1;\n    }\n    if (bPath[i] < aPath[i]) {\n      return 1;\n    }\n  }\n  return 0;\n}\n\n/**\n * 'strip' allows unknown properties and removes unknown properties.\n * 'strict' errors if there are unknown properties.\n * 'passthrough' allows unknown properties.\n */\nexport type ParseOptionsMode = 'passthrough' | 'strict' | 'strip';\n\nexport function parse<T>(\n  value: unknown,\n  schema: v.Type<T>,\n  mode?: ParseOptionsMode,\n): T {\n  const res = test(value, schema, mode);\n  if (!res.ok) {\n    throw new TypeError(res.error);\n  }\n  return res.value;\n}\n\nexport function is<T>(\n  value: unknown,\n  schema: v.Type<T>,\n  mode?: ParseOptionsMode,\n): value is T {\n  return test(value, schema, mode).ok;\n}\n\nexport function assert<T>(\n  value: unknown,\n  schema: v.Type<T>,\n  mode?: ParseOptionsMode,\n): asserts value is T {\n  parse(value, schema, mode);\n}\n\ntype Result<T> = {ok: true; value: T} | {ok: false; error: string};\n\nexport function test<T>(\n  value: unknown,\n  schema: v.Type<T>,\n  mode?: ParseOptionsMode,\n): Result<T> {\n  const res = schema.try(value, mode ? {mode} : undefined);\n  if (!res.ok) {\n    return {\n      ok: false,\n      error: getMessage(res, value, schema, mode),\n    };\n  }\n  return res;\n}\n\n/**\n * Similar to {@link test} but works for AbstractTypes such as Optional.\n * This is for advanced usage. Prefer {@link test} unless you really need\n * to operate directly on an Optional field.\n */\nexport function testOptional<T>(\n  value: unknown,\n  schema: v.Type<T> | v.Optional<T>,\n  mode?: ParseOptionsMode,\n): Result<T | undefined> {\n  let flags = 0x1; // FLAG_FORBID_EXTRA_KEYS;\n  if (mode === 'passthrough') {\n    flags = 0;\n  } else if (mode === 'strip') {\n    flags = 0x2; // FLAG_STRIP_EXTRA_KEYS;\n  }\n  const res = schema.func(value, flags);\n  if (res === undefined) {\n    return {ok: true, value} as Result<T>;\n  } else if (res.ok) {\n    return res;\n  }\n  const err = new v.ValitaError(res);\n  return {ok: false, error: getMessage(err, value, schema, mode)};\n}\n\n/**\n * Shallowly marks the schema as readonly.\n */\nexport function readonly<T extends v.Type>(t: T): v.Type<Readonly<v.Infer<T>>> {\n  return t as v.Type<Readonly<v.Infer<T>>>;\n}\n\nexport function readonlyObject<T extends Record<string, v.Type | v.Optional>>(\n  t: T,\n): v.ObjectType<Readonly<T>, undefined> {\n  return v.object(t);\n}\n\nexport function readonlyArray<T extends v.Type>(\n  t: T,\n): v.Type<readonly v.Infer<T>[]> {\n  return v.array(t);\n}\n\nexport function readonlyRecord<T extends v.Type>(\n  t: T,\n): v.Type<Readonly<Record<string, v.Infer<T>>>> {\n  return v.record(t);\n}\n\n// eslint-disable-next-line @typescript-eslint/naming-convention\nconst AbstractType = Object.getPrototypeOf(\n  Object.getPrototypeOf(v.string().optional()),\n).constructor;\n\nexport function instanceOfAbstractType<T = unknown>(\n  obj: unknown,\n): obj is v.Type<T> | v.Optional<T> {\n  return obj instanceof AbstractType;\n}\n\ntype ObjectShape = Record<string, typeof AbstractType>;\n\n/**\n * Similar to `ObjectType.partial()` except it recurses into nested objects.\n * Rest types are not supported.\n */\nexport function deepPartial<Shape extends ObjectShape>(\n  s: v.ObjectType<Shape, undefined>,\n) {\n  const shape = {} as Record<string, unknown>;\n  for (const [key, type] of Object.entries(s.shape)) {\n    if (type.name === 'object') {\n      shape[key] = deepPartial(type as v.ObjectType).optional();\n    } else {\n      shape[key] = type.optional();\n    }\n  }\n  return v.object(shape as {[K in keyof Shape]: v.Optional<v.Infer<Shape[K]>>});\n}\n\ntype Literal = string | number | bigint | boolean;\n\nexport function literalUnion<T extends [...Literal[]]>(\n  ...literals: T\n): v.Type<T[number]> {\n  return v.union(...literals.map(v.literal));\n}\n","import {assert} from '../../../shared/src/asserts.ts';\nimport type {Hash} from '../hash.ts';\nimport type {Release} from '../with-transactions.ts';\nimport type {Chunk, Refs} from './chunk.ts';\n\nexport interface Store {\n  read(): Promise<Read>;\n  write(): Promise<Write>;\n  close(): Promise<void>;\n}\n\ninterface GetChunk {\n  getChunk(hash: Hash): Promise<Chunk | undefined>;\n}\n\nexport interface MustGetChunk {\n  mustGetChunk(hash: Hash): Promise<Chunk>;\n}\n\nexport interface Read extends GetChunk, MustGetChunk, Release {\n  hasChunk(hash: Hash): Promise<boolean>;\n  getHead(name: string): Promise<Hash | undefined>;\n  get closed(): boolean;\n}\n\nexport interface Write extends Read {\n  createChunk<V>(data: V, refs: Refs): Chunk<V>;\n  putChunk<V>(c: Chunk<V>): Promise<void>;\n  setHead(name: string, hash: Hash): Promise<void>;\n  removeHead(name: string): Promise<void>;\n  assertValidHash(hash: Hash): void;\n  commit(): Promise<void>;\n}\n\nexport class ChunkNotFoundError extends Error {\n  name = 'ChunkNotFoundError';\n  readonly hash: Hash;\n  constructor(hash: Hash) {\n    super(`Chunk not found ${hash}`);\n    this.hash = hash;\n  }\n}\n\nexport async function mustGetChunk(\n  store: GetChunk,\n  hash: Hash,\n): Promise<Chunk> {\n  const chunk = await store.getChunk(hash);\n  if (chunk) {\n    return chunk;\n  }\n  throw new ChunkNotFoundError(hash);\n}\n\nexport async function mustGetHeadHash(\n  name: string,\n  store: Read,\n): Promise<Hash> {\n  const hash = await store.getHead(name);\n  assert(hash, `Missing head ${name}`);\n  return hash;\n}\n","export interface Release {\n  release(): void;\n}\n\nexport interface Commit {\n  commit(): Promise<void>;\n}\n\ninterface ReadStore<Read extends Release> {\n  read(): Promise<Read>;\n}\n\ninterface WriteStore<Write extends Release> {\n  write(): Promise<Write>;\n}\n\nexport function withRead<Read extends Release, Return>(\n  store: ReadStore<Read>,\n  fn: (read: Read) => Return | Promise<Return>,\n): Promise<Return> {\n  return using(store.read(), fn);\n}\n\nexport function withWriteNoImplicitCommit<Write extends Release, Return>(\n  store: WriteStore<Write>,\n  fn: (write: Write) => Return | Promise<Return>,\n): Promise<Return> {\n  return using(store.write(), fn);\n}\n\nexport function withWrite<Write extends Release & Commit, Return>(\n  store: WriteStore<Write>,\n  fn: (write: Write) => Return | Promise<Return>,\n): Promise<Return> {\n  return using(store.write(), async write => {\n    const result = await fn(write);\n    await write.commit();\n    return result;\n  });\n}\n\n/**\n * This function takes a promise for a resource and a function that uses that\n * resource. It will release the resource after the function returns by calling\n * the `release` function\n */\nexport async function using<TX extends Release, Return>(\n  x: Promise<TX>,\n  fn: (tx: TX) => Return | Promise<Return>,\n): Promise<Return> {\n  const write = await x;\n  try {\n    return await fn(write);\n  } finally {\n    write.release();\n  }\n}\n","import {assert, assertString} from '../../../shared/src/asserts.ts';\nimport {assertDeepFrozen} from '../frozen-json.ts';\nimport type {Hash} from '../hash.ts';\n\n// By using declare we tell the type system that there is a unique symbol.\n// However, there is no such symbol but the type system does not care.\ndeclare const refsTag: unique symbol;\n\n/**\n * Opaque type representing a Refs. The reason to use an opaque type here is to\n * make sure that Refs are always sorted and have no duplicates.\n */\nexport type Refs = [] | readonly [Hash] | (readonly Hash[] & {[refsTag]: true});\n\n/**\n * Convert to a Refs when we already know it is sorted and has no duplicates.\n */\nexport function asRefs(sortedRefs: Hash[]): Refs {\n  return sortedRefs as unknown as Refs;\n}\n\n/**\n * Sorts and tags as Refs. If an Array is passed in the array is sorted in\n * place, otherwise a copy of the iterable is created. This checks for duplicates.\n */\nexport function toRefs(refs: Hash[] | Set<Hash>): Refs {\n  if (Array.isArray(refs)) {\n    refs.sort();\n    for (let i = 1; i < refs.length; i++) {\n      assert(refs[i - 1] !== refs[i], 'Refs must not have duplicates');\n    }\n    return asRefs(refs);\n  }\n\n  const refsArray = [...refs];\n  refsArray.sort();\n  // no need to check for duplicates as Set cannot have duplicates.\n  return asRefs(refsArray);\n}\n\nexport class Chunk<V = unknown> {\n  readonly hash: Hash;\n  readonly data: V;\n\n  /**\n   * Meta is an array of refs. If there are no refs we do not write a meta\n   * chunk.\n   */\n  readonly meta: Refs;\n\n  constructor(hash: Hash, data: V, refs: Refs) {\n    assert(\n      !(refs as unknown[]).includes(hash),\n      'Chunk cannot reference itself',\n    );\n    assertDeepFrozen(data);\n    this.hash = hash;\n    this.data = data;\n    this.meta = refs;\n  }\n}\n\nexport function assertRefs(v: unknown): asserts v is Refs {\n  if (!Array.isArray(v)) {\n    throw new Error('Refs must be an array');\n  }\n  if (v.length > 0) {\n    assertString(v[0]);\n    for (let i = 1; i < v.length; i++) {\n      assertString(v[i]);\n    }\n  }\n}\n\nexport function createChunk<V>(\n  data: V,\n  refs: Refs,\n  chunkHasher: ChunkHasher,\n): Chunk<V> {\n  const hash = chunkHasher();\n  return new Chunk(hash, data, refs);\n}\n\nexport type CreateChunk = <V>(data: V, refs: Refs) => Chunk<V>;\n\nexport type ChunkHasher = () => Hash;\n\nexport function throwChunkHasher(): Hash {\n  throw new Error('unexpected call to compute chunk hash');\n}\n","export function randomUint64(): bigint {\n  // Generate two random 32-bit unsigned integers using Math.random()\n  const high = Math.floor(Math.random() * 0xffffffff); // High 32 bits\n  const low = Math.floor(Math.random() * 0xffffffff); // Low 32 bits\n\n  // Combine the high and low parts to form a 64-bit unsigned integer\n  return (BigInt(high) << 32n) | BigInt(low);\n}\n","import {assert} from '../../shared/src/asserts.ts';\nimport {randomUint64} from '../../shared/src/random-uint64.ts';\nimport * as valita from '../../shared/src/valita.ts';\n\nexport const STRING_LENGTH = 22;\n\n// We use an opaque type so that we can make sure that a hash is always a hash.\n// TypeScript does not have direct support but we can use a trick described\n// here:\n//\n// https://evertpot.com/opaque-ts-types/\n//\n// The basic idea is to declare a type that cannot be created. We then use\n// functions that cast a string to this type.\n//\n\n// By using declare we tell the type system that there is a unique symbol.\n// However, there is no such symbol but the type system does not care.\ndeclare const hashTag: unique symbol;\n\n/**\n * Opaque type representing a hash. The only way to create one is using `parse`\n * or `hashOf` (except for static unsafe cast of course).\n */\nexport type Hash = string & {[hashTag]: true};\n\n// We are no longer using hashes but due to legacy reason we still refer to\n// them as hashes. We use UUID and counters instead.\nconst hashRe = /^[0-9a-v-]+$/;\n\nexport function parse(s: string): Hash {\n  assertHash(s);\n  return s;\n}\n\nconst emptyUUID = '0'.repeat(STRING_LENGTH);\nexport const emptyHash = emptyUUID as unknown as Hash;\n\n/**\n * Creates a function that generates random hashes.\n */\nexport const newRandomHash = makeNewRandomHashFunctionInternal();\n\n/**\n * Creates a function that generates UUID hashes for tests.\n */\nexport function makeNewFakeHashFunction(hashPrefix = 'fake'): () => Hash {\n  assert(\n    /^[0-9a-v]{0,8}$/.test(hashPrefix),\n    `Invalid hash prefix: ${hashPrefix}`,\n  );\n  let i = 0;\n  return () => {\n    const count = String(i++);\n    return (hashPrefix +\n      '0'.repeat(STRING_LENGTH - hashPrefix.length - count.length) +\n      count) as Hash;\n  };\n}\n\nfunction toStringAndSlice(n: number | bigint, len: number): string {\n  return n.toString(32).slice(-len).padStart(len, '0');\n}\n\n/**\n * This creates an ID that looks like `<RANDOM><COUNTER>`. The random part is\n * a random number encoded with base 32 and the length is 12 characters. The\n * is 10 characters long and encoded as base 32. The total length is 22 characters.\n *\n * Do the math: https://devina.io/collision-calculator\n */\nfunction makeNewRandomHashFunctionInternal(): () => Hash {\n  let base = '';\n  let i = 0;\n\n  return () => {\n    if (!base) {\n      // This needs to be lazy because the cloudflare worker environment will\n      // throw an error if crypto.getRandomValues is used statically.  Specifically:\n      // Error: Some functionality, such as asynchronous I/O, timeouts, and\n      // generating random values, can only be performed while handling a\n      // request.\n      base = toStringAndSlice(randomUint64(), 12);\n    }\n    const tail = toStringAndSlice(i++, 10);\n    return (base + tail) as Hash;\n  };\n}\n\n/**\n * Generates a fake hash useful for testing.\n */\nexport function fakeHash(word: string | number): Hash {\n  if (typeof word === 'number') {\n    word = String(word);\n  }\n  return ('fake' + '0'.repeat(STRING_LENGTH - 4 - word.length) + word) as Hash;\n}\n\nexport function isHash(value: unknown): value is Hash {\n  return typeof value === 'string' && hashRe.test(value);\n}\n\nexport function assertHash(value: unknown): asserts value is Hash {\n  valita.assert(value, hashSchema);\n}\n\nexport const hashSchema = valita.string().assert(isHash, 'Invalid hash');\n","import * as valita from '../../shared/src/valita.ts';\n\n/**\n * The definition of a single index.\n */\nexport type IndexDefinition = {\n  /**\n   * The prefix, if any, to limit the index over. If not provided the values of\n   * all keys are indexed.\n   */\n  readonly prefix?: string | undefined;\n\n  /**\n   * A [JSON Pointer](https://tools.ietf.org/html/rfc6901) pointing at the sub\n   * value inside each value to index over.\n   *\n   * For example, one might index over users' ages like so:\n   * `{prefix: '/user/', jsonPointer: '/age'}`\n   */\n  readonly jsonPointer: string;\n\n  /**\n   * If `true`, indexing empty values will not emit a warning.  Defaults to `false`.\n   */\n  readonly allowEmpty?: boolean | undefined;\n};\n\nexport const indexDefinitionSchema: valita.Type<IndexDefinition> =\n  valita.readonlyObject({\n    prefix: valita.string().optional(),\n    jsonPointer: valita.string(),\n    allowEmpty: valita.boolean().optional(),\n  });\n\n/**\n * An object as a map defining the indexes. The keys are the index names and the\n * values are the index definitions.\n */\nexport type IndexDefinitions = {readonly [name: string]: IndexDefinition};\n\nexport const indexDefinitionsSchema = valita.readonlyRecord(\n  indexDefinitionSchema,\n);\n\nexport function indexDefinitionEqual(\n  a: IndexDefinition,\n  b: IndexDefinition,\n): boolean {\n  return (\n    a.jsonPointer === b.jsonPointer &&\n    (a.allowEmpty ?? false) === (b.allowEmpty ?? false) &&\n    (a.prefix ?? '') === (b.prefix ?? '')\n  );\n}\n\nexport function indexDefinitionsEqual(\n  a: IndexDefinitions,\n  b: IndexDefinitions,\n): boolean {\n  if (Object.keys(a).length !== Object.keys(b).length) {\n    return false;\n  }\n  for (const [aKey, aValue] of Object.entries(a)) {\n    const bValue = b[aKey];\n    if (!bValue || !indexDefinitionEqual(aValue, bValue)) {\n      return false;\n    }\n  }\n  return true;\n}\n\nexport function assertIndexDefinitions(\n  value: unknown,\n): asserts value is IndexDefinitions {\n  valita.assert(value, indexDefinitionsSchema);\n}\n","import {assert, assertObject} from '../../../shared/src/asserts.ts';\nimport * as valita from '../../../shared/src/valita.ts';\nimport {toRefs} from '../dag/chunk.ts';\nimport type {Read, Write} from '../dag/store.ts';\nimport {deepFreeze, type FrozenJSONValue} from '../frozen-json.ts';\nimport {type Hash, hashSchema} from '../hash.ts';\nimport {indexDefinitionsEqual, indexDefinitionsSchema} from '../index-defs.ts';\nimport type {ClientGroupID} from '../sync/ids.ts';\n\nexport type ClientGroupMap = ReadonlyMap<ClientGroupID, ClientGroup>;\n\nconst clientGroupSchema = valita.readonlyObject({\n  /**\n   * The hash of the commit in the perdag last persisted to this client group.\n   * Should only be updated by clients assigned to this client group.\n   */\n  headHash: hashSchema,\n\n  /**\n   * Set of mutator names common to all clients assigned to this client group.\n   */\n  mutatorNames: valita.readonlyArray(valita.string()),\n\n  /**\n   * Index definitions common to all clients assigned to this client group.\n   */\n  indexes: indexDefinitionsSchema,\n\n  /**\n   * The highest mutation ID of every client assigned to this client group.\n   * Should only be updated by clients assigned to this client group. Read by\n   * other clients to determine if there are unacknowledged pending mutations\n   * for them to try to recover. This is redundant with information in the\n   * commit graph at `headHash`, but allows other clients to determine if there\n   * are unacknowledged pending mutations without having to load the commit\n   * graph.\n   */\n  mutationIDs: valita.readonlyRecord(valita.number()),\n\n  /**\n   * The highest lastMutationID received from the server for every client\n   * assigned to this client group.\n   *\n   * Should be updated by the clients assigned to this client group whenever\n   * they persist to this client group. Read by other clients to determine if\n   * there are unacknowledged pending mutations for them to recover and\n   * *updated* by other clients upon successfully recovering pending mutations\n   * to avoid redundant pushes of pending mutations.\n   *\n   * Note: This will be the same as the `lastMutationIDs` of the base snapshot\n   * of the client group's commit graph when written by clients assigned to this\n   * client group.  However, when written by another client recovering mutations\n   * it may be different because the other client does not update the commit\n   * graph.\n   */\n  lastServerAckdMutationIDs: valita.record(valita.number()),\n\n  /**\n   * If the server deletes this client group it can signal that the client group\n   * was deleted. If that happens we mark this client group as disabled so that\n   * we do not use it again when creating new clients.\n   */\n  disabled: valita.boolean(),\n});\n\nexport type ClientGroup = valita.Infer<typeof clientGroupSchema>;\n\nexport const CLIENT_GROUPS_HEAD_NAME = 'client-groups';\n\nfunction assertClientGroup(value: unknown): asserts value is ClientGroup {\n  valita.assert(value, clientGroupSchema);\n}\n\nfunction chunkDataToClientGroupMap(chunkData: unknown): ClientGroupMap {\n  assertObject(chunkData);\n  const clientGroups = new Map<ClientGroupID, ClientGroup>();\n  for (const [key, value] of Object.entries(chunkData)) {\n    if (value !== undefined) {\n      assertClientGroup(value);\n      clientGroups.set(key, value);\n    }\n  }\n  return clientGroups;\n}\n\nfunction clientGroupMapToChunkData(\n  clientGroups: ClientGroupMap,\n  dagWrite: Write,\n): FrozenJSONValue {\n  const chunkData: {[id: ClientGroupID]: ClientGroup} = {};\n  for (const [clientGroupID, clientGroup] of clientGroups.entries()) {\n    dagWrite.assertValidHash(clientGroup.headHash);\n    chunkData[clientGroupID] = {\n      ...clientGroup,\n      mutatorNames: [...clientGroup.mutatorNames.values()],\n    };\n  }\n  return deepFreeze(chunkData);\n}\n\nasync function getClientGroupsAtHash(\n  hash: Hash,\n  dagRead: Read,\n): Promise<ClientGroupMap> {\n  const chunk = await dagRead.getChunk(hash);\n  return chunkDataToClientGroupMap(chunk?.data);\n}\n\nexport async function getClientGroups(dagRead: Read): Promise<ClientGroupMap> {\n  const hash = await dagRead.getHead(CLIENT_GROUPS_HEAD_NAME);\n  if (!hash) {\n    return new Map();\n  }\n  return getClientGroupsAtHash(hash, dagRead);\n}\n\nexport async function setClientGroups(\n  clientGroups: ClientGroupMap,\n  dagWrite: Write,\n): Promise<ClientGroupMap> {\n  const currClientGroups = await getClientGroups(dagWrite);\n  for (const [clientGroupID, clientGroup] of clientGroups) {\n    const currClientGroup = currClientGroups.get(clientGroupID);\n    validateClientGroupUpdate(clientGroup, currClientGroup);\n  }\n  return setValidatedClientGroups(clientGroups, dagWrite);\n}\n\nexport async function setClientGroup(\n  clientGroupID: ClientGroupID,\n  clientGroup: ClientGroup,\n  dagWrite: Write,\n): Promise<ClientGroupMap> {\n  const currClientGroups = await getClientGroups(dagWrite);\n  const currClientGroup = currClientGroups.get(clientGroupID);\n  validateClientGroupUpdate(clientGroup, currClientGroup);\n  const newClientGroups = new Map(currClientGroups);\n  newClientGroups.set(clientGroupID, clientGroup);\n  return setValidatedClientGroups(newClientGroups, dagWrite);\n}\n\nexport async function deleteClientGroup(\n  clientGroupID: ClientGroupID,\n  dagWrite: Write,\n): Promise<ClientGroupMap> {\n  const currClientGroups = await getClientGroups(dagWrite);\n  if (!currClientGroups.has(clientGroupID)) {\n    return currClientGroups;\n  }\n  const newClientGroups = new Map(currClientGroups.entries());\n  newClientGroups.delete(clientGroupID);\n  return setValidatedClientGroups(newClientGroups, dagWrite);\n}\n\nfunction validateClientGroupUpdate(\n  clientGroup: ClientGroup,\n  currClientGroup: ClientGroup | undefined,\n) {\n  const mutatorNamesSet = new Set(clientGroup.mutatorNames);\n  assert(\n    mutatorNamesSet.size === clientGroup.mutatorNames.length,\n    \"A client group's mutatorNames must be a set.\",\n  );\n  if (currClientGroup !== undefined) {\n    assert(\n      indexDefinitionsEqual(currClientGroup.indexes, clientGroup.indexes),\n      \"A client group's index definitions must never change.\",\n    );\n    assert(\n      mutatorNamesEqual(mutatorNamesSet, currClientGroup.mutatorNames),\n      \"A client group's mutatorNames must never change.\",\n    );\n  }\n}\n\nasync function setValidatedClientGroups(\n  clientGroups: ClientGroupMap,\n  dagWrite: Write,\n): Promise<ClientGroupMap> {\n  const chunkData = clientGroupMapToChunkData(clientGroups, dagWrite);\n  const refs: Set<Hash> = new Set();\n  for (const clientGroup of clientGroups.values()) {\n    refs.add(clientGroup.headHash);\n  }\n  const chunk = dagWrite.createChunk(chunkData, toRefs(refs));\n  await dagWrite.putChunk(chunk);\n  await dagWrite.setHead(CLIENT_GROUPS_HEAD_NAME, chunk.hash);\n  return clientGroups;\n}\n\nexport function mutatorNamesEqual(\n  mutatorNamesSet: ReadonlySet<string>,\n  mutatorNames: readonly string[],\n): boolean {\n  if (mutatorNames.length !== mutatorNamesSet.size) {\n    return false;\n  }\n  for (const mutatorName of mutatorNames) {\n    if (!mutatorNamesSet.has(mutatorName)) {\n      return false;\n    }\n  }\n  return true;\n}\n\nexport async function getClientGroup(\n  id: ClientGroupID,\n  dagRead: Read,\n): Promise<ClientGroup | undefined> {\n  const clientGroups = await getClientGroups(dagRead);\n  return clientGroups.get(id);\n}\n\nexport function clientGroupHasPendingMutations(clientGroup: ClientGroup) {\n  for (const [clientID, mutationID] of Object.entries(\n    clientGroup.mutationIDs,\n  )) {\n    const lastServerAckdMutationID =\n      clientGroup.lastServerAckdMutationIDs[clientID];\n    if (\n      (lastServerAckdMutationID === undefined && mutationID !== 0) ||\n      lastServerAckdMutationID < mutationID\n    ) {\n      return true;\n    }\n  }\n  return false;\n}\n\n/**\n * Marks a client group as disabled. This can happen if the server deletes the\n * client group (servers should not delete clients or client groups but it often\n * happens in practice when developing).\n *\n * A disabled client group prevents pulls and pushes from happening.\n */\nexport async function disableClientGroup(\n  clientGroupID: string,\n  dagWrite: Write,\n): Promise<void> {\n  const clientGroup = await getClientGroup(clientGroupID, dagWrite);\n  if (!clientGroup) {\n    // No client group matching in the database, so nothing to do.\n    return;\n  }\n  const disabledClientGroup = {\n    ...clientGroup,\n    disabled: true,\n  };\n  await setClientGroup(clientGroupID, disabledClientGroup, dagWrite);\n}\n","import {assertObject, throwInvalidType} from './asserts.ts';\nimport {skipAssertJSONValue} from './config.ts';\nimport {hasOwn} from './has-own.ts';\n\n/** The values that can be represented in JSON */\nexport type JSONValue =\n  | null\n  | string\n  | boolean\n  | number\n  | Array<JSONValue>\n  | JSONObject;\n\n/**\n * A JSON object. This is a map from strings to JSON values or `undefined`. We\n * allow `undefined` values as a convenience... but beware that the `undefined`\n * values do not round trip to the server. For example:\n *\n * ```\n * // Time t1\n * await tx.set('a', {a: undefined});\n *\n * // time passes, in a new transaction\n * const v = await tx.get('a');\n * console.log(v); // either {a: undefined} or {}\n * ```\n */\nexport type JSONObject = {[key: string]: JSONValue | undefined};\n\n/** Like {@link JSONValue} but deeply readonly */\nexport type ReadonlyJSONValue =\n  | null\n  | string\n  | boolean\n  | number\n  | ReadonlyArray<ReadonlyJSONValue>\n  | ReadonlyJSONObject;\n\n/** Like {@link JSONObject} but deeply readonly */\nexport type ReadonlyJSONObject = {\n  readonly [key: string]: ReadonlyJSONValue | undefined;\n};\n\n/**\n * Checks deep equality of two JSON value with (almost) same semantics as\n * `JSON.stringify`. The only difference is that with `JSON.stringify` the\n * ordering of the properties in an object/map/dictionary matters. In\n * {@link deepEqual} the following two values are consider equal, even though the\n * strings JSON.stringify would produce is different:\n *\n * ```js\n * assert(deepEqual(t({a: 1, b: 2}, {b: 2, a: 1}))\n * ```\n */\nexport function deepEqual(\n  a: ReadonlyJSONValue | undefined,\n  b: ReadonlyJSONValue | undefined,\n): boolean {\n  if (a === b) {\n    return true;\n  }\n\n  if (typeof a !== typeof b) {\n    return false;\n  }\n\n  switch (typeof a) {\n    case 'boolean':\n    case 'number':\n    case 'string':\n      return false;\n  }\n\n  // a cannot be undefined here because either a and b are undefined or their\n  // types are different.\n  // eslint-disable-next-line  @typescript-eslint/no-non-null-assertion\n  a = a!;\n\n  // 'object'\n  if (Array.isArray(a)) {\n    if (!Array.isArray(b)) {\n      return false;\n    }\n    if (a.length !== b.length) {\n      return false;\n    }\n    for (let i = 0; i < a.length; i++) {\n      if (!deepEqual(a[i], b[i])) {\n        return false;\n      }\n    }\n    return true;\n  }\n\n  if (a === null || b === null) {\n    return false;\n  }\n\n  if (Array.isArray(b)) {\n    return false;\n  }\n\n  // We know a and b are objects here but type inference is not smart enough.\n  a = a as ReadonlyJSONObject;\n  b = b as ReadonlyJSONObject;\n\n  // We use for-in loops instead of for of Object.keys() to make sure deepEquals\n  // does not allocate any objects.\n\n  let aSize = 0;\n  for (const key in a) {\n    if (hasOwn(a, key)) {\n      if (!deepEqual(a[key], b[key])) {\n        return false;\n      }\n      aSize++;\n    }\n  }\n\n  let bSize = 0;\n  for (const key in b) {\n    if (hasOwn(b, key)) {\n      bSize++;\n    }\n  }\n\n  return aSize === bSize;\n}\n\nexport function assertJSONValue(v: unknown): asserts v is JSONValue {\n  if (skipAssertJSONValue) {\n    return;\n  }\n  switch (typeof v) {\n    case 'boolean':\n    case 'number':\n    case 'string':\n      return;\n    case 'object':\n      if (v === null) {\n        return;\n      }\n      if (Array.isArray(v)) {\n        return assertJSONArray(v);\n      }\n      return assertObjectIsJSONObject(v as Record<string, unknown>);\n  }\n  throwInvalidType(v, 'JSON value');\n}\n\nexport function assertJSONObject(v: unknown): asserts v is JSONObject {\n  assertObject(v);\n  assertObjectIsJSONObject(v);\n}\n\nfunction assertObjectIsJSONObject(\n  v: Record<string, unknown>,\n): asserts v is JSONObject {\n  for (const k in v) {\n    if (hasOwn(v, k)) {\n      const value = v[k];\n      if (value !== undefined) {\n        assertJSONValue(value);\n      }\n    }\n  }\n}\n\nfunction assertJSONArray(v: unknown[]): asserts v is JSONValue[] {\n  for (const item of v) {\n    assertJSONValue(item);\n  }\n}\n\ninterface Path {\n  push(key: string | number): void;\n  pop(): void;\n}\n\n/**\n * Checks if a value is a JSON value. If there is a value that is not a JSON\n * value, the path parameter is updated to the path of the invalid value.\n */\nexport function isJSONValue(v: unknown, path: Path): v is JSONValue {\n  switch (typeof v) {\n    case 'boolean':\n    case 'number':\n    case 'string':\n      return true;\n    case 'object':\n      if (v === null) {\n        return true;\n      }\n      if (Array.isArray(v)) {\n        return isJSONArray(v, path);\n      }\n      return objectIsJSONObject(v as Record<string, unknown>, path);\n  }\n  return false;\n}\n\nexport function isJSONObject(v: unknown, path: Path): v is JSONObject {\n  if (typeof v !== 'object' || v === null) {\n    return false;\n  }\n  return objectIsJSONObject(v as Record<string, unknown>, path);\n}\n\nfunction objectIsJSONObject(\n  v: Record<string, unknown>,\n  path: Path,\n): v is JSONObject {\n  for (const k in v) {\n    if (hasOwn(v, k)) {\n      path.push(k);\n      const value = v[k];\n      if (value !== undefined && !isJSONValue(value, path)) {\n        return false;\n      }\n      path.pop();\n    }\n  }\n  return true;\n}\n\nfunction isJSONArray(v: unknown[], path: Path): v is JSONValue[] {\n  for (let i = 0; i < v.length; i++) {\n    path.push(i);\n    if (!isJSONValue(v[i], path)) {\n      return false;\n    }\n    path.pop();\n  }\n  return true;\n}\n\n/** Basic deep readonly type. It works for {@link JSONValue} types. */\nexport type DeepReadonly<T> = T extends\n  | null\n  | boolean\n  | string\n  | number\n  | undefined\n  ? T\n  : {readonly [K in keyof T]: DeepReadonly<T[K]>};\n","import {hasOwn} from '../../shared/src/has-own.ts';\nimport type {ReadonlyJSONObject} from '../../shared/src/json.ts';\n\nconst SIZE_TAG = 1;\nconst SIZE_INT32 = 4;\nconst SIZE_SMI = 5;\nconst SIZE_DOUBLE = 8;\n\n/**\n * Gives a size of a value. The size is modelled after the size used by\n * Chromium/V8's structuredClone algorithm. It does not match exactly so the\n * size is just an approximation.\n * https://source.chromium.org/chromium/chromium/src/+/main:v8/src/objects/value-serializer.cc;l=102;drc=f0b6f7d12ea47ad7c08fb554f678c1e73801ca36;bpv=1;bpt=1\n * For example we follow JSC/Mozilla for ints and skip the varint encoding.\n *\n * Mozilla does things similarly. Main difference is that there is no varint\n * encoding and every value uses multiples of 64bits\n * https://searchfox.org/mozilla-central/source/js/src/vm/StructuredClone.cpp#94\n *\n * And JSC:\n * https://github.com/WebKit/WebKit/blob/main/Source/WebCore/bindings/js/SerializedScriptValue.cpp#L356\n * - Use 1 byte tag\n * - Numbers are either stored as Int32 or Float64\n */\nexport function getSizeOfValue(value: unknown): number {\n  switch (typeof value) {\n    case 'string':\n      // Assumes all strings are one byte strings. V8 writes OneByteString and\n      // TwoByteString. We could check the string but it would require iterating\n      // over all the characters.\n      return SIZE_TAG + SIZE_INT32 + value.length;\n    case 'number':\n      if (isSmi(value)) {\n        if (value <= -(2 ** 30) || value >= 2 ** 30 - 1) {\n          return SIZE_TAG + SIZE_SMI;\n        }\n        return SIZE_TAG + SIZE_INT32;\n      }\n      return SIZE_TAG + SIZE_DOUBLE;\n    case 'boolean':\n      return SIZE_TAG;\n    case 'object':\n      if (value === null) {\n        return SIZE_TAG;\n      }\n\n      if (Array.isArray(value)) {\n        let sum = 2 * SIZE_TAG + SIZE_INT32;\n        for (const element of value) {\n          sum += getSizeOfValue(element);\n        }\n        return sum;\n      }\n\n      {\n        const val = value as ReadonlyJSONObject;\n        let sum: number = 2 * SIZE_TAG + SIZE_INT32;\n        for (const k in val) {\n          if (hasOwn(val, k)) {\n            // Skip undefined values. undefined values in an object gets\n            // stripped if we round trip through JSON.stringif which is what we\n            // use when syncing.\n            const propertyValue = val[k];\n            if (propertyValue !== undefined) {\n              sum += getSizeOfValue(k) + getSizeOfValue(propertyValue);\n            }\n          }\n        }\n        return sum;\n      }\n  }\n\n  throw new Error(`Invalid value. type: ${typeof value}, value: ${value}`);\n}\n\nfunction isSmi(value: number): boolean {\n  return value === (value | 0);\n}\n\nconst entryFixed = 2 * SIZE_TAG + SIZE_INT32 + SIZE_TAG + SIZE_INT32;\n\nexport function getSizeOfEntry<K, V>(key: K, value: V): number {\n  // Entries are stored as [key, value, sizeOfEntry]\n  return entryFixed + getSizeOfValue(key) + getSizeOfValue(value);\n}\n","import {compareUTF8} from 'compare-utf8';\nimport {\n  assert,\n  assertArray,\n  assertNumber,\n  assertString,\n} from '../../../shared/src/asserts.ts';\nimport {binarySearch as binarySearchWithFunc} from '../../../shared/src/binary-search.ts';\nimport type {Enum} from '../../../shared/src/enum.ts';\nimport {joinIterables} from '../../../shared/src/iterables.ts';\nimport {\n  type JSONValue,\n  type ReadonlyJSONValue,\n  assertJSONValue,\n} from '../../../shared/src/json.ts';\nimport {skipBTreeNodeAsserts} from '../config.ts';\nimport type {IndexKey} from '../db/index.ts';\nimport * as FormatVersion from '../format-version-enum.ts';\nimport {\n  type FrozenJSONValue,\n  type FrozenTag,\n  assertDeepFrozen,\n  deepFreeze,\n} from '../frozen-json.ts';\nimport {type Hash, emptyHash, newRandomHash} from '../hash.ts';\nimport type {BTreeRead} from './read.ts';\nimport type {BTreeWrite} from './write.ts';\n\ntype FormatVersion = Enum<typeof FormatVersion>;\n\nexport type Entry<V> = readonly [key: string, value: V, sizeOfEntry: number];\n\nexport const NODE_LEVEL = 0;\nexport const NODE_ENTRIES = 1;\n\n/**\n * The type of B+Tree node chunk data\n */\ntype BaseNode<V> = FrozenTag<\n  readonly [level: number, entries: ReadonlyArray<Entry<V>>]\n>;\nexport type InternalNode = BaseNode<Hash>;\n\nexport type DataNode = BaseNode<FrozenJSONValue>;\n\nexport function makeNodeChunkData<V>(\n  level: number,\n  entries: ReadonlyArray<Entry<V>>,\n  formatVersion: FormatVersion,\n): BaseNode<V> {\n  return deepFreeze([\n    level,\n    (formatVersion >= FormatVersion.V7\n      ? entries\n      : entries.map(e => e.slice(0, 2))) as readonly ReadonlyJSONValue[],\n  ]) as BaseNode<V>;\n}\n\nexport type Node = DataNode | InternalNode;\n\n/**\n * Describes the changes that happened to Replicache after a\n * {@link WriteTransaction} was committed.\n *\n * @experimental This type is experimental and may change in the future.\n */\nexport type Diff = IndexDiff | NoIndexDiff;\n\n/**\n * @experimental This type is experimental and may change in the future.\n */\nexport type IndexDiff = readonly DiffOperation<IndexKey>[];\n\n/**\n * @experimental This type is experimental and may change in the future.\n */\nexport type NoIndexDiff = readonly DiffOperation<string>[];\n\n/**\n * InternalDiff uses string keys even for the secondary index maps.\n */\nexport type InternalDiff = readonly InternalDiffOperation[];\n\nexport type DiffOperationAdd<Key, Value = ReadonlyJSONValue> = {\n  readonly op: 'add';\n  readonly key: Key;\n  readonly newValue: Value;\n};\n\nexport type DiffOperationDel<Key, Value = ReadonlyJSONValue> = {\n  readonly op: 'del';\n  readonly key: Key;\n  readonly oldValue: Value;\n};\n\nexport type DiffOperationChange<Key, Value = ReadonlyJSONValue> = {\n  readonly op: 'change';\n  readonly key: Key;\n  readonly oldValue: Value;\n  readonly newValue: Value;\n};\n\n/**\n * The individual parts describing the changes that happened to the Replicache\n * data. There are three different kinds of operations:\n * - `add`: A new entry was added.\n * - `del`: An entry was deleted.\n * - `change`: An entry was changed.\n *\n * @experimental This type is experimental and may change in the future.\n */\nexport type DiffOperation<Key> =\n  | DiffOperationAdd<Key>\n  | DiffOperationDel<Key>\n  | DiffOperationChange<Key>;\n\n// Duplicated with DiffOperation to make the docs less confusing.\nexport type InternalDiffOperation<Key = string, Value = FrozenJSONValue> =\n  | DiffOperationAdd<Key, Value>\n  | DiffOperationDel<Key, Value>\n  | DiffOperationChange<Key, Value>;\n\n/**\n * Finds the leaf where a key is (if present) or where it should go if not\n * present.\n */\nexport async function findLeaf(\n  key: string,\n  hash: Hash,\n  source: BTreeRead,\n  expectedRootHash: Hash,\n): Promise<DataNodeImpl> {\n  const node = await source.getNode(hash);\n  // The root changed. Try again\n  if (expectedRootHash !== source.rootHash) {\n    return findLeaf(key, source.rootHash, source, source.rootHash);\n  }\n  if (isDataNodeImpl(node)) {\n    return node;\n  }\n  const {entries} = node;\n  let i = binarySearch(key, entries);\n  if (i === entries.length) {\n    i--;\n  }\n  const entry = entries[i];\n  return findLeaf(key, entry[1], source, expectedRootHash);\n}\n\ntype BinarySearchEntries = readonly Entry<unknown>[];\n\n/**\n * Does a binary search over entries\n *\n * If the key found then the return value is the index it was found at.\n *\n * If the key was *not* found then the return value is the index where it should\n * be inserted at\n */\nexport function binarySearch(\n  key: string,\n  entries: BinarySearchEntries,\n): number {\n  return binarySearchWithFunc(entries.length, i =>\n    compareUTF8(key, entries[i][0]),\n  );\n}\n\nexport function binarySearchFound(\n  i: number,\n  entries: BinarySearchEntries,\n  key: string,\n): boolean {\n  return i !== entries.length && entries[i][0] === key;\n}\n\nexport function parseBTreeNode(\n  v: unknown,\n  formatVersion: FormatVersion,\n  getSizeOfEntry: <K, V>(key: K, value: V) => number,\n): InternalNode | DataNode {\n  if (skipBTreeNodeAsserts && formatVersion >= FormatVersion.V7) {\n    return v as InternalNode | DataNode;\n  }\n\n  assertArray(v);\n  assertDeepFrozen(v);\n  // Be relaxed about what we accept.\n  assert(v.length >= 2);\n  const [level, entries] = v;\n  assertNumber(level);\n  assertArray(entries);\n\n  const f = level > 0 ? assertString : assertJSONValue;\n\n  // For V7 we do not need to change the entries. Just assert that they are correct.\n  if (formatVersion >= FormatVersion.V7) {\n    for (const e of entries) {\n      assertEntry(e, f);\n    }\n    return v as unknown as InternalNode | DataNode;\n  }\n\n  const newEntries = entries.map(e => convertNonV7Entry(e, f, getSizeOfEntry));\n  return [level, newEntries] as unknown as InternalNode | DataNode;\n}\n\nfunction assertEntry(\n  entry: unknown,\n  f:\n    | ((v: unknown) => asserts v is Hash)\n    | ((v: unknown) => asserts v is JSONValue),\n): asserts entry is Entry<Hash | JSONValue> {\n  assertArray(entry);\n  // Be relaxed about what we accept.\n  assert(entry.length >= 3);\n  assertString(entry[0]);\n  f(entry[1]);\n  assertNumber(entry[2]);\n}\n\n/**\n * Converts an entry that was from a format version before V7 to the format\n * wanted by V7.\n */\nfunction convertNonV7Entry(\n  entry: unknown,\n  f:\n    | ((v: unknown) => asserts v is Hash)\n    | ((v: unknown) => asserts v is JSONValue),\n  getSizeOfEntry: <K, V>(key: K, value: V) => number,\n): Entry<Hash | JSONValue> {\n  assertArray(entry);\n  assert(entry.length >= 2);\n  assertString(entry[0]);\n  f(entry[1]);\n  const entrySize = getSizeOfEntry(entry[0], entry[1]);\n  return [entry[0], entry[1], entrySize] as Entry<Hash | JSONValue>;\n}\n\nexport function isInternalNode(node: Node): node is InternalNode {\n  return node[NODE_LEVEL] > 0;\n}\n\nabstract class NodeImpl<Value> {\n  entries: Array<Entry<Value>>;\n  hash: Hash;\n  abstract readonly level: number;\n  readonly isMutable: boolean;\n\n  #childNodeSize = -1;\n\n  constructor(entries: Array<Entry<Value>>, hash: Hash, isMutable: boolean) {\n    this.entries = entries;\n    this.hash = hash;\n    this.isMutable = isMutable;\n  }\n\n  abstract set(\n    key: string,\n    value: FrozenJSONValue,\n    entrySize: number,\n    tree: BTreeWrite,\n  ): Promise<NodeImpl<Value>>;\n\n  abstract del(\n    key: string,\n    tree: BTreeWrite,\n  ): Promise<NodeImpl<Value> | DataNodeImpl>;\n\n  maxKey(): string {\n    return this.entries[this.entries.length - 1][0];\n  }\n\n  getChildNodeSize(tree: BTreeRead): number {\n    if (this.#childNodeSize !== -1) {\n      return this.#childNodeSize;\n    }\n\n    let sum = tree.chunkHeaderSize;\n    for (const entry of this.entries) {\n      sum += entry[2];\n    }\n    return (this.#childNodeSize = sum);\n  }\n\n  protected _updateNode(tree: BTreeWrite) {\n    this.#childNodeSize = -1;\n    tree.updateNode(\n      this as NodeImpl<unknown> as DataNodeImpl | InternalNodeImpl,\n    );\n  }\n}\n\nexport function toChunkData<V>(\n  node: NodeImpl<V>,\n  formatVersion: FormatVersion,\n): BaseNode<V> {\n  return makeNodeChunkData(node.level, node.entries, formatVersion);\n}\n\nexport class DataNodeImpl extends NodeImpl<FrozenJSONValue> {\n  readonly level = 0;\n\n  set(\n    key: string,\n    value: FrozenJSONValue,\n    entrySize: number,\n    tree: BTreeWrite,\n  ): Promise<DataNodeImpl> {\n    let deleteCount: number;\n    const i = binarySearch(key, this.entries);\n    if (!binarySearchFound(i, this.entries, key)) {\n      // Not found, insert.\n      deleteCount = 0;\n    } else {\n      deleteCount = 1;\n    }\n\n    return Promise.resolve(\n      this.#splice(tree, i, deleteCount, [key, value, entrySize]),\n    );\n  }\n\n  #splice(\n    tree: BTreeWrite,\n    start: number,\n    deleteCount: number,\n    ...items: Entry<FrozenJSONValue>[]\n  ): DataNodeImpl {\n    if (this.isMutable) {\n      this.entries.splice(start, deleteCount, ...items);\n      this._updateNode(tree);\n      return this;\n    }\n\n    const entries = readonlySplice(this.entries, start, deleteCount, ...items);\n    return tree.newDataNodeImpl(entries);\n  }\n\n  del(key: string, tree: BTreeWrite): Promise<DataNodeImpl> {\n    const i = binarySearch(key, this.entries);\n    if (!binarySearchFound(i, this.entries, key)) {\n      // Not found. Return this without changes.\n      return Promise.resolve(this);\n    }\n\n    // Found. Create new node or mutate existing one.\n    return Promise.resolve(this.#splice(tree, i, 1));\n  }\n\n  async *keys(_tree: BTreeRead): AsyncGenerator<string, void> {\n    for (const entry of this.entries) {\n      yield entry[0];\n    }\n  }\n\n  async *entriesIter(\n    _tree: BTreeRead,\n  ): AsyncGenerator<Entry<FrozenJSONValue>, void> {\n    for (const entry of this.entries) {\n      yield entry;\n    }\n  }\n}\n\nfunction readonlySplice<T>(\n  array: ReadonlyArray<T>,\n  start: number,\n  deleteCount: number,\n  ...items: T[]\n): T[] {\n  const arr = array.slice(0, start);\n  for (let i = 0; i < items.length; i++) {\n    arr.push(items[i]);\n  }\n  for (let i = start + deleteCount; i < array.length; i++) {\n    arr.push(array[i]);\n  }\n  return arr;\n}\n\nexport class InternalNodeImpl extends NodeImpl<Hash> {\n  readonly level: number;\n\n  constructor(\n    entries: Array<Entry<Hash>>,\n    hash: Hash,\n    level: number,\n    isMutable: boolean,\n  ) {\n    super(entries, hash, isMutable);\n    this.level = level;\n  }\n\n  async set(\n    key: string,\n    value: FrozenJSONValue,\n    entrySize: number,\n    tree: BTreeWrite,\n  ): Promise<InternalNodeImpl> {\n    let i = binarySearch(key, this.entries);\n    if (i === this.entries.length) {\n      // We are going to insert into last (right most) leaf.\n      i--;\n    }\n\n    const childHash = this.entries[i][1];\n    const oldChildNode = await tree.getNode(childHash);\n\n    const childNode = await oldChildNode.set(key, value, entrySize, tree);\n\n    const childNodeSize = childNode.getChildNodeSize(tree);\n    if (childNodeSize > tree.maxSize || childNodeSize < tree.minSize) {\n      return this.#mergeAndPartition(tree, i, childNode);\n    }\n\n    const newEntry = createNewInternalEntryForNode(\n      childNode,\n      tree.getEntrySize,\n    );\n    return this.#replaceChild(tree, i, newEntry);\n  }\n\n  /**\n   * This merges the child node entries with previous or next sibling and then\n   * partitions the merged entries.\n   */\n  async #mergeAndPartition(\n    tree: BTreeWrite,\n    i: number,\n    childNode: DataNodeImpl | InternalNodeImpl,\n  ): Promise<InternalNodeImpl> {\n    const level = this.level - 1;\n    const thisEntries = this.entries;\n\n    type IterableHashEntries = Iterable<Entry<Hash>>;\n\n    let values: IterableHashEntries;\n    let startIndex: number;\n    let removeCount: number;\n    if (i > 0) {\n      const hash = thisEntries[i - 1][1];\n      const previousSibling = await tree.getNode(hash);\n      values = joinIterables(\n        previousSibling.entries as IterableHashEntries,\n        childNode.entries as IterableHashEntries,\n      );\n      startIndex = i - 1;\n      removeCount = 2;\n    } else if (i < thisEntries.length - 1) {\n      const hash = thisEntries[i + 1][1];\n      const nextSibling = await tree.getNode(hash);\n      values = joinIterables(\n        childNode.entries as IterableHashEntries,\n        nextSibling.entries as IterableHashEntries,\n      );\n      startIndex = i;\n      removeCount = 2;\n    } else {\n      values = childNode.entries as IterableHashEntries;\n      startIndex = i;\n      removeCount = 1;\n    }\n\n    const partitions = partition(\n      values,\n      value => value[2],\n      tree.minSize - tree.chunkHeaderSize,\n      tree.maxSize - tree.chunkHeaderSize,\n    );\n\n    // TODO: There are cases where we can reuse the old nodes. Creating new ones\n    // means more memory churn but also more writes to the underlying KV store.\n    const newEntries: Entry<Hash>[] = [];\n    for (const entries of partitions) {\n      const node = tree.newNodeImpl(entries, level);\n      const newHashEntry = createNewInternalEntryForNode(\n        node,\n        tree.getEntrySize,\n      );\n      newEntries.push(newHashEntry);\n    }\n\n    if (this.isMutable) {\n      this.entries.splice(startIndex, removeCount, ...newEntries);\n      this._updateNode(tree);\n      return this;\n    }\n\n    const entries = readonlySplice(\n      thisEntries,\n      startIndex,\n      removeCount,\n      ...newEntries,\n    );\n\n    return tree.newInternalNodeImpl(entries, this.level);\n  }\n\n  #replaceChild(\n    tree: BTreeWrite,\n    index: number,\n    newEntry: Entry<Hash>,\n  ): InternalNodeImpl {\n    if (this.isMutable) {\n      this.entries.splice(index, 1, newEntry);\n      this._updateNode(tree);\n      return this;\n    }\n    const entries = readonlySplice(this.entries, index, 1, newEntry);\n    return tree.newInternalNodeImpl(entries, this.level);\n  }\n\n  async del(\n    key: string,\n    tree: BTreeWrite,\n  ): Promise<InternalNodeImpl | DataNodeImpl> {\n    const i = binarySearch(key, this.entries);\n    if (i === this.entries.length) {\n      // Key is larger than maxKey of rightmost entry so it is not present.\n      return this;\n    }\n\n    const childHash = this.entries[i][1];\n    const oldChildNode = await tree.getNode(childHash);\n    const oldHash = oldChildNode.hash;\n\n    const childNode = await oldChildNode.del(key, tree);\n    if (childNode.hash === oldHash) {\n      // Not changed so not found.\n      return this;\n    }\n\n    if (childNode.entries.length === 0) {\n      // Subtree is now empty. Remove internal node.\n      const entries = readonlySplice(this.entries, i, 1);\n      return tree.newInternalNodeImpl(entries, this.level);\n    }\n\n    if (i === 0 && this.entries.length === 1) {\n      // There was only one node at this level and it was removed. We can return\n      // the modified subtree.\n      return childNode;\n    }\n\n    // The child node is still a good size.\n    if (childNode.getChildNodeSize(tree) > tree.minSize) {\n      // No merging needed.\n      const entry = createNewInternalEntryForNode(childNode, tree.getEntrySize);\n      return this.#replaceChild(tree, i, entry);\n    }\n\n    // Child node size is too small.\n    return this.#mergeAndPartition(tree, i, childNode);\n  }\n\n  async *keys(tree: BTreeRead): AsyncGenerator<string, void> {\n    for (const entry of this.entries) {\n      const childNode = await tree.getNode(entry[1]);\n      yield* childNode.keys(tree);\n    }\n  }\n\n  async *entriesIter(\n    tree: BTreeRead,\n  ): AsyncGenerator<Entry<FrozenJSONValue>, void> {\n    for (const entry of this.entries) {\n      const childNode = await tree.getNode(entry[1]);\n      yield* childNode.entriesIter(tree);\n    }\n  }\n\n  getChildren(\n    start: number,\n    length: number,\n    tree: BTreeRead,\n  ): Promise<Array<InternalNodeImpl | DataNodeImpl>> {\n    const ps: Promise<DataNodeImpl | InternalNodeImpl>[] = [];\n    for (let i = start; i < length && i < this.entries.length; i++) {\n      ps.push(tree.getNode(this.entries[i][1]));\n    }\n    return Promise.all(ps);\n  }\n\n  async getCompositeChildren(\n    start: number,\n    length: number,\n    tree: BTreeRead,\n  ): Promise<InternalNodeImpl | DataNodeImpl> {\n    const {level} = this;\n\n    if (length === 0) {\n      return new InternalNodeImpl([], newRandomHash(), level - 1, true);\n    }\n\n    const output = await this.getChildren(start, start + length, tree);\n\n    if (level > 1) {\n      const entries: Entry<Hash>[] = [];\n      for (const child of output as InternalNodeImpl[]) {\n        entries.push(...child.entries);\n      }\n      return new InternalNodeImpl(entries, newRandomHash(), level - 1, true);\n    }\n\n    assert(level === 1);\n    const entries: Entry<FrozenJSONValue>[] = [];\n    for (const child of output as DataNodeImpl[]) {\n      entries.push(...child.entries);\n    }\n    return new DataNodeImpl(entries, newRandomHash(), true);\n  }\n}\n\nexport function newNodeImpl(\n  entries: Array<Entry<FrozenJSONValue>>,\n  hash: Hash,\n  level: number,\n  isMutable: boolean,\n): DataNodeImpl;\nexport function newNodeImpl(\n  entries: Array<Entry<Hash>>,\n  hash: Hash,\n  level: number,\n  isMutable: boolean,\n): InternalNodeImpl;\nexport function newNodeImpl(\n  entries: Array<Entry<FrozenJSONValue>> | Array<Entry<Hash>>,\n  hash: Hash,\n  level: number,\n  isMutable: boolean,\n): DataNodeImpl | InternalNodeImpl;\nexport function newNodeImpl(\n  entries: Array<Entry<FrozenJSONValue>> | Array<Entry<Hash>>,\n  hash: Hash,\n  level: number,\n  isMutable: boolean,\n): DataNodeImpl | InternalNodeImpl {\n  if (level === 0) {\n    return new DataNodeImpl(\n      entries as Entry<FrozenJSONValue>[],\n      hash,\n      isMutable,\n    );\n  }\n  return new InternalNodeImpl(entries as Entry<Hash>[], hash, level, isMutable);\n}\n\nexport function isDataNodeImpl(\n  node: DataNodeImpl | InternalNodeImpl,\n): node is DataNodeImpl {\n  return node.level === 0;\n}\n\nexport function partition<T>(\n  values: Iterable<T>,\n  // This is the size of each Entry\n  getSizeOfEntry: (v: T) => number,\n  min: number,\n  max: number,\n): T[][] {\n  const partitions: T[][] = [];\n  const sizes: number[] = [];\n  let sum = 0;\n  let accum: T[] = [];\n  for (const value of values) {\n    const size = getSizeOfEntry(value);\n    if (size >= max) {\n      if (accum.length > 0) {\n        partitions.push(accum);\n        sizes.push(sum);\n      }\n      partitions.push([value]);\n      sizes.push(size);\n      sum = 0;\n      accum = [];\n    } else if (sum + size >= min) {\n      accum.push(value);\n      partitions.push(accum);\n      sizes.push(sum + size);\n      sum = 0;\n      accum = [];\n    } else {\n      sum += size;\n      accum.push(value);\n    }\n  }\n\n  if (sum > 0) {\n    if (sizes.length > 0 && sum + sizes[sizes.length - 1] <= max) {\n      partitions[partitions.length - 1].push(...accum);\n    } else {\n      partitions.push(accum);\n    }\n  }\n\n  return partitions;\n}\n\nexport const emptyDataNode = makeNodeChunkData<ReadonlyJSONValue>(\n  0,\n  [],\n  FormatVersion.Latest,\n);\nexport const emptyDataNodeImpl = new DataNodeImpl([], emptyHash, false);\n\nexport function createNewInternalEntryForNode(\n  node: NodeImpl<unknown>,\n  getSizeOfEntry: <K, V>(k: K, v: V) => number,\n): [string, Hash, number] {\n  const key = node.maxKey();\n  const value = node.hash;\n  const size = getSizeOfEntry(key, value);\n  return [key, value, size];\n}\n","/**\n * This is a binary search that returns the index of the first element in the\n * array that is greater than or equal to the given value.\n *\n * Typical usage:\n *\n * ```\n * const haystack = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9];\n * const needle = 3;\n * const index = binarySearch(haystack.length, i => needle - haystack[i]);\n * const found = index < haystack.length && haystack[index] === needle;\n * ```\n */\nexport function binarySearch(high: number, compare: (i: number) => number) {\n  let low = 0;\n  while (low < high) {\n    const mid = low + ((high - low) >> 1);\n    const i = compare(mid);\n    if (i === 0) {\n      return mid;\n    }\n    if (i > 0) {\n      low = mid + 1;\n    } else {\n      high = mid;\n    }\n  }\n  return low;\n}\n","import {assert} from './asserts.ts';\n\nexport function* joinIterables<T>(...iters: Iterable<T>[]) {\n  for (const iter of iters) {\n    yield* iter;\n  }\n}\n\nfunction* filterIter<T>(\n  iter: Iterable<T>,\n  p: (t: T, index: number) => boolean,\n): Iterable<T> {\n  let index = 0;\n  for (const t of iter) {\n    if (p(t, index++)) {\n      yield t;\n    }\n  }\n}\n\nfunction* mapIter<T, U>(\n  iter: Iterable<T>,\n  f: (t: T, index: number) => U,\n): Iterable<U> {\n  let index = 0;\n  for (const t of iter) {\n    yield f(t, index++);\n  }\n}\n\nexport function first<T>(stream: Iterable<T>): T | undefined {\n  const it = stream[Symbol.iterator]();\n  const {value} = it.next();\n  it.return?.();\n  return value;\n}\n\nexport function* once<T>(stream: Iterable<T>): Iterable<T> {\n  const it = stream[Symbol.iterator]();\n  const {value} = it.next();\n  if (value !== undefined) {\n    yield value;\n  }\n  it.return?.();\n}\n\n// TODO(arv): Use ES2024 Iterable.from when available\n// https://github.com/tc39/proposal-iterator-helpers\n\nclass IterWrapper<T> implements Iterable<T> {\n  iter: Iterable<T>;\n  constructor(iter: Iterable<T>) {\n    this.iter = iter;\n  }\n\n  [Symbol.iterator]() {\n    return this.iter[Symbol.iterator]();\n  }\n\n  map<U>(f: (t: T, index: number) => U): IterWrapper<U> {\n    return new IterWrapper(mapIter(this.iter, f));\n  }\n\n  filter(p: (t: T, index: number) => boolean): IterWrapper<T> {\n    return new IterWrapper(filterIter(this.iter, p));\n  }\n}\n\nexport function wrapIterable<T>(iter: Iterable<T>): IterWrapper<T> {\n  return new IterWrapper(iter);\n}\n\nexport function* mergeIterables<T>(\n  iterables: Iterable<T>[],\n  comparator: (l: T, r: T) => number,\n  distinct = false,\n): IterableIterator<T> {\n  const iterators = iterables.map(i => i[Symbol.iterator]());\n  try {\n    const current = iterators.map(i => i.next());\n    let lastYielded: T | undefined;\n    while (current.some(c => !c.done)) {\n      const min = current.reduce(\n        (acc: [T, number] | undefined, c, i): [T, number] | undefined => {\n          if (c.done) {\n            return acc;\n          }\n          if (acc === undefined || comparator(c.value, acc[0]) < 0) {\n            return [c.value, i];\n          }\n          return acc;\n        },\n        undefined,\n      );\n\n      assert(min !== undefined, 'min is undefined');\n      current[min[1]] = iterators[min[1]].next();\n      if (\n        lastYielded !== undefined &&\n        distinct &&\n        comparator(lastYielded, min[0]) === 0\n      ) {\n        continue;\n      }\n      lastYielded = min[0];\n      yield min[0];\n    }\n  } finally {\n    for (const it of iterators) {\n      it.return?.();\n    }\n  }\n}\n","import {deepEqual, type ReadonlyJSONValue} from '../../../shared/src/json.ts';\n\nexport type Splice = [at: number, removed: number, added: number, from: number];\n\nconst SPLICE_UNASSIGNED = -1;\nexport const SPLICE_AT = 0;\nexport const SPLICE_REMOVED = 1;\nexport const SPLICE_ADDED = 2;\nexport const SPLICE_FROM = 3;\n\nconst KEY = 0;\nconst VALUE = 1;\n\ntype Entry<V> = readonly [key: string, value: V, ...rest: unknown[]];\n\nexport function* computeSplices<T>(\n  previous: readonly Entry<T>[],\n  current: readonly Entry<T>[],\n): Generator<Splice, void> {\n  let previousIndex = 0;\n  let currentIndex = 0;\n  let splice: Splice | undefined;\n\n  function ensureAssigned(splice: Splice, index: number): void {\n    if (splice[SPLICE_FROM] === SPLICE_UNASSIGNED) {\n      splice[SPLICE_FROM] = index;\n    }\n  }\n\n  function newSplice(): Splice {\n    return [previousIndex, 0, 0, SPLICE_UNASSIGNED];\n  }\n\n  while (previousIndex < previous.length && currentIndex < current.length) {\n    if (previous[previousIndex][KEY] === current[currentIndex][KEY]) {\n      if (\n        deepEqual(\n          // These are really Hash | InternalValue\n          previous[previousIndex][VALUE] as ReadonlyJSONValue,\n          current[currentIndex][VALUE] as ReadonlyJSONValue,\n        )\n      ) {\n        if (splice) {\n          ensureAssigned(splice, 0);\n          yield splice;\n          splice = undefined;\n        }\n      } else {\n        if (!splice) {\n          splice = newSplice();\n        }\n        splice[SPLICE_ADDED]++;\n        splice[SPLICE_REMOVED]++;\n        ensureAssigned(splice, currentIndex);\n      }\n      previousIndex++;\n      currentIndex++;\n    } else if (previous[previousIndex][KEY] < current[currentIndex][KEY]) {\n      // previous was removed\n      if (!splice) {\n        splice = newSplice();\n      }\n      splice[SPLICE_REMOVED]++;\n\n      previousIndex++;\n    } else {\n      // current was added\n      if (!splice) {\n        splice = newSplice();\n      }\n      splice[SPLICE_ADDED]++;\n      ensureAssigned(splice, currentIndex);\n\n      currentIndex++;\n    }\n  }\n\n  if (currentIndex < current.length) {\n    if (!splice) {\n      splice = newSplice();\n    }\n    splice[SPLICE_ADDED] += current.length - currentIndex;\n    ensureAssigned(splice, currentIndex);\n  }\n\n  if (previousIndex < previous.length) {\n    if (!splice) {\n      splice = newSplice();\n    }\n    splice[SPLICE_REMOVED] += previous.length - previousIndex;\n  }\n\n  if (splice) {\n    ensureAssigned(splice, 0);\n    yield splice;\n  }\n}\n","import type {Enum} from '../../../shared/src/enum.ts';\nimport {deepEqual} from '../../../shared/src/json.ts';\nimport type {Read} from '../dag/store.ts';\nimport * as FormatVersion from '../format-version-enum.ts';\nimport type {FrozenJSONValue} from '../frozen-json.ts';\nimport {type Hash, emptyHash} from '../hash.ts';\nimport {getSizeOfEntry} from '../size-of-value.ts';\nimport {\n  DataNodeImpl,\n  type Entry,\n  type InternalDiff,\n  type InternalDiffOperation,\n  InternalNodeImpl,\n  NODE_ENTRIES,\n  NODE_LEVEL,\n  binarySearch,\n  binarySearchFound,\n  emptyDataNodeImpl,\n  findLeaf,\n  isDataNodeImpl,\n  newNodeImpl,\n  parseBTreeNode,\n} from './node.ts';\nimport {\n  SPLICE_ADDED,\n  SPLICE_AT,\n  SPLICE_FROM,\n  SPLICE_REMOVED,\n  computeSplices,\n} from './splice.ts';\n\ntype FormatVersion = Enum<typeof FormatVersion>;\n\n/**\n * The size of the header of a node. (If we had compile time\n * constants we would have used that).\n *\n * There is a test ensuring this is correct.\n */\nexport const NODE_HEADER_SIZE = 11;\n\nexport class BTreeRead implements AsyncIterable<Entry<FrozenJSONValue>> {\n  protected readonly _cache: Map<Hash, DataNodeImpl | InternalNodeImpl> =\n    new Map();\n\n  protected readonly _dagRead: Read;\n  protected readonly _formatVersion: FormatVersion;\n  rootHash: Hash;\n  readonly getEntrySize: <K, V>(k: K, v: V) => number;\n  readonly chunkHeaderSize: number;\n\n  constructor(\n    dagRead: Read,\n    formatVersion: FormatVersion,\n    root: Hash = emptyHash,\n    getEntrySize: <K, V>(k: K, v: V) => number = getSizeOfEntry,\n    chunkHeaderSize = NODE_HEADER_SIZE,\n  ) {\n    this._dagRead = dagRead;\n    this._formatVersion = formatVersion;\n    this.rootHash = root;\n    this.getEntrySize = getEntrySize;\n    this.chunkHeaderSize = chunkHeaderSize;\n  }\n\n  async getNode(hash: Hash): Promise<DataNodeImpl | InternalNodeImpl> {\n    if (hash === emptyHash) {\n      return emptyDataNodeImpl;\n    }\n\n    const cached = this._cache.get(hash);\n    if (cached) {\n      return cached;\n    }\n\n    const chunk = await this._dagRead.mustGetChunk(hash);\n    const data = parseBTreeNode(\n      chunk.data,\n      this._formatVersion,\n      this.getEntrySize,\n    );\n    const impl = newNodeImpl(\n      data[NODE_ENTRIES] as Entry<FrozenJSONValue>[],\n      hash,\n      data[NODE_LEVEL],\n      false,\n    );\n    this._cache.set(hash, impl);\n    return impl;\n  }\n\n  async get(key: string): Promise<FrozenJSONValue | undefined> {\n    const leaf = await findLeaf(key, this.rootHash, this, this.rootHash);\n    const index = binarySearch(key, leaf.entries);\n    if (!binarySearchFound(index, leaf.entries, key)) {\n      return undefined;\n    }\n    return leaf.entries[index][1];\n  }\n\n  async has(key: string): Promise<boolean> {\n    const leaf = await findLeaf(key, this.rootHash, this, this.rootHash);\n    const index = binarySearch(key, leaf.entries);\n    return binarySearchFound(index, leaf.entries, key);\n  }\n\n  async isEmpty(): Promise<boolean> {\n    const {rootHash} = this;\n    const node = await this.getNode(this.rootHash);\n    // The root hash has changed, so the tree has been modified.\n    if (this.rootHash !== rootHash) {\n      return this.isEmpty();\n    }\n    return node.entries.length === 0;\n  }\n\n  // We don't do any encoding of the key in the map, so we have no way of\n  // determining from an entry.key alone whether it is a regular key or an\n  // encoded IndexKey in an index map. Without encoding regular map keys the\n  // caller has to deal with encoding and decoding the keys for the index map.\n  scan(fromKey: string): AsyncIterableIterator<Entry<FrozenJSONValue>> {\n    return scanForHash(\n      this.rootHash,\n      () => this.rootHash,\n      this.rootHash,\n      fromKey,\n      async hash => {\n        const cached = await this.getNode(hash);\n        if (cached) {\n          return [\n            cached.level,\n            cached.isMutable ? cached.entries.slice() : cached.entries,\n          ];\n        }\n        const chunk = await this._dagRead.mustGetChunk(hash);\n        return parseBTreeNode(\n          chunk.data,\n          this._formatVersion,\n          this.getEntrySize,\n        );\n      },\n    );\n  }\n\n  async *keys(): AsyncIterableIterator<string> {\n    const node = await this.getNode(this.rootHash);\n    yield* node.keys(this);\n  }\n\n  async *entries(): AsyncIterableIterator<Entry<FrozenJSONValue>> {\n    const node = await this.getNode(this.rootHash);\n    yield* node.entriesIter(this);\n  }\n\n  [Symbol.asyncIterator](): AsyncIterableIterator<Entry<FrozenJSONValue>> {\n    return this.entries();\n  }\n\n  async *diff(last: BTreeRead): AsyncIterableIterator<InternalDiffOperation> {\n    const [currentNode, lastNode] = await Promise.all([\n      this.getNode(this.rootHash),\n      last.getNode(last.rootHash),\n    ]);\n    yield* diffNodes(lastNode, currentNode, last, this);\n  }\n}\n\nasync function* diffNodes(\n  last: InternalNodeImpl | DataNodeImpl,\n  current: InternalNodeImpl | DataNodeImpl,\n  lastTree: BTreeRead,\n  currentTree: BTreeRead,\n): AsyncIterableIterator<InternalDiffOperation> {\n  if (last.level > current.level) {\n    // merge all of last's children into a new node\n    // We know last is an internal node because level > 0.\n    const lastChild = (await (last as InternalNodeImpl).getCompositeChildren(\n      0,\n      last.entries.length,\n      lastTree,\n    )) as InternalNodeImpl;\n    yield* diffNodes(lastChild, current, lastTree, currentTree);\n    return;\n  }\n\n  if (current.level > last.level) {\n    // We know current is an internal node because level > 0.\n    const currentChild = (await (\n      current as InternalNodeImpl\n    ).getCompositeChildren(\n      0,\n      current.entries.length,\n      currentTree,\n    )) as InternalNodeImpl;\n    yield* diffNodes(last, currentChild, lastTree, currentTree);\n    return;\n  }\n\n  if (isDataNodeImpl(last) && isDataNodeImpl(current)) {\n    yield* diffEntries(\n      (last as DataNodeImpl).entries,\n      (current as DataNodeImpl).entries,\n    );\n    return;\n  }\n\n  // Now we have two internal nodes with the same level. We compute the diff as\n  // splices for the internal node entries. We then flatten these and call diff\n  // recursively.\n  const initialSplices = computeSplices(\n    (last as InternalNodeImpl).entries,\n    (current as InternalNodeImpl).entries,\n  );\n  for (const splice of initialSplices) {\n    const [lastChild, currentChild] = await Promise.all([\n      (last as InternalNodeImpl).getCompositeChildren(\n        splice[SPLICE_AT],\n        splice[SPLICE_REMOVED],\n        lastTree,\n      ),\n      (current as InternalNodeImpl).getCompositeChildren(\n        splice[SPLICE_FROM],\n        splice[SPLICE_ADDED],\n        currentTree,\n      ),\n    ]);\n    yield* diffNodes(lastChild, currentChild, lastTree, currentTree);\n  }\n}\n\nfunction* diffEntries(\n  lastEntries: readonly Entry<FrozenJSONValue>[],\n  currentEntries: readonly Entry<FrozenJSONValue>[],\n): IterableIterator<InternalDiffOperation> {\n  const lastLength = lastEntries.length;\n  const currentLength = currentEntries.length;\n  let i = 0;\n  let j = 0;\n  while (i < lastLength && j < currentLength) {\n    const lastKey = lastEntries[i][0];\n    const currentKey = currentEntries[j][0];\n    if (lastKey === currentKey) {\n      if (!deepEqual(lastEntries[i][1], currentEntries[j][1])) {\n        yield {\n          op: 'change',\n          key: lastKey,\n          oldValue: lastEntries[i][1],\n          newValue: currentEntries[j][1],\n        };\n      }\n      i++;\n      j++;\n    } else if (lastKey < currentKey) {\n      yield {\n        op: 'del',\n        key: lastKey,\n        oldValue: lastEntries[i][1],\n      };\n      i++;\n    } else {\n      yield {\n        op: 'add',\n        key: currentKey,\n        newValue: currentEntries[j][1],\n      };\n      j++;\n    }\n  }\n  for (; i < lastLength; i++) {\n    yield {\n      op: 'del',\n      key: lastEntries[i][0],\n      oldValue: lastEntries[i][1],\n    };\n  }\n  for (; j < currentLength; j++) {\n    yield {\n      op: 'add',\n      key: currentEntries[j][0],\n      newValue: currentEntries[j][1],\n    };\n  }\n}\n\n// Redefine the type here to allow the optional size in the tuple.\ntype ReadNodeResult = readonly [\n  level: number,\n  data: readonly Entry<FrozenJSONValue>[] | readonly Entry<Hash>[],\n];\n\ntype ReadNode = (hash: Hash) => Promise<ReadNodeResult>;\n\nasync function* scanForHash(\n  expectedRootHash: Hash,\n  getRootHash: () => Hash,\n  hash: Hash,\n  fromKey: string,\n  readNode: ReadNode,\n): AsyncIterableIterator<Entry<FrozenJSONValue>> {\n  if (hash === emptyHash) {\n    return;\n  }\n\n  const data = await readNode(hash);\n  const entries = data[NODE_ENTRIES];\n  let i = 0;\n  if (fromKey) {\n    i = binarySearch(fromKey, entries);\n  }\n  if (data[NODE_LEVEL] > 0) {\n    for (; i < entries.length; i++) {\n      yield* scanForHash(\n        expectedRootHash,\n        getRootHash,\n        (entries[i] as Entry<Hash>)[1],\n        fromKey,\n        readNode,\n      );\n      fromKey = '';\n    }\n  } else {\n    for (; i < entries.length; i++) {\n      const rootHash = getRootHash();\n      // If rootHash changed then we start a new iterator from the key.\n      if (expectedRootHash !== rootHash) {\n        yield* scanForHash(\n          rootHash,\n          getRootHash,\n          rootHash,\n          entries[i][0],\n          readNode,\n        );\n        return;\n      }\n      yield entries[i] as Entry<FrozenJSONValue>;\n    }\n  }\n}\n\nexport async function allEntriesAsDiff(\n  map: BTreeRead,\n  op: 'add' | 'del',\n): Promise<InternalDiff> {\n  const diff: InternalDiffOperation[] = [];\n  const make: (entry: Entry<FrozenJSONValue>) => InternalDiffOperation =\n    op === 'add'\n      ? entry => ({\n          op: 'add',\n          key: entry[0],\n          newValue: entry[1],\n        })\n      : entry => ({\n          op: 'del',\n          key: entry[0],\n          oldValue: entry[1],\n        });\n\n  for await (const entry of map.entries()) {\n    diff.push(make(entry));\n  }\n  return diff;\n}\n","export function stringCompare(a: string, b: string): number {\n  if (a === b) {\n    return 0;\n  }\n  if (a < b) {\n    return -1;\n  }\n  return 1;\n}\n","import {\n  assertJSONObject,\n  type ReadonlyJSONValue,\n} from '../../shared/src/json.ts';\nimport {stringCompare} from '../../shared/src/string-compare.ts';\nimport type {FrozenJSONValue} from './frozen-json.ts';\n\n/**\n * A cookie is a value that is used to determine the order of snapshots. It\n * needs to be comparable. This can be a `string`, `number` or if you want to\n * use a more complex value, you can use an object with an `order` property. The\n * value `null` is considered to be less than any other cookie and it is used\n * for the first pull when no cookie has been set.\n *\n * The order is the natural order of numbers and strings. If one of the cookies\n * is an object then the value of the `order` property is treated as the cookie\n * when doing comparison.\n *\n * If one of the cookies is a string and the other is a number, the number is\n * fist converted to a string (using `toString()`).\n */\nexport type Cookie =\n  | null\n  | string\n  | number\n  | (ReadonlyJSONValue & {readonly order: number | string});\n\nexport type FrozenCookie =\n  | null\n  | string\n  | number\n  | (FrozenJSONValue & {readonly order: number | string});\n\n/**\n * Compare two cookies.\n * `null` is considered to be less than any other cookie.\n */\nexport function compareCookies(a: Cookie, b: Cookie): number {\n  if (a === b) {\n    return 0;\n  }\n  if (a === null) {\n    return -1;\n  }\n  if (b === null) {\n    return 1;\n  }\n\n  const cva = getCompareValue(a);\n  const cvb = getCompareValue(b);\n\n  // If either a or b is a string. Compare by string.\n  if (typeof cva === 'string' || typeof cvb === 'string') {\n    return stringCompare(String(cva), String(cvb));\n  }\n\n  return cva - cvb;\n}\n\ntype NonNull<T> = T extends null ? never : T;\n\nfunction getCompareValue(cookie: NonNull<Cookie>): string | number {\n  if (typeof cookie === 'string' || typeof cookie === 'number') {\n    return cookie;\n  }\n  return cookie.order;\n}\n\nexport function assertCookie(v: unknown): asserts v is Cookie {\n  if (v === null || typeof v === 'string' || typeof v === 'number') {\n    return;\n  }\n\n  assertJSONObject(v);\n  if (typeof v.order === 'string' || typeof v.order === 'number') {\n    return;\n  }\n\n  throw new Error('Invalid cookie');\n}\n","/* eslint-disable @typescript-eslint/naming-convention */\n\n// These three were used before...\n// IndexChangeSDD = 1;\n// LocalSDD = 2;\n// SnapshotSDD = 3;\nexport const LocalDD31 = 4;\nexport const SnapshotDD31 = 5;\n\nexport type LocalDD31 = typeof LocalDD31;\nexport type SnapshotDD31 = typeof SnapshotDD31;\n","import {\n  assert,\n  assertArray,\n  assertBoolean,\n  assertNumber,\n  assertObject,\n  assertString,\n  unreachable,\n} from '../../../shared/src/asserts.ts';\nimport {assertJSONValue} from '../../../shared/src/json.ts';\nimport {skipCommitDataAsserts} from '../config.ts';\nimport {type FrozenCookie, compareCookies} from '../cookies.ts';\nimport {type Chunk, type CreateChunk, type Refs, toRefs} from '../dag/chunk.ts';\nimport {type MustGetChunk, type Read, mustGetHeadHash} from '../dag/store.ts';\nimport {\n  type FrozenJSONValue,\n  type FrozenTag,\n  assertDeepFrozen,\n  deepFreeze,\n} from '../frozen-json.ts';\nimport {type Hash, assertHash} from '../hash.ts';\nimport type {IndexDefinition} from '../index-defs.ts';\nimport type {ClientID} from '../sync/ids.ts';\nimport * as MetaType from './meta-type-enum.ts';\n\nexport const DEFAULT_HEAD_NAME = 'main';\n\nexport function commitIsLocalDD31(\n  commit: Commit<Meta>,\n): commit is Commit<LocalMetaDD31> {\n  return isLocalMetaDD31(commit.meta);\n}\n\nexport function commitIsLocal(\n  commit: Commit<Meta>,\n): commit is Commit<LocalMetaDD31> {\n  return commitIsLocalDD31(commit);\n}\n\nexport function commitIsSnapshot(\n  commit: Commit<Meta>,\n): commit is Commit<SnapshotMetaDD31> {\n  return isSnapshotMetaDD31(commit.meta);\n}\n\nexport class Commit<M extends Meta> {\n  readonly chunk: Chunk<CommitData<M>>;\n\n  constructor(chunk: Chunk<CommitData<M>>) {\n    this.chunk = chunk;\n  }\n\n  get meta(): M {\n    return this.chunk.data.meta;\n  }\n\n  get valueHash(): Hash {\n    // Already validated!\n    return this.chunk.data.valueHash;\n  }\n\n  getMutationID(clientID: ClientID, dagRead: MustGetChunk): Promise<number> {\n    return getMutationID(clientID, dagRead, this.meta);\n  }\n\n  async getNextMutationID(\n    clientID: ClientID,\n    dagRead: MustGetChunk,\n  ): Promise<number> {\n    return (await this.getMutationID(clientID, dagRead)) + 1;\n  }\n\n  get indexes(): readonly IndexRecord[] {\n    // Already validated!\n    return this.chunk.data.indexes;\n  }\n}\n\nexport async function getMutationID(\n  clientID: ClientID,\n  dagRead: MustGetChunk,\n  meta: Meta,\n): Promise<number> {\n  switch (meta.type) {\n    case MetaType.SnapshotDD31:\n      return meta.lastMutationIDs[clientID] ?? 0;\n\n    case MetaType.LocalDD31: {\n      if (meta.clientID === clientID) {\n        return meta.mutationID;\n      }\n      const {basisHash} = meta;\n      const basisCommit = await commitFromHash(basisHash, dagRead);\n      return getMutationID(clientID, dagRead, basisCommit.meta);\n    }\n\n    default:\n      unreachable(meta);\n  }\n}\n\n/**\n * Returns the set of local commits from the given `fromCommitHash` back to but not\n * including its base snapshot. If `fromCommitHash` is a snapshot, the returned vector\n * will be empty. When, as typical, `fromCommitHash` is the head of the default chain\n * then the returned commits are the set of pending commits, ie the set of local commits\n * that have not yet been pushed to the data layer.\n *\n * The vector of commits is returned in reverse chain order, that is, starting\n * with the commit with hash `fromCommitHash` and walking backwards.\n */\nexport async function localMutations(\n  fromCommitHash: Hash,\n  dagRead: Read,\n): Promise<Commit<LocalMetaDD31>[]> {\n  const commits = await commitChain(fromCommitHash, dagRead);\n  // Filter does not deal with type narrowing.\n  return commits.filter(c => commitIsLocal(c)) as Commit<LocalMetaDD31>[];\n}\n\nexport async function localMutationsDD31(\n  fromCommitHash: Hash,\n  dagRead: Read,\n): Promise<Commit<LocalMetaDD31>[]> {\n  const commits = await commitChain(fromCommitHash, dagRead);\n  // Filter does not deal with type narrowing.\n  return commits.filter(c => commitIsLocalDD31(c)) as Commit<LocalMetaDD31>[];\n}\n\nexport async function localMutationsGreaterThan(\n  commit: Commit<Meta>,\n  mutationIDLimits: Record<ClientID, number>,\n  dagRead: Read,\n): Promise<Commit<LocalMetaDD31>[]> {\n  const commits: Commit<LocalMetaDD31>[] = [];\n  const remainingMutationIDLimits = new Map(Object.entries(mutationIDLimits));\n  while (!commitIsSnapshot(commit) && remainingMutationIDLimits.size > 0) {\n    if (commitIsLocalDD31(commit)) {\n      const {meta} = commit;\n      const mutationIDLowerLimit = remainingMutationIDLimits.get(meta.clientID);\n      if (mutationIDLowerLimit !== undefined) {\n        if (meta.mutationID <= mutationIDLowerLimit) {\n          remainingMutationIDLimits.delete(meta.clientID);\n        } else {\n          commits.push(commit as Commit<LocalMetaDD31>);\n        }\n      }\n    }\n    const {basisHash} = commit.meta;\n    if (basisHash === null) {\n      throw new Error(`Commit ${commit.chunk.hash} has no basis`);\n    }\n    commit = await commitFromHash(basisHash, dagRead);\n  }\n  return commits;\n}\n\nexport async function baseSnapshotFromHead(\n  name: string,\n  dagRead: Read,\n): Promise<Commit<SnapshotMetaDD31>> {\n  const hash = await dagRead.getHead(name);\n  assert(hash, `Missing head ${name}`);\n  return baseSnapshotFromHash(hash, dagRead);\n}\n\nexport async function baseSnapshotHashFromHash(\n  hash: Hash,\n  dagRead: Read,\n): Promise<Hash> {\n  return (await baseSnapshotFromHash(hash, dagRead)).chunk.hash;\n}\n\nexport async function baseSnapshotFromHash(\n  hash: Hash,\n  dagRead: Read,\n): Promise<Commit<SnapshotMetaDD31>> {\n  const commit = await commitFromHash(hash, dagRead);\n  return baseSnapshotFromCommit(commit, dagRead);\n}\n\nexport async function baseSnapshotFromCommit(\n  commit: Commit<Meta>,\n  dagRead: Read,\n): Promise<Commit<SnapshotMetaDD31>> {\n  while (!commitIsSnapshot(commit)) {\n    const {meta} = commit;\n    if (isLocalMetaDD31(meta)) {\n      commit = await commitFromHash(meta.baseSnapshotHash, dagRead);\n    } else {\n      const {basisHash} = meta;\n      if (basisHash === null) {\n        throw new Error(`Commit ${commit.chunk.hash} has no basis`);\n      }\n      commit = await commitFromHash(basisHash, dagRead);\n    }\n  }\n  return commit;\n}\n\nexport function snapshotMetaParts(\n  c: Commit<SnapshotMetaDD31>,\n  clientID: ClientID,\n): [lastMutationID: number, cookie: FrozenCookie | FrozenJSONValue] {\n  const m = c.meta;\n  const lmid = m.lastMutationIDs[clientID] ?? 0;\n  return [lmid, m.cookieJSON];\n}\n\nexport function compareCookiesForSnapshots(\n  a: Commit<SnapshotMetaDD31>,\n  b: Commit<SnapshotMetaDD31>,\n): number {\n  return compareCookies(a.meta.cookieJSON, b.meta.cookieJSON);\n}\n\n/**\n * Returns all commits from the commit with fromCommitHash to its base snapshot,\n * inclusive of both. Resulting vector is in chain-head-first order (so snapshot\n * comes last).\n */\nexport async function commitChain(\n  fromCommitHash: Hash,\n  dagRead: Read,\n): Promise<Commit<Meta>[]> {\n  let commit = await commitFromHash(fromCommitHash, dagRead);\n  const commits = [];\n  while (!commitIsSnapshot(commit)) {\n    const {meta} = commit;\n    const {basisHash} = meta;\n    if (basisHash === null) {\n      throw new Error(`Commit ${commit.chunk.hash} has no basis`);\n    }\n    commits.push(commit);\n    commit = await commitFromHash(basisHash, dagRead);\n  }\n  commits.push(commit);\n  return commits;\n}\n\nexport async function commitFromHash(\n  hash: Hash,\n  dagRead: MustGetChunk,\n): Promise<Commit<Meta>> {\n  const chunk = await dagRead.mustGetChunk(hash);\n  return fromChunk(chunk);\n}\n\nexport async function commitFromHead(\n  name: string,\n  dagRead: Read,\n): Promise<Commit<Meta>> {\n  const hash = await mustGetHeadHash(name, dagRead);\n  return commitFromHash(hash, dagRead);\n}\n\nexport type LocalMetaDD31 = {\n  readonly type: MetaType.LocalDD31;\n  readonly basisHash: Hash;\n  readonly mutationID: number;\n  readonly mutatorName: string;\n  readonly mutatorArgsJSON: FrozenJSONValue;\n  readonly originalHash: Hash | null;\n  readonly timestamp: number;\n  readonly clientID: ClientID;\n  readonly baseSnapshotHash: Hash;\n};\n\nexport type LocalMeta = LocalMetaDD31;\n\nexport function assertLocalMetaDD31(\n  v: Record<string, unknown>,\n): asserts v is LocalMetaDD31 {\n  // type already asserted\n  assertString(v.clientID);\n  assertNumber(v.mutationID);\n  assertString(v.mutatorName);\n  if (!v.mutatorName) {\n    throw new Error('Missing mutator name');\n  }\n  assertJSONValue(v.mutatorArgsJSON);\n  if (v.originalHash !== null) {\n    assertHash(v.originalHash);\n  }\n  assertNumber(v.timestamp);\n}\n\nexport function isLocalMetaDD31(meta: Meta): meta is LocalMetaDD31 {\n  return meta.type === MetaType.LocalDD31;\n}\n\nexport function assertLocalCommitDD31(\n  c: Commit<Meta>,\n): asserts c is Commit<LocalMetaDD31> {\n  assertLocalMetaDD31(c.meta);\n}\n\nexport type SnapshotMetaDD31 = {\n  readonly type: MetaType.SnapshotDD31;\n  readonly basisHash: Hash | null;\n  readonly lastMutationIDs: Record<ClientID, number>;\n  readonly cookieJSON: FrozenCookie;\n};\n\nexport type SnapshotMeta = SnapshotMetaDD31;\n\nexport function assertSnapshotMetaDD31(\n  v: Record<string, unknown>,\n): asserts v is SnapshotMetaDD31 {\n  // type already asserted\n  if (v.basisHash !== null) {\n    assertHash(v.basisHash);\n  }\n  assertJSONValue(v.cookieJSON);\n  assertLastMutationIDs(v.lastMutationIDs);\n}\n\nfunction assertLastMutationIDs(\n  v: unknown,\n): asserts v is Record<ClientID, number> {\n  assertObject(v);\n  for (const e of Object.values(v)) {\n    assertNumber(e);\n  }\n}\n\nexport type Meta = LocalMetaDD31 | SnapshotMetaDD31;\n\nexport function assertSnapshotCommitDD31(\n  c: Commit<Meta>,\n): asserts c is Commit<SnapshotMetaDD31> {\n  assertSnapshotMetaDD31(c.meta);\n}\n\nfunction isSnapshotMetaDD31(meta: Meta): meta is SnapshotMetaDD31 {\n  return meta.type === MetaType.SnapshotDD31;\n}\n\nfunction assertMeta(v: unknown): asserts v is Meta {\n  assertObject(v);\n  assertDeepFrozen(v);\n  if (v.basisHash !== null) {\n    assertString(v.basisHash);\n  }\n\n  assertNumber(v.type);\n  switch (v.type) {\n    case MetaType.LocalDD31:\n      assertLocalMetaDD31(v);\n      break;\n    case MetaType.SnapshotDD31:\n      assertSnapshotMetaDD31(v);\n      break;\n    default:\n      throw new Error(`Invalid enum value ${v.type}`);\n  }\n}\n\n/**\n * This is the type used for index definitions as defined in the Commit chunk data.\n *\n * Changing this requires a REPLICACHE_FORMAT_VERSION bump.\n */\nexport type ChunkIndexDefinition = {\n  readonly name: string;\n  readonly keyPrefix: string;\n  readonly jsonPointer: string;\n  // Used to not exist\n  readonly allowEmpty?: boolean;\n};\n\nexport function chunkIndexDefinitionEqualIgnoreName(\n  a: ChunkIndexDefinition,\n  b: ChunkIndexDefinition,\n): boolean {\n  return (\n    a.jsonPointer === b.jsonPointer &&\n    (a.allowEmpty ?? false) === (b.allowEmpty ?? false) &&\n    a.keyPrefix === b.keyPrefix\n  );\n}\n\nfunction assertChunkIndexDefinition(\n  v: unknown,\n): asserts v is ChunkIndexDefinition {\n  assertObject(v);\n  assertDeepFrozen(v);\n  assertString(v.name);\n  assertString(v.keyPrefix);\n  assertString(v.jsonPointer);\n  if (v.allowEmpty !== undefined) {\n    assertBoolean(v.allowEmpty);\n  }\n}\n\nexport function toChunkIndexDefinition(\n  name: string,\n  indexDefinition: IndexDefinition,\n): Required<ChunkIndexDefinition> {\n  return {\n    name,\n    keyPrefix: indexDefinition.prefix ?? '',\n    jsonPointer: indexDefinition.jsonPointer,\n    allowEmpty: indexDefinition.allowEmpty ?? false,\n  };\n}\n\nexport type IndexRecord = {\n  readonly definition: ChunkIndexDefinition;\n  readonly valueHash: Hash;\n};\n\nfunction assertIndexRecord(v: unknown): asserts v is IndexRecord {\n  assertObject(v);\n  assertDeepFrozen(v);\n  assertChunkIndexDefinition(v.definition);\n  assertString(v.valueHash);\n}\n\nfunction assertIndexRecords(v: unknown): asserts v is IndexRecord[] {\n  assertArray(v);\n  assertDeepFrozen(v);\n  for (const ir of v) {\n    assertIndexRecord(ir);\n  }\n}\n\nexport function newLocalDD31(\n  createChunk: CreateChunk,\n  basisHash: Hash,\n  baseSnapshotHash: Hash,\n  mutationID: number,\n  mutatorName: string,\n  mutatorArgsJSON: FrozenJSONValue,\n  originalHash: Hash | null,\n  valueHash: Hash,\n  indexes: readonly IndexRecord[],\n  timestamp: number,\n  clientID: ClientID,\n): Commit<LocalMetaDD31> {\n  const meta: LocalMetaDD31 = {\n    type: MetaType.LocalDD31,\n    basisHash,\n    baseSnapshotHash,\n    mutationID,\n    mutatorName,\n    mutatorArgsJSON,\n    originalHash,\n    timestamp,\n    clientID,\n  };\n  return commitFromCommitData(\n    createChunk,\n    makeCommitData(meta, valueHash, indexes),\n  );\n}\n\nexport function newSnapshotDD31(\n  createChunk: CreateChunk,\n  basisHash: Hash | null,\n  lastMutationIDs: Record<ClientID, number>,\n  cookieJSON: FrozenCookie,\n  valueHash: Hash,\n  indexes: readonly IndexRecord[],\n): Commit<SnapshotMetaDD31> {\n  return commitFromCommitData(\n    createChunk,\n    newSnapshotCommitDataDD31(\n      basisHash,\n      lastMutationIDs,\n      cookieJSON,\n      valueHash,\n      indexes,\n    ),\n  );\n}\n\nexport function newSnapshotCommitDataDD31(\n  basisHash: Hash | null,\n  lastMutationIDs: Record<ClientID, number>,\n  cookieJSON: FrozenCookie,\n  valueHash: Hash,\n  indexes: readonly IndexRecord[],\n): CommitData<SnapshotMetaDD31> {\n  const meta: SnapshotMetaDD31 = {\n    type: MetaType.SnapshotDD31,\n    basisHash,\n    lastMutationIDs,\n    cookieJSON,\n  };\n  return makeCommitData(meta, valueHash, indexes);\n}\n\nexport function fromChunk(chunk: Chunk): Commit<Meta> {\n  validateChunk(chunk);\n  return new Commit(chunk);\n}\n\nfunction commitFromCommitData<M extends Meta>(\n  createChunk: CreateChunk,\n  data: CommitData<M>,\n): Commit<M> {\n  return new Commit(createChunk(data, getRefs(data)));\n}\n\nexport function getRefs(data: CommitData<Meta>): Refs {\n  const refs: Set<Hash> = new Set();\n  refs.add(data.valueHash);\n  const {meta} = data;\n  switch (meta.type) {\n    case MetaType.LocalDD31:\n      meta.basisHash && refs.add(meta.basisHash);\n      // Local has weak originalHash\n      break;\n    case MetaType.SnapshotDD31:\n      // Snapshot has weak basisHash\n      break;\n    default:\n      unreachable(meta);\n  }\n\n  for (const index of data.indexes) {\n    refs.add(index.valueHash);\n  }\n\n  return toRefs(refs);\n}\n\nexport type CommitData<M extends Meta> = FrozenTag<{\n  readonly meta: M;\n  readonly valueHash: Hash;\n  readonly indexes: readonly IndexRecord[];\n}>;\n\nexport function makeCommitData<M extends Meta>(\n  meta: M,\n  valueHash: Hash,\n  indexes: readonly IndexRecord[],\n): CommitData<M> {\n  return deepFreeze({\n    meta,\n    valueHash,\n    indexes,\n  }) as unknown as CommitData<M>;\n}\n\nexport function assertCommitData(v: unknown): asserts v is CommitData<Meta> {\n  if (skipCommitDataAsserts) {\n    return;\n  }\n\n  assertObject(v);\n  assertDeepFrozen(v);\n  assertMeta(v.meta);\n  assertString(v.valueHash);\n  assertIndexRecords(v.indexes);\n}\n\nfunction validateChunk(chunk: Chunk): asserts chunk is Chunk<CommitData<Meta>> {\n  const {data} = chunk;\n  assertCommitData(data);\n\n  const seen = new Set();\n  for (const index of data.indexes) {\n    const {name} = index.definition;\n    if (seen.has(name)) {\n      throw new Error(`Duplicate index ${name}`);\n    }\n    seen.add(name);\n  }\n}\n","/* eslint-disable @typescript-eslint/naming-convention */\n\nexport const Add = 0;\nexport const Remove = 1;\n\nexport type Add = typeof Add;\nexport type Remove = typeof Remove;\n","import type {LogContext} from '@rocicorp/logger';\nimport type {Enum} from '../../../shared/src/enum.ts';\nimport type {BTreeRead} from '../btree/read.ts';\nimport type {BTreeWrite} from '../btree/write.ts';\nimport type {FrozenJSONObject, FrozenJSONValue} from '../frozen-json.ts';\nimport type {Hash} from '../hash.ts';\nimport type {IndexRecord} from './commit.ts';\nimport * as IndexOperation from './index-operation-enum.ts';\n\ntype IndexOperation = Enum<typeof IndexOperation>;\n\nexport class IndexRead<BTree = BTreeRead> {\n  readonly meta: IndexRecord;\n  readonly map: BTree;\n\n  constructor(meta: IndexRecord, map: BTree) {\n    this.meta = meta;\n    this.map = map;\n  }\n}\n\nexport class IndexWrite extends IndexRead<BTreeWrite> {\n  // Note: does not update self.meta.valueHash (doesn't need to at this point as flush\n  // is only called during commit.)\n  flush(): Promise<Hash> {\n    return this.map.flush();\n  }\n\n  clear(): Promise<void> {\n    return this.map.clear();\n  }\n}\n\n// Index or de-index a single primary entry.\nexport async function indexValue(\n  lc: LogContext,\n  index: BTreeWrite,\n  op: IndexOperation,\n  key: string,\n  val: FrozenJSONValue,\n  jsonPointer: string,\n  allowEmpty: boolean,\n): Promise<void> {\n  try {\n    for (const entry of getIndexKeys(key, val, jsonPointer, allowEmpty)) {\n      switch (op) {\n        case IndexOperation.Add:\n          await index.put(entry, val);\n          break;\n        case IndexOperation.Remove:\n          await index.del(entry);\n          break;\n      }\n    }\n  } catch (e) {\n    // Right now all the errors that index_value() returns are customers dev\n    // problems: either the value is not json, the pointer is into nowhere, etc.\n    // So we ignore them.\n    lc.info?.('Not indexing value', val, ':', e);\n  }\n}\n\n// Gets the set of index keys for a given primary key and value.\nexport function getIndexKeys(\n  primary: string,\n  value: FrozenJSONValue,\n  jsonPointer: string,\n  allowEmpty: boolean,\n): string[] {\n  const target = evaluateJSONPointer(value, jsonPointer);\n  if (target === undefined) {\n    if (allowEmpty) {\n      return [];\n    }\n    throw new Error(`No value at path: ${jsonPointer}`);\n  }\n\n  const values = Array.isArray(target) ? target : [target];\n\n  const indexKeys: string[] = [];\n  for (const value of values) {\n    if (typeof value === 'string') {\n      indexKeys.push(encodeIndexKey([value, primary]));\n    } else {\n      throw new Error('Unsupported target type');\n    }\n  }\n\n  return indexKeys;\n}\n\nexport const KEY_VERSION_0 = '\\u0000';\nexport const KEY_SEPARATOR = '\\u0000';\n\n/**\n * When using indexes the key is a tuple of the secondary key and the primary\n * key.\n */\nexport type IndexKey = readonly [secondary: string, primary: string];\n\n// An index key is encoded to vec of bytes in the following order:\n//   - key version byte(s), followed by\n//   - the secondary key bytes (which for now is a UTF8 encoded string), followed by\n//   - the key separator, a null byte, followed by\n//   - the primary key bytes\n//\n// The null separator byte ensures that if a secondary key A is longer than B then\n// A always sorts after B. Appending the primary key ensures index keys with\n// identical secondary keys sort in primary key order. Secondary keys must not\n// contain a zero (null) byte.\nexport function encodeIndexKey(indexKey: IndexKey): string {\n  const secondary = indexKey[0];\n  const primary = indexKey[1];\n\n  if (secondary.includes('\\u0000')) {\n    throw new Error('Secondary key cannot contain null byte');\n  }\n  return KEY_VERSION_0 + secondary + KEY_SEPARATOR + primary;\n}\n\n// Returns bytes that can be used to scan for the given secondary index value.\n//\n// Consider a scan for start_secondary_key=\"a\" (97). We want to scan with scan\n// key [0, 97]. We could also scan with [0, 97, 0], but then we couldn't use\n// this function for prefix scans, so we lop off the null byte. If we want\n// the scan to be exclusive, we scan with the next greater value, [0, 97, 1]\n// (we disallow zero bytes in secondary keys).\n//\n// Now it gets a little tricky. We also want to be able to scan using the\n// primary key, start_key. When we do this we have to encode the scan key\n// a little differently We essentially have to fix the value of the\n// secondary key so we can vary the start_key. That is, the match on\n// start_secondary_key becomes an exact match.\n//\n// Consider the scan for start_secondary_key=\"a\" and start_key=[2]. We want\n// to scan with [0, 97, 0, 2]. If we want exclusive we want to scan with\n// the next highest value, [0, 97, 0, 2, 0] (zero bytes are allowed in primary\n// keys). So far so good. It is important to notice that we need to\n// be able to distinguish between not wanting use start_key and wanting to\n// use start_key=[]. In the former case we want to scan with the secondary\n// key value, possibly followed by a 1 with no trailing zero byte ([0, 97]\n// or [0, 97, 1]). In the latter case we want to scan by the secondary\n// key value, followed by the zero byte, followed by the primary key value\n// and another zero if it is exclusive ([0, 97, 0] or [0, 97, 0, 0]).\n// This explains why we need the Option around start_key.\nexport function encodeIndexScanKey(\n  secondary: string,\n  primary: string | undefined,\n): string {\n  const k = encodeIndexKey([secondary, primary || '']);\n  if (primary === undefined) {\n    return k.slice(0, k.length - 1);\n  }\n  return k;\n}\n\n// Decodes an IndexKey encoded by encode_index_key.\nexport function decodeIndexKey(encodedIndexKey: string): IndexKey {\n  if (encodedIndexKey[0] !== KEY_VERSION_0) {\n    throw new Error('Invalid version');\n  }\n\n  const versionLen = KEY_VERSION_0.length;\n  const separatorLen = KEY_SEPARATOR.length;\n  const separatorOffset = encodedIndexKey.indexOf(KEY_SEPARATOR, versionLen);\n  if (separatorOffset === -1) {\n    throw new Error('Invalid formatting');\n  }\n\n  const secondary = encodedIndexKey.slice(versionLen, separatorOffset);\n  const primary = encodedIndexKey.slice(separatorOffset + separatorLen);\n  return [secondary, primary];\n}\n\nexport function evaluateJSONPointer(\n  value: FrozenJSONValue,\n  pointer: string,\n): FrozenJSONValue | undefined {\n  function parseIndex(s: string): number | undefined {\n    if (s.startsWith('+') || (s.startsWith('0') && s.length !== 1)) {\n      return undefined;\n    }\n    return parseInt(s, 10);\n  }\n\n  if (pointer === '') {\n    return value;\n  }\n  if (!pointer.startsWith('/')) {\n    throw new Error(`Invalid JSON pointer: ${pointer}`);\n  }\n\n  const tokens = pointer\n    .split('/')\n    .slice(1)\n    .map(x => x.replace(/~1/g, '/').replace(/~0/g, '~'));\n\n  let target = value;\n  for (const token of tokens) {\n    let targetOpt;\n    if (Array.isArray(target)) {\n      const i = parseIndex(token);\n      if (i === undefined) {\n        return undefined;\n      }\n      targetOpt = target[i];\n    } else if (target === null) {\n      return undefined;\n    } else if (typeof target === 'object') {\n      target = target as FrozenJSONObject;\n      targetOpt = target[token];\n    }\n    if (targetOpt === undefined) {\n      return undefined;\n    }\n    target = targetOpt;\n  }\n  return target;\n}\n","import type {Enum} from '../../../shared/src/enum.ts';\nimport {BTreeRead} from '../btree/read.ts';\nimport type {Read as DagRead} from '../dag/store.ts';\nimport * as FormatVersion from '../format-version-enum.ts';\nimport type {FrozenJSONValue} from '../frozen-json.ts';\nimport type {Hash} from '../hash.ts';\nimport {\n  Commit,\n  DEFAULT_HEAD_NAME,\n  type Meta,\n  commitFromHash,\n  commitFromHead,\n} from './commit.ts';\nimport {IndexRead} from './index.ts';\n\ntype FormatVersion = Enum<typeof FormatVersion>;\n\nexport class Read {\n  readonly #dagRead: DagRead;\n  map: BTreeRead;\n  readonly indexes: Map<string, IndexRead>;\n\n  constructor(\n    dagRead: DagRead,\n    map: BTreeRead,\n    indexes: Map<string, IndexRead>,\n  ) {\n    this.#dagRead = dagRead;\n    this.map = map;\n    this.indexes = indexes;\n  }\n\n  has(key: string): Promise<boolean> {\n    return this.map.has(key);\n  }\n\n  get(key: string): Promise<FrozenJSONValue | undefined> {\n    return this.map.get(key);\n  }\n\n  isEmpty(): Promise<boolean> {\n    return this.map.isEmpty();\n  }\n\n  getMapForIndex(indexName: string): BTreeRead {\n    const idx = this.indexes.get(indexName);\n    if (idx === undefined) {\n      throw new Error(`Unknown index name: ${indexName}`);\n    }\n    return idx.map;\n  }\n\n  get closed(): boolean {\n    return this.#dagRead.closed;\n  }\n\n  close(): void {\n    this.#dagRead.release();\n  }\n}\n\nexport function readFromDefaultHead(\n  dagRead: DagRead,\n  formatVersion: FormatVersion,\n): Promise<Read> {\n  return readFromHead(DEFAULT_HEAD_NAME, dagRead, formatVersion);\n}\n\nexport async function readFromHead(\n  name: string,\n  dagRead: DagRead,\n  formatVersion: FormatVersion,\n): Promise<Read> {\n  const commit = await commitFromHead(name, dagRead);\n  return readFromCommit(commit, dagRead, formatVersion);\n}\n\nexport async function readFromHash(\n  hash: Hash,\n  dagRead: DagRead,\n  formatVersion: FormatVersion,\n): Promise<Read> {\n  const commit = await commitFromHash(hash, dagRead);\n  return readFromCommit(commit, dagRead, formatVersion);\n}\n\nfunction readFromCommit(\n  commit: Commit<Meta>,\n  dagRead: DagRead,\n  formatVersion: FormatVersion,\n): Read {\n  const indexes = readIndexesForRead(commit, dagRead, formatVersion);\n  const map = new BTreeRead(dagRead, formatVersion, commit.valueHash);\n  return new Read(dagRead, map, indexes);\n}\n\nexport function readIndexesForRead(\n  commit: Commit<Meta>,\n  dagRead: DagRead,\n  formatVersion: FormatVersion,\n): Map<string, IndexRead> {\n  const m = new Map();\n  for (const index of commit.indexes) {\n    m.set(\n      index.definition.name,\n      new IndexRead(\n        index,\n        new BTreeRead(dagRead, formatVersion, index.valueHash),\n      ),\n    );\n  }\n  return m;\n}\n","export async function asyncIterableToArray<T>(\n  it: AsyncIterable<T>,\n): Promise<T[]> {\n  const arr: T[] = [];\n  for await (const v of it) {\n    arr.push(v);\n  }\n  return arr;\n}\n","import {asyncIterableToArray} from '../async-iterable-to-array.ts';\nimport type {InternalDiff} from './node.ts';\nimport type {BTreeRead} from './read.ts';\n\nexport function diff(\n  oldMap: BTreeRead,\n  newMap: BTreeRead,\n): Promise<InternalDiff> {\n  // Return an array to ensure we do not compute the diff more than once.\n  return asyncIterableToArray(newMap.diff(oldMap));\n}\n","import {Lock} from '@rocicorp/lock';\nimport {assert} from '../../../shared/src/asserts.ts';\nimport type {Enum} from '../../../shared/src/enum.ts';\nimport type {ReadonlyJSONValue} from '../../../shared/src/json.ts';\nimport {type Chunk, type CreateChunk, toRefs} from '../dag/chunk.ts';\nimport type {Write} from '../dag/store.ts';\nimport * as FormatVersion from '../format-version-enum.ts';\nimport type {FrozenJSONValue} from '../frozen-json.ts';\nimport {type Hash, emptyHash, newRandomHash} from '../hash.ts';\nimport {getSizeOfEntry} from '../size-of-value.ts';\nimport {\n  DataNodeImpl,\n  type Entry,\n  InternalNodeImpl,\n  createNewInternalEntryForNode,\n  emptyDataNode,\n  isDataNodeImpl,\n  newNodeImpl,\n  partition,\n  toChunkData,\n} from './node.ts';\nimport {BTreeRead} from './read.ts';\n\ntype FormatVersion = Enum<typeof FormatVersion>;\n\nexport class BTreeWrite extends BTreeRead {\n  /**\n   * This rw lock is used to ensure we do not mutate the btree in parallel. It\n   * would be a problem if we didn't have the lock in cases like this:\n   *\n   * ```ts\n   * const p1 = tree.put('a', 0);\n   * const p2 = tree.put('b', 1);\n   * await p1;\n   * await p2;\n   * ```\n   *\n   * because both `p1` and `p2` would start from the old root hash but a put\n   * changes the root hash so the two concurrent puts would lead to only one of\n   * them actually working, and it is not deterministic which one would finish\n   * last.\n   */\n  readonly #lock = new Lock();\n  readonly #modified: Map<Hash, DataNodeImpl | InternalNodeImpl> = new Map();\n\n  declare protected _dagRead: Write;\n\n  readonly minSize: number;\n  readonly maxSize: number;\n\n  constructor(\n    dagWrite: Write,\n    formatVersion: FormatVersion,\n    root: Hash = emptyHash,\n    minSize = 8 * 1024,\n    maxSize = 16 * 1024,\n    getEntrySize: <K, V>(k: K, v: V) => number = getSizeOfEntry,\n    chunkHeaderSize?: number,\n  ) {\n    super(dagWrite, formatVersion, root, getEntrySize, chunkHeaderSize);\n\n    this.minSize = minSize;\n    this.maxSize = maxSize;\n  }\n\n  #addToModified(node: DataNodeImpl | InternalNodeImpl): void {\n    assert(node.isMutable);\n    this.#modified.set(node.hash, node);\n    this._cache.set(node.hash, node);\n  }\n\n  updateNode(node: DataNodeImpl | InternalNodeImpl): void {\n    assert(node.isMutable);\n    this.#modified.delete(node.hash);\n    node.hash = newRandomHash();\n    this.#addToModified(node);\n  }\n\n  newInternalNodeImpl(\n    entries: Array<Entry<Hash>>,\n    level: number,\n  ): InternalNodeImpl {\n    const n = new InternalNodeImpl(entries, newRandomHash(), level, true);\n    this.#addToModified(n);\n    return n;\n  }\n\n  newDataNodeImpl(entries: Entry<FrozenJSONValue>[]): DataNodeImpl {\n    const n = new DataNodeImpl(entries, newRandomHash(), true);\n    this.#addToModified(n);\n    return n;\n  }\n\n  newNodeImpl(entries: Entry<FrozenJSONValue>[], level: number): DataNodeImpl;\n  newNodeImpl(entries: Entry<Hash>[], level: number): InternalNodeImpl;\n  newNodeImpl(\n    entries: Entry<Hash>[] | Entry<FrozenJSONValue>[],\n    level: number,\n  ): InternalNodeImpl | DataNodeImpl;\n  newNodeImpl(\n    entries: Entry<Hash>[] | Entry<FrozenJSONValue>[],\n    level: number,\n  ): InternalNodeImpl | DataNodeImpl {\n    const n = newNodeImpl(entries, newRandomHash(), level, true);\n    this.#addToModified(n);\n    return n;\n  }\n\n  put(key: string, value: FrozenJSONValue): Promise<void> {\n    return this.#lock.withLock(async () => {\n      const oldRootNode = await this.getNode(this.rootHash);\n      const entrySize = this.getEntrySize(key, value);\n      const rootNode = await oldRootNode.set(key, value, entrySize, this);\n\n      // We do the rebalancing in the parent so we need to do it here as well.\n      if (rootNode.getChildNodeSize(this) > this.maxSize) {\n        const headerSize = this.chunkHeaderSize;\n        const partitions = partition(\n          rootNode.entries,\n          value => value[2],\n          this.minSize - headerSize,\n          this.maxSize - headerSize,\n        );\n        const {level} = rootNode;\n        const entries: Entry<Hash>[] = partitions.map(entries => {\n          const node = this.newNodeImpl(entries, level);\n          return createNewInternalEntryForNode(node, this.getEntrySize);\n        });\n        const newRoot = this.newInternalNodeImpl(entries, level + 1);\n        this.rootHash = newRoot.hash;\n        return;\n      }\n\n      this.rootHash = rootNode.hash;\n    });\n  }\n\n  del(key: string): Promise<boolean> {\n    return this.#lock.withLock(async () => {\n      const oldRootNode = await this.getNode(this.rootHash);\n      const newRootNode = await oldRootNode.del(key, this);\n\n      // No need to rebalance here since if root gets too small there is nothing\n      // we can do about that.\n      const found = this.rootHash !== newRootNode.hash;\n      if (found) {\n        // Flatten one layer.\n        if (newRootNode.level > 0 && newRootNode.entries.length === 1) {\n          this.rootHash = (newRootNode as InternalNodeImpl).entries[0][1];\n        } else {\n          this.rootHash = newRootNode.hash;\n        }\n      }\n\n      return found;\n    });\n  }\n\n  clear(): Promise<void> {\n    return this.#lock.withLock(() => {\n      this.#modified.clear();\n      this.rootHash = emptyHash;\n    });\n  }\n\n  flush(): Promise<Hash> {\n    return this.#lock.withLock(async () => {\n      const dagWrite = this._dagRead;\n\n      if (this.rootHash === emptyHash) {\n        // Write a chunk for the empty tree.\n        const chunk = dagWrite.createChunk(emptyDataNode, []);\n        await dagWrite.putChunk(chunk as Chunk<ReadonlyJSONValue>);\n        return chunk.hash;\n      }\n\n      const newChunks: Chunk[] = [];\n      const newRoot = gatherNewChunks(\n        this.rootHash,\n        newChunks,\n        dagWrite.createChunk,\n        this.#modified,\n        this._formatVersion,\n      );\n      await Promise.all(newChunks.map(chunk => dagWrite.putChunk(chunk)));\n      this.#modified.clear();\n      this.rootHash = newRoot;\n      return newRoot;\n    });\n  }\n}\n\nfunction gatherNewChunks(\n  hash: Hash,\n  newChunks: Chunk[],\n  createChunk: CreateChunk,\n  modified: Map<Hash, DataNodeImpl | InternalNodeImpl>,\n  formatVersion: FormatVersion,\n): Hash {\n  const node = modified.get(hash);\n  if (node === undefined) {\n    // Not modified, use the original.\n    return hash;\n  }\n\n  if (isDataNodeImpl(node)) {\n    const chunk = createChunk(toChunkData(node, formatVersion), []);\n    newChunks.push(chunk);\n    return chunk.hash;\n  }\n\n  // The BTree cannot have duplicate keys so the child entry hashes are unique.\n  // No need fot a set to dedupe here.\n  const refs: Hash[] = [];\n  const {entries} = node;\n  for (let i = 0; i < entries.length; i++) {\n    const entry = entries[i];\n    const childHash = entry[1];\n    const newChildHash = gatherNewChunks(\n      childHash,\n      newChunks,\n      createChunk,\n      modified,\n      formatVersion,\n    );\n    if (newChildHash !== childHash) {\n      // MUTATES the entries!\n      // Hashes do not change the size of the entry because all hashes have the same length\n      entries[i] = [entry[0], newChildHash, entry[2]];\n    }\n    refs.push(newChildHash);\n  }\n  const chunk = createChunk(toChunkData(node, formatVersion), toRefs(refs));\n  newChunks.push(chunk);\n  return chunk.hash;\n}\n","export function lazy<T>(factory: () => T): () => T {\n  let value: T | undefined;\n  return () => {\n    if (value === undefined) {\n      value = factory();\n    }\n    return value;\n  };\n}\n","import {assert} from '../../../shared/src/asserts.ts';\nimport type {Enum} from '../../../shared/src/enum.ts';\nimport {diff as btreeDiff} from '../btree/diff.ts';\nimport type {InternalDiff} from '../btree/node.ts';\nimport {allEntriesAsDiff, BTreeRead} from '../btree/read.ts';\nimport type {Read} from '../dag/store.ts';\nimport {Commit, commitFromHash, type Meta} from '../db/commit.ts';\nimport {readIndexesForRead} from '../db/read.ts';\nimport * as FormatVersion from '../format-version-enum.ts';\nimport type {Hash} from '../hash.ts';\n\ntype FormatVersion = Enum<typeof FormatVersion>;\n\n/**\n * Interface allowing different diff functions to skip costly diff computations.\n */\nexport interface DiffComputationConfig {\n  shouldComputeDiffs(): boolean;\n  shouldComputeDiffsForIndex(name: string): boolean;\n}\n\n/**\n * The diffs in different indexes. The key of the map is the index name.\n * \"\" is used for the primary index.\n */\nexport class DiffsMap extends Map<string, InternalDiff> {\n  override set(key: string, value: InternalDiff): this {\n    if (value.length === 0) {\n      return this;\n    }\n    return super.set(key, value);\n  }\n}\n\n/**\n * Diffs the state of the db at two different hashes.\n * It will include the primary indexes as well as all the secondary indexes.\n */\nexport async function diff(\n  oldHash: Hash,\n  newHash: Hash,\n  read: Read,\n  diffConfig: DiffComputationConfig,\n  formatVersion: FormatVersion,\n): Promise<DiffsMap> {\n  const [oldCommit, newCommit] = await Promise.all([\n    commitFromHash(oldHash, read),\n    commitFromHash(newHash, read),\n  ]);\n\n  return diffCommits(oldCommit, newCommit, read, diffConfig, formatVersion);\n}\n\n/**\n * Diffs the state of the db at two different commits.\n * It will include the primary indexes as well as all the secondary indexes.\n */\n// TODO: this should probably move to db/\nexport async function diffCommits(\n  oldCommit: Commit<Meta>,\n  newCommit: Commit<Meta>,\n  read: Read,\n  diffConfig: DiffComputationConfig,\n  formatVersion: FormatVersion,\n): Promise<DiffsMap> {\n  const diffsMap = new DiffsMap();\n  if (!diffConfig.shouldComputeDiffs()) {\n    return diffsMap;\n  }\n\n  const oldMap = new BTreeRead(read, formatVersion, oldCommit.valueHash);\n  const newMap = new BTreeRead(read, formatVersion, newCommit.valueHash);\n  const valueDiff = await btreeDiff(oldMap, newMap);\n  diffsMap.set('', valueDiff);\n\n  await addDiffsForIndexes(\n    oldCommit,\n    newCommit,\n    read,\n    diffsMap,\n    diffConfig,\n    formatVersion,\n  );\n\n  return diffsMap;\n}\n\nexport async function addDiffsForIndexes(\n  mainCommit: Commit<Meta>,\n  syncCommit: Commit<Meta>,\n  read: Read,\n  diffsMap: DiffsMap,\n  diffConfig: DiffComputationConfig,\n  formatVersion: FormatVersion,\n) {\n  const oldIndexes = readIndexesForRead(mainCommit, read, formatVersion);\n  const newIndexes = readIndexesForRead(syncCommit, read, formatVersion);\n\n  for (const [oldIndexName, oldIndex] of oldIndexes) {\n    if (!diffConfig.shouldComputeDiffsForIndex(oldIndexName)) {\n      continue;\n    }\n\n    const newIndex = newIndexes.get(oldIndexName);\n    if (newIndex !== undefined) {\n      assert(newIndex !== oldIndex);\n      const diffs = await btreeDiff(oldIndex.map, newIndex.map);\n      newIndexes.delete(oldIndexName);\n      diffsMap.set(oldIndexName, diffs);\n    } else {\n      // old index name is not in the new indexes. All entries removed!\n      const diffs = await allEntriesAsDiff(oldIndex.map, 'del');\n      diffsMap.set(oldIndexName, diffs);\n    }\n  }\n\n  for (const [newIndexName, newIndex] of newIndexes) {\n    if (!diffConfig.shouldComputeDiffsForIndex(newIndexName)) {\n      continue;\n    }\n    // new index name is not in the old indexes. All keys added!\n    const diffs = await allEntriesAsDiff(newIndex.map, 'add');\n    diffsMap.set(newIndexName, diffs);\n  }\n}\n","import type {LogContext} from '@rocicorp/logger';\nimport {assert} from '../../../shared/src/asserts.ts';\nimport type {Enum} from '../../../shared/src/enum.ts';\nimport {diff} from '../btree/diff.ts';\nimport type {InternalDiff} from '../btree/node.ts';\nimport {BTreeRead, allEntriesAsDiff} from '../btree/read.ts';\nimport {BTreeWrite} from '../btree/write.ts';\nimport type {FrozenCookie} from '../cookies.ts';\nimport type {Write as DagWrite} from '../dag/store.ts';\nimport * as FormatVersion from '../format-version-enum.ts';\nimport type {FrozenJSONValue} from '../frozen-json.ts';\nimport {type Hash, emptyHash} from '../hash.ts';\nimport {lazy} from '../lazy.ts';\nimport type {DiffComputationConfig} from '../sync/diff.ts';\nimport {DiffsMap} from '../sync/diff.ts';\nimport type {ClientID} from '../sync/ids.ts';\nimport {\n  Commit,\n  type Meta as CommitMeta,\n  type IndexRecord,\n  type Meta,\n  baseSnapshotHashFromHash,\n  commitFromHash,\n  newLocalDD31 as commitNewLocalDD31,\n  newSnapshotDD31 as commitNewSnapshotDD31,\n  getMutationID,\n} from './commit.ts';\nimport * as IndexOperation from './index-operation-enum.ts';\nimport {IndexRead, IndexWrite, indexValue} from './index.ts';\nimport * as MetaType from './meta-type-enum.ts';\nimport {Read, readIndexesForRead} from './read.ts';\n\ntype FormatVersion = Enum<typeof FormatVersion>;\n\nexport class Write extends Read {\n  readonly #dagWrite: DagWrite;\n  readonly #basis: Commit<CommitMeta> | undefined;\n  readonly #meta: CommitMeta;\n\n  declare map: BTreeWrite;\n\n  declare readonly indexes: Map<string, IndexWrite>;\n  readonly #clientID: ClientID;\n  readonly #formatVersion: FormatVersion;\n\n  constructor(\n    dagWrite: DagWrite,\n    map: BTreeWrite,\n    basis: Commit<CommitMeta> | undefined,\n    meta: CommitMeta,\n    indexes: Map<string, IndexWrite>,\n    clientID: ClientID,\n    formatVersion: FormatVersion,\n  ) {\n    // TypeScript has trouble\n    super(dagWrite, map, indexes);\n    this.#dagWrite = dagWrite;\n    this.#basis = basis;\n    this.#meta = meta;\n    this.#clientID = clientID;\n    this.#formatVersion = formatVersion;\n\n    // TODO(arv): if (DEBUG) { ...\n    if (basis === undefined) {\n      assert(meta.basisHash === emptyHash);\n    } else {\n      assert(meta.basisHash === basis.chunk.hash);\n    }\n  }\n\n  /**\n   * The value needs to be frozen since it is kept in memory and used later for\n   * comparison as well as returned in `get`.\n   */\n  async put(\n    lc: LogContext,\n    key: string,\n    value: FrozenJSONValue,\n  ): Promise<void> {\n    const oldVal = lazy(() => this.map.get(key));\n    await updateIndexes(lc, this.indexes, key, oldVal, value);\n\n    await this.map.put(key, value);\n  }\n\n  getMutationID(): Promise<number> {\n    return getMutationID(this.#clientID, this.#dagWrite, this.#meta);\n  }\n\n  async del(lc: LogContext, key: string): Promise<boolean> {\n    // TODO(arv): This does the binary search twice. We can do better.\n    const oldVal = lazy(() => this.map.get(key));\n    if (oldVal !== undefined) {\n      await updateIndexes(lc, this.indexes, key, oldVal, undefined);\n    }\n    return this.map.del(key);\n  }\n\n  async clear(): Promise<void> {\n    await this.map.clear();\n    const ps = [];\n    for (const idx of this.indexes.values()) {\n      ps.push(idx.clear());\n    }\n    await Promise.all(ps);\n  }\n\n  async putCommit(): Promise<Commit<CommitMeta>> {\n    const valueHash = await this.map.flush();\n    const indexRecords: IndexRecord[] = [];\n\n    for (const index of this.indexes.values()) {\n      const valueHash = await index.flush();\n      const indexRecord: IndexRecord = {\n        definition: index.meta.definition,\n        valueHash,\n      };\n      indexRecords.push(indexRecord);\n    }\n\n    let commit: Commit<Meta>;\n    const meta = this.#meta;\n    switch (meta.type) {\n      case MetaType.LocalDD31: {\n        assert(this.#formatVersion >= FormatVersion.DD31);\n        const {\n          basisHash,\n          mutationID,\n          mutatorName,\n          mutatorArgsJSON,\n          originalHash,\n          timestamp,\n        } = meta;\n        commit = commitNewLocalDD31(\n          this.#dagWrite.createChunk,\n          basisHash,\n          await baseSnapshotHashFromHash(basisHash, this.#dagWrite),\n          mutationID,\n          mutatorName,\n          mutatorArgsJSON,\n          originalHash,\n          valueHash,\n          indexRecords,\n          timestamp,\n          this.#clientID,\n        );\n        break;\n      }\n\n      case MetaType.SnapshotDD31: {\n        assert(this.#formatVersion > FormatVersion.DD31);\n        const {basisHash, lastMutationIDs, cookieJSON} = meta;\n        commit = commitNewSnapshotDD31(\n          this.#dagWrite.createChunk,\n          basisHash,\n          lastMutationIDs,\n          cookieJSON,\n          valueHash,\n          indexRecords,\n        );\n        break;\n      }\n    }\n    await this.#dagWrite.putChunk(commit.chunk);\n    return commit;\n  }\n\n  // Return value is the hash of the new commit.\n  async commit(headName: string): Promise<Hash> {\n    const commit = await this.putCommit();\n    const commitHash = commit.chunk.hash;\n    await this.#dagWrite.setHead(headName, commitHash);\n    await this.#dagWrite.commit();\n    return commitHash;\n  }\n\n  async commitWithDiffs(\n    headName: string,\n    diffConfig: DiffComputationConfig,\n  ): Promise<[Hash, DiffsMap]> {\n    const commit = this.putCommit();\n    const diffMap = await this.#generateDiffs(diffConfig);\n    const commitHash = (await commit).chunk.hash;\n    await this.#dagWrite.setHead(headName, commitHash);\n    await this.#dagWrite.commit();\n    return [commitHash, diffMap];\n  }\n\n  async #generateDiffs(diffConfig: DiffComputationConfig): Promise<DiffsMap> {\n    const diffsMap = new DiffsMap();\n    if (!diffConfig.shouldComputeDiffs()) {\n      return diffsMap;\n    }\n\n    let valueDiff: InternalDiff = [];\n    if (this.#basis) {\n      const basisMap = new BTreeRead(\n        this.#dagWrite,\n        this.#formatVersion,\n        this.#basis.valueHash,\n      );\n      valueDiff = await diff(basisMap, this.map);\n    }\n    diffsMap.set('', valueDiff);\n    let basisIndexes: Map<string, IndexRead>;\n    if (this.#basis) {\n      basisIndexes = readIndexesForRead(\n        this.#basis,\n        this.#dagWrite,\n        this.#formatVersion,\n      );\n    } else {\n      basisIndexes = new Map();\n    }\n\n    for (const [name, index] of this.indexes) {\n      if (!diffConfig.shouldComputeDiffsForIndex(name)) {\n        continue;\n      }\n      const basisIndex = basisIndexes.get(name);\n      assert(index !== basisIndex);\n\n      const indexDiffResult = await (basisIndex\n        ? diff(basisIndex.map, index.map)\n        : // No basis. All keys are new.\n          allEntriesAsDiff(index.map, 'add'));\n      diffsMap.set(name, indexDiffResult);\n    }\n\n    // Handle indexes in basisIndex but not in this.indexes. All keys are\n    // deleted.\n    for (const [name, basisIndex] of basisIndexes) {\n      if (\n        !this.indexes.has(name) &&\n        diffConfig.shouldComputeDiffsForIndex(name)\n      ) {\n        const indexDiffResult = await allEntriesAsDiff(basisIndex.map, 'del');\n        diffsMap.set(name, indexDiffResult);\n      }\n    }\n    return diffsMap;\n  }\n\n  close(): void {\n    this.#dagWrite.release();\n  }\n}\n\nexport async function newWriteLocal(\n  basisHash: Hash,\n  mutatorName: string,\n  mutatorArgsJSON: FrozenJSONValue,\n  originalHash: Hash | null,\n  dagWrite: DagWrite,\n  timestamp: number,\n  clientID: ClientID,\n  formatVersion: FormatVersion,\n): Promise<Write> {\n  const basis = await commitFromHash(basisHash, dagWrite);\n  const bTreeWrite = new BTreeWrite(dagWrite, formatVersion, basis.valueHash);\n  const mutationID = await basis.getNextMutationID(clientID, dagWrite);\n  const indexes = readIndexesForWrite(basis, dagWrite, formatVersion);\n  assert(formatVersion >= FormatVersion.DD31);\n  return new Write(\n    dagWrite,\n    bTreeWrite,\n    basis,\n\n    {\n      type: MetaType.LocalDD31,\n      basisHash,\n      baseSnapshotHash: await baseSnapshotHashFromHash(basisHash, dagWrite),\n      mutatorName,\n      mutatorArgsJSON,\n      mutationID,\n      originalHash,\n      timestamp,\n      clientID,\n    },\n    indexes,\n    clientID,\n    formatVersion,\n  );\n}\n\nexport async function newWriteSnapshotDD31(\n  basisHash: Hash,\n  lastMutationIDs: Record<ClientID, number>,\n  cookieJSON: FrozenCookie,\n  dagWrite: DagWrite,\n  clientID: ClientID,\n  formatVersion: FormatVersion,\n): Promise<Write> {\n  const basis = await commitFromHash(basisHash, dagWrite);\n  const bTreeWrite = new BTreeWrite(dagWrite, formatVersion, basis.valueHash);\n  return new Write(\n    dagWrite,\n    bTreeWrite,\n    basis,\n    {basisHash, type: MetaType.SnapshotDD31, lastMutationIDs, cookieJSON},\n    readIndexesForWrite(basis, dagWrite, formatVersion),\n    clientID,\n    formatVersion,\n  );\n}\n\nexport async function updateIndexes(\n  lc: LogContext,\n  indexes: Map<string, IndexWrite>,\n  key: string,\n  oldValGetter: () => Promise<FrozenJSONValue | undefined>,\n  newVal: FrozenJSONValue | undefined,\n): Promise<void> {\n  const ps: Promise<void>[] = [];\n  for (const idx of indexes.values()) {\n    const {keyPrefix} = idx.meta.definition;\n    if (!keyPrefix || key.startsWith(keyPrefix)) {\n      const oldVal = await oldValGetter();\n      if (oldVal !== undefined) {\n        ps.push(\n          indexValue(\n            lc,\n            idx.map,\n            IndexOperation.Remove,\n            key,\n            oldVal,\n            idx.meta.definition.jsonPointer,\n            idx.meta.definition.allowEmpty ?? false,\n          ),\n        );\n      }\n      if (newVal !== undefined) {\n        ps.push(\n          indexValue(\n            lc,\n            idx.map,\n            IndexOperation.Add,\n            key,\n            newVal,\n            idx.meta.definition.jsonPointer,\n            idx.meta.definition.allowEmpty ?? false,\n          ),\n        );\n      }\n    }\n  }\n  await Promise.all(ps);\n}\n\nexport function readIndexesForWrite(\n  commit: Commit<CommitMeta>,\n  dagWrite: DagWrite,\n  formatVersion: FormatVersion,\n): Map<string, IndexWrite> {\n  const m = new Map();\n  for (const index of commit.indexes) {\n    m.set(\n      index.definition.name,\n      new IndexWrite(\n        index,\n        new BTreeWrite(dagWrite, formatVersion, index.valueHash),\n      ),\n    );\n  }\n  return m;\n}\n\nexport async function createIndexBTree(\n  lc: LogContext,\n  dagWrite: DagWrite,\n  valueMap: BTreeRead,\n  prefix: string,\n  jsonPointer: string,\n  allowEmpty: boolean,\n  formatVersion: FormatVersion,\n): Promise<BTreeWrite> {\n  const indexMap = new BTreeWrite(dagWrite, formatVersion);\n  for await (const entry of valueMap.scan(prefix)) {\n    const key = entry[0];\n    if (!key.startsWith(prefix)) {\n      break;\n    }\n    await indexValue(\n      lc,\n      indexMap,\n      IndexOperation.Add,\n      key,\n      entry[1],\n      jsonPointer,\n      allowEmpty,\n    );\n  }\n  return indexMap;\n}\n","import * as valita from '../../../shared/src/valita.ts';\n\n/**\n * The ID describing a group of clients. All clients in the same group share a\n * persistent storage (IDB).\n */\nexport type ClientGroupID = string;\n\nexport const clientGroupIDSchema: valita.Type<ClientGroupID> = valita.string();\n\n/**\n * The ID describing a client.\n */\nexport type ClientID = string;\n\nexport const clientIDSchema: valita.Type<ClientID> = valita.string();\n","import {randomUint64} from '../../../shared/src/random-uint64.ts';\n\n/**\n * Returns a random 18 character string encoded in base32 suitable as a client\n * ID.\n */\nexport function makeClientID(): string {\n  const length = 18;\n  const high = randomUint64();\n  const low = randomUint64();\n  const combined = (high << 64n) | low;\n  return combined.toString(32).slice(-length).padStart(length, '0');\n}\n","import type {LogContext} from '@rocicorp/logger';\nimport {assert, assertObject} from '../../../shared/src/asserts.ts';\nimport type {Enum} from '../../../shared/src/enum.ts';\nimport {hasOwn} from '../../../shared/src/has-own.ts';\nimport * as valita from '../../../shared/src/valita.ts';\nimport {emptyDataNode} from '../btree/node.ts';\nimport {BTreeRead} from '../btree/read.ts';\nimport {type FrozenCookie, compareCookies} from '../cookies.ts';\nimport {type Refs, toRefs} from '../dag/chunk.ts';\nimport type {Read, Store, Write} from '../dag/store.ts';\nimport {\n  type ChunkIndexDefinition,\n  Commit,\n  type IndexRecord,\n  type SnapshotMetaDD31,\n  assertSnapshotCommitDD31,\n  baseSnapshotFromHash,\n  chunkIndexDefinitionEqualIgnoreName,\n  getRefs,\n  newSnapshotCommitDataDD31,\n  toChunkIndexDefinition,\n} from '../db/commit.ts';\nimport {createIndexBTree} from '../db/write.ts';\nimport * as FormatVersion from '../format-version-enum.ts';\nimport {type FrozenJSONValue, deepFreeze} from '../frozen-json.ts';\nimport {type Hash, hashSchema} from '../hash.ts';\nimport {type IndexDefinitions, indexDefinitionsEqual} from '../index-defs.ts';\nimport {\n  type ClientGroupID,\n  type ClientID,\n  clientGroupIDSchema,\n} from '../sync/ids.ts';\nimport {withWrite} from '../with-transactions.ts';\nimport {\n  type ClientGroup,\n  getClientGroup,\n  getClientGroups,\n  mutatorNamesEqual,\n  setClientGroup,\n} from './client-groups.ts';\nimport {makeClientID} from './make-client-id.ts';\n\ntype FormatVersion = Enum<typeof FormatVersion>;\n\nexport type ClientMap = ReadonlyMap<ClientID, ClientV5 | ClientV6>;\n\nconst clientV5Schema = valita.readonlyObject({\n  heartbeatTimestampMs: valita.number(),\n\n  headHash: hashSchema,\n\n  /**\n   * The hash of a commit we are in the middle of refreshing into this client's\n   * memdag.\n   */\n  tempRefreshHash: hashSchema.nullable(),\n\n  /**\n   * ID of this client's perdag client group. This needs to be sent in pull\n   * request (to enable syncing all last mutation ids in the client group).\n   */\n  clientGroupID: clientGroupIDSchema,\n});\n\nexport type ClientV5 = valita.Infer<typeof clientV5Schema>;\n\nconst clientV6Schema = valita.readonlyObject({\n  heartbeatTimestampMs: valita.number(),\n\n  /**\n   * A set of hashes, which contains:\n   * 1. The hash of the last commit this client refreshed from its client group\n   *    (this is the commit it bootstrapped from until it completes its first\n   *    refresh).\n   * 2. One or more hashes that were added to retain chunks of a commit while it\n   *    was being refreshed into this client's memdag. (This can be one or more\n   *    because refresh's cleanup step is a separate transaction and can fail).\n   * Upon refresh completing and successfully running its clean up step, this\n   * set will contain a single hash: the hash of the last commit this client\n   * refreshed.\n   */\n  refreshHashes: valita.readonlyArray(hashSchema),\n\n  /**\n   * The hash of the last snapshot commit persisted by this client to this\n   * client's client group, or null if has never persisted a snapshot.\n   */\n  persistHash: hashSchema.nullable(),\n\n  /**\n   * ID of this client's perdag client group. This needs to be sent in pull\n   * request (to enable syncing all last mutation ids in the client group).\n   */\n  clientGroupID: clientGroupIDSchema,\n});\n\nexport type ClientV6 = valita.Infer<typeof clientV6Schema>;\n\nexport type Client = ClientV5 | ClientV6;\n\nfunction isClientV6(client: Client): client is ClientV6 {\n  return (client as ClientV6).refreshHashes !== undefined;\n}\n\nexport const CLIENTS_HEAD_NAME = 'clients';\n\nconst clientSchema = valita.union(clientV5Schema, clientV6Schema);\n\nfunction assertClient(value: unknown): asserts value is Client {\n  valita.assert(value, clientSchema);\n}\n\nexport function assertClientV6(value: unknown): asserts value is ClientV6 {\n  valita.assert(value, clientV6Schema);\n}\n\nfunction chunkDataToClientMap(chunkData: unknown): ClientMap {\n  assertObject(chunkData);\n  const clients = new Map();\n  for (const key in chunkData) {\n    if (hasOwn(chunkData, key)) {\n      const value = chunkData[key];\n      if (value !== undefined) {\n        assertClient(value);\n        clients.set(key, value);\n      }\n    }\n  }\n  return clients;\n}\n\nfunction clientMapToChunkData(\n  clients: ClientMap,\n  dagWrite: Write,\n): FrozenJSONValue {\n  for (const client of clients.values()) {\n    if (isClientV6(client)) {\n      client.refreshHashes.forEach(dagWrite.assertValidHash);\n      if (client.persistHash) {\n        dagWrite.assertValidHash(client.persistHash);\n      }\n    } else {\n      dagWrite.assertValidHash(client.headHash);\n      if (client.tempRefreshHash) {\n        dagWrite.assertValidHash(client.tempRefreshHash);\n      }\n    }\n  }\n  return deepFreeze(Object.fromEntries(clients));\n}\n\nexport async function getClients(dagRead: Read): Promise<ClientMap> {\n  const hash = await dagRead.getHead(CLIENTS_HEAD_NAME);\n  return getClientsAtHash(hash, dagRead);\n}\n\nasync function getClientsAtHash(\n  hash: Hash | undefined,\n  dagRead: Read,\n): Promise<ClientMap> {\n  if (!hash) {\n    return new Map();\n  }\n  const chunk = await dagRead.getChunk(hash);\n  return chunkDataToClientMap(chunk?.data);\n}\n\n/**\n * Used to signal that a client does not exist. Maybe it was garbage collected?\n */\nexport class ClientStateNotFoundError extends Error {\n  name = 'ClientStateNotFoundError';\n  readonly id: string;\n  constructor(id: ClientID) {\n    super(`Client state not found, id: ${id}`);\n    this.id = id;\n  }\n}\n\n/**\n * Throws a `ClientStateNotFoundError` if the client does not exist.\n */\nexport async function assertHasClientState(\n  id: ClientID,\n  dagRead: Read,\n): Promise<void> {\n  if (!(await hasClientState(id, dagRead))) {\n    throw new ClientStateNotFoundError(id);\n  }\n}\n\nexport async function hasClientState(\n  id: ClientID,\n  dagRead: Read,\n): Promise<boolean> {\n  return !!(await getClient(id, dagRead));\n}\n\nexport async function getClient(\n  id: ClientID,\n  dagRead: Read,\n): Promise<Client | undefined> {\n  const clients = await getClients(dagRead);\n  return clients.get(id);\n}\n\nexport async function mustGetClient(\n  id: ClientID,\n  dagRead: Read,\n): Promise<Client> {\n  const client = await getClient(id, dagRead);\n  if (!client) {\n    throw new ClientStateNotFoundError(id);\n  }\n  return client;\n}\n\ntype InitClientV6Result = [\n  client: ClientV6,\n  hash: Hash,\n  clientMap: ClientMap,\n  newClientGroup: boolean,\n];\n\nexport function initClientV6(\n  newClientID: ClientID,\n  lc: LogContext,\n  perdag: Store,\n  mutatorNames: string[],\n  indexes: IndexDefinitions,\n  formatVersion: FormatVersion,\n  enableClientGroupForking: boolean,\n): Promise<InitClientV6Result> {\n  return withWrite(perdag, async dagWrite => {\n    async function setClientsAndClientGroupAndCommit(\n      basisHash: Hash | null,\n      cookieJSON: FrozenCookie,\n      valueHash: Hash,\n      indexRecords: readonly IndexRecord[],\n    ): Promise<InitClientV6Result> {\n      const newSnapshotData = newSnapshotCommitDataDD31(\n        basisHash,\n        {},\n        cookieJSON,\n        valueHash,\n        indexRecords,\n      );\n      const chunk = dagWrite.createChunk(\n        newSnapshotData,\n        getRefs(newSnapshotData),\n      );\n\n      const newClientGroupID = makeClientID();\n\n      const newClient: ClientV6 = {\n        heartbeatTimestampMs: Date.now(),\n        refreshHashes: [chunk.hash],\n        persistHash: null,\n        clientGroupID: newClientGroupID,\n      };\n\n      const newClients = new Map(clients).set(newClientID, newClient);\n\n      const clientGroup: ClientGroup = {\n        headHash: chunk.hash,\n        mutatorNames,\n        indexes,\n        mutationIDs: {},\n        lastServerAckdMutationIDs: {},\n        disabled: false,\n      };\n\n      await Promise.all([\n        dagWrite.putChunk(chunk),\n        setClients(newClients, dagWrite),\n        setClientGroup(newClientGroupID, clientGroup, dagWrite),\n      ]);\n\n      return [newClient, chunk.hash, newClients, true];\n    }\n\n    const clients = await getClients(dagWrite);\n\n    const res = await findMatchingClient(dagWrite, mutatorNames, indexes);\n    if (res.type === FIND_MATCHING_CLIENT_TYPE_HEAD) {\n      // We found a client group with matching mutators and indexes. We can\n      // reuse it.\n      const {clientGroupID, headHash} = res;\n\n      const newClient: ClientV6 = {\n        clientGroupID,\n        refreshHashes: [headHash],\n        heartbeatTimestampMs: Date.now(),\n        persistHash: null,\n      };\n      const newClients = new Map(clients).set(newClientID, newClient);\n      await setClients(newClients, dagWrite);\n\n      return [newClient, headHash, newClients, false];\n    }\n\n    if (\n      !enableClientGroupForking ||\n      res.type === FIND_MATCHING_CLIENT_TYPE_NEW\n    ) {\n      // No client group to fork from. Create empty snapshot.\n      const emptyBTreeChunk = dagWrite.createChunk(emptyDataNode, []);\n      await dagWrite.putChunk(emptyBTreeChunk);\n\n      // Create indexes\n      const indexRecords: IndexRecord[] = [];\n\n      // At this point the value of replicache is the empty tree so all index\n      // maps will also be the empty tree.\n      for (const [name, indexDefinition] of Object.entries(indexes)) {\n        const chunkIndexDefinition = toChunkIndexDefinition(\n          name,\n          indexDefinition,\n        );\n        indexRecords.push({\n          definition: chunkIndexDefinition,\n          valueHash: emptyBTreeChunk.hash,\n        });\n      }\n\n      return setClientsAndClientGroupAndCommit(\n        null,\n        null,\n        emptyBTreeChunk.hash,\n        indexRecords,\n      );\n    }\n\n    // Now we create a new client and client group that we fork from the found\n    // snapshot.\n    assert(res.type === FIND_MATCHING_CLIENT_TYPE_FORK);\n\n    const {snapshot} = res;\n\n    // Create indexes\n    const indexRecords: IndexRecord[] = [];\n    const {valueHash, indexes: oldIndexes} = snapshot;\n    const map = new BTreeRead(dagWrite, formatVersion, valueHash);\n\n    for (const [name, indexDefinition] of Object.entries(indexes)) {\n      const {prefix = '', jsonPointer, allowEmpty = false} = indexDefinition;\n      const chunkIndexDefinition: ChunkIndexDefinition = {\n        name,\n        keyPrefix: prefix,\n        jsonPointer,\n        allowEmpty,\n      };\n\n      const oldIndex = findMatchingOldIndex(oldIndexes, chunkIndexDefinition);\n      if (oldIndex) {\n        indexRecords.push({\n          definition: chunkIndexDefinition,\n          valueHash: oldIndex.valueHash,\n        });\n      } else {\n        const indexBTree = await createIndexBTree(\n          lc,\n          dagWrite,\n          map,\n          prefix,\n          jsonPointer,\n          allowEmpty,\n          formatVersion,\n        );\n        indexRecords.push({\n          definition: chunkIndexDefinition,\n          valueHash: await indexBTree.flush(),\n        });\n      }\n    }\n\n    return setClientsAndClientGroupAndCommit(\n      snapshot.meta.basisHash,\n      snapshot.meta.cookieJSON,\n      snapshot.valueHash,\n      indexRecords,\n    );\n  });\n}\n\nfunction findMatchingOldIndex(\n  oldIndexes: readonly IndexRecord[],\n  chunkIndexDefinition: ChunkIndexDefinition,\n) {\n  return oldIndexes.find(index =>\n    chunkIndexDefinitionEqualIgnoreName(index.definition, chunkIndexDefinition),\n  );\n}\n\nexport const FIND_MATCHING_CLIENT_TYPE_NEW = 0;\nexport const FIND_MATCHING_CLIENT_TYPE_FORK = 1;\nexport const FIND_MATCHING_CLIENT_TYPE_HEAD = 2;\n\nexport type FindMatchingClientResult =\n  | {\n      type: typeof FIND_MATCHING_CLIENT_TYPE_NEW;\n    }\n  | {\n      type: typeof FIND_MATCHING_CLIENT_TYPE_FORK;\n      snapshot: Commit<SnapshotMetaDD31>;\n    }\n  | {\n      type: typeof FIND_MATCHING_CLIENT_TYPE_HEAD;\n      clientGroupID: ClientGroupID;\n      headHash: Hash;\n    };\n\nexport async function findMatchingClient(\n  dagRead: Read,\n  mutatorNames: string[],\n  indexes: IndexDefinitions,\n): Promise<FindMatchingClientResult> {\n  let newestCookie: FrozenCookie | undefined;\n  let bestSnapshot: Commit<SnapshotMetaDD31> | undefined;\n  const mutatorNamesSet = new Set(mutatorNames);\n\n  const clientGroups = await getClientGroups(dagRead);\n  for (const [clientGroupID, clientGroup] of clientGroups) {\n    if (\n      !clientGroup.disabled &&\n      mutatorNamesEqual(mutatorNamesSet, clientGroup.mutatorNames) &&\n      indexDefinitionsEqual(indexes, clientGroup.indexes)\n    ) {\n      // exact match\n      return {\n        type: FIND_MATCHING_CLIENT_TYPE_HEAD,\n        clientGroupID,\n        headHash: clientGroup.headHash,\n      };\n    }\n\n    const clientGroupSnapshotCommit = await baseSnapshotFromHash(\n      clientGroup.headHash,\n      dagRead,\n    );\n    assertSnapshotCommitDD31(clientGroupSnapshotCommit);\n\n    const {cookieJSON} = clientGroupSnapshotCommit.meta;\n    if (\n      newestCookie === undefined ||\n      compareCookies(cookieJSON, newestCookie) > 0\n    ) {\n      newestCookie = cookieJSON;\n      bestSnapshot = clientGroupSnapshotCommit;\n    }\n  }\n\n  if (bestSnapshot) {\n    return {\n      type: FIND_MATCHING_CLIENT_TYPE_FORK,\n      snapshot: bestSnapshot,\n    };\n  }\n\n  return {type: FIND_MATCHING_CLIENT_TYPE_NEW};\n}\n\nfunction getRefsForClients(clients: ClientMap): Refs {\n  const refs: Set<Hash> = new Set();\n  for (const client of clients.values()) {\n    if (isClientV6(client)) {\n      for (const hash of client.refreshHashes) {\n        refs.add(hash);\n      }\n      if (client.persistHash) {\n        refs.add(client.persistHash);\n      }\n    } else {\n      refs.add(client.headHash);\n      if (client.tempRefreshHash) {\n        refs.add(client.tempRefreshHash);\n      }\n    }\n  }\n  return toRefs(refs);\n}\n\nexport async function getClientGroupForClient(\n  clientID: ClientID,\n  read: Read,\n): Promise<ClientGroup | undefined> {\n  const clientGroupID = await getClientGroupIDForClient(clientID, read);\n  if (!clientGroupID) {\n    return undefined;\n  }\n  return getClientGroup(clientGroupID, read);\n}\n\nexport async function getClientGroupIDForClient(\n  clientID: ClientID,\n  read: Read,\n): Promise<ClientGroupID | undefined> {\n  const client = await getClient(clientID, read);\n  return client?.clientGroupID;\n}\n\n/**\n * Adds a Client to the ClientMap and updates the 'clients' head to point at\n * the updated clients.\n */\nexport async function setClient(\n  clientID: ClientID,\n  client: Client,\n  dagWrite: Write,\n): Promise<Hash> {\n  const clients = await getClients(dagWrite);\n  const newClients = new Map(clients).set(clientID, client);\n  return setClients(newClients, dagWrite);\n}\n\n/**\n * Sets the ClientMap and updates the 'clients' head top point at the new\n * clients.\n */\nexport async function setClients(\n  clients: ClientMap,\n  dagWrite: Write,\n): Promise<Hash> {\n  const chunkData = clientMapToChunkData(clients, dagWrite);\n  const chunk = dagWrite.createChunk(chunkData, getRefsForClients(clients));\n  await dagWrite.putChunk(chunk);\n  await dagWrite.setHead(CLIENTS_HEAD_NAME, chunk.hash);\n  return chunk.hash;\n}\n\n/**\n * Callback function for when Replicache has deleted one or more clients.\n */\nexport type OnClientsDeleted = (\n  clientIDs: readonly ClientID[],\n  clientGroupIDs: readonly ClientGroupID[],\n) => void;\n","export function mapValues<T extends Record<string, unknown>, U>(\n  input: T,\n  mapper: (value: T[keyof T]) => U,\n): {[K in keyof T]: U} {\n  return mapEntries(input, (k, v) => [k, mapper(v as T[keyof T])]) as {\n    [K in keyof T]: U;\n  };\n}\n\nexport function mapEntries<T, U>(\n  input: Record<string, T>,\n  mapper: (key: string, val: T) => [key: string, val: U],\n): Record<string, U> {\n  // Direct assignment is faster than Object.fromEntries()\n  // https://github.com/rocicorp/mono/pull/3927#issuecomment-2706059475\n  const output: Record<string, U> = {};\n\n  // In chrome Object.entries is faster than for-in (13x) or Object.keys (15x)\n  // https://gist.github.com/arv/1b4e113724f6a14e2d4742bcc760d1fa\n  for (const entry of Object.entries(input)) {\n    const mapped = mapper(entry[0], entry[1]);\n    output[mapped[0]] = mapped[1];\n  }\n  return output;\n}\n\nexport function mapAllEntries<T, U>(\n  input: Record<string, T>,\n  mapper: (entries: [key: string, val: T][]) => [key: string, val: U][],\n): Record<string, U> {\n  // Direct assignment is faster than Object.fromEntries()\n  // https://github.com/rocicorp/mono/pull/3927#issuecomment-2706059475\n  const output: Record<string, U> = {};\n  for (const mapped of mapper(Object.entries(input))) {\n    output[mapped[0]] = mapped[1];\n  }\n  return output;\n}\n","export function must<T>(v: T | undefined | null, msg?: string): T {\n  // eslint-disable-next-line eqeqeq\n  if (v == null) {\n    throw new Error(msg ?? `Unexpected ${v} value`);\n  }\n  return v;\n}\n","import {compareUTF8} from 'compare-utf8';\nimport {\n  assertBoolean,\n  assertNumber,\n  assertString,\n} from '../../../shared/src/asserts.ts';\nimport type {Ordering} from '../../../zero-protocol/src/ast.ts';\nimport type {Row, Value} from '../../../zero-protocol/src/data.ts';\nimport type {Stream} from './stream.ts';\n\n/**\n * A row flowing through the pipeline, plus its relationships.\n * Relationships are generated lazily as read.\n */\nexport type Node = {\n  row: Row;\n  relationships: Record<string, () => Stream<Node>>;\n};\n\n/**\n * Compare two values. The values must be of the same type. This function\n * throws at runtime if the types differ.\n *\n * Note, this function considers `null === null` and\n * `undefined === undefined`. This is different than SQL. In join code,\n * null must be treated separately.\n *\n * See: https://github.com/rocicorp/mono/pull/2116/files#r1704811479\n *\n * @returns < 0 if a < b, 0 if a === b, > 0 if a > b\n */\nexport function compareValues(a: Value, b: Value): number {\n  a = normalizeUndefined(a);\n  b = normalizeUndefined(b);\n\n  if (a === b) {\n    return 0;\n  }\n  if (a === null) {\n    return -1;\n  }\n  if (b === null) {\n    return 1;\n  }\n  if (typeof a === 'boolean') {\n    assertBoolean(b);\n    return a ? 1 : -1;\n  }\n  if (typeof a === 'number') {\n    assertNumber(b);\n    return a - b;\n  }\n  if (typeof a === 'string') {\n    assertString(b);\n    // We compare all strings in Zero as UTF-8. This is the default on SQLite\n    // and we need to match it. See:\n    // https://blog.replicache.dev/blog/replicache-11-adventures-in-text-encoding.\n    //\n    // TODO: We could change this since SQLite supports UTF-16. Microbenchmark\n    // to see if there's a big win.\n    //\n    // https://www.sqlite.org/c3ref/create_collation.html\n    return compareUTF8(a, b);\n  }\n  throw new Error(`Unsupported type: ${a}`);\n}\n\nexport type NormalizedValue = Exclude<Value, undefined>;\n\n/**\n * We allow undefined to be passed for the convenience of developers, but we\n * treat it equivalently to null. It's better for perf to not create an copy\n * of input values, so we just normalize at use when necessary.\n */\nexport function normalizeUndefined(v: Value): NormalizedValue {\n  return v ?? null;\n}\n\nexport type Comparator = (r1: Row, r2: Row) => number;\n\nexport function makeComparator(\n  order: Ordering,\n  reverse?: boolean | undefined,\n): Comparator {\n  return (a, b) => {\n    // Skip destructuring here since it is hot code.\n    for (const ord of order) {\n      const field = ord[0];\n      const comp = compareValues(a[field], b[field]);\n      if (comp !== 0) {\n        const result = ord[1] === 'asc' ? comp : -comp;\n        return reverse ? -result : result;\n      }\n    }\n    return 0;\n  };\n}\n\n/**\n * Determine if two values are equal. Note that unlike compareValues() above,\n * this function treats `null` as unequal to itself (and same for `undefined`).\n * This is required to make joins work correctly, but may not be the right\n * semantic for your application.\n */\nexport function valuesEqual(a: Value, b: Value): boolean {\n  // eslint-disable-next-line eqeqeq\n  if (a == null || b == null) {\n    return false;\n  }\n  return a === b;\n}\n\nexport function drainStreams(node: Node) {\n  for (const stream of Object.values(node.relationships)) {\n    for (const node of stream()) {\n      drainStreams(node);\n    }\n  }\n}\n","import {\n  assert,\n  assertArray,\n  assertNumber,\n  unreachable,\n} from '../../../shared/src/asserts.ts';\nimport {must} from '../../../shared/src/must.ts';\nimport type {Writable} from '../../../shared/src/writable.ts';\nimport type {Row} from '../../../zero-protocol/src/data.ts';\nimport {drainStreams, type Comparator, type Node} from './data.ts';\nimport type {SourceSchema} from './schema.ts';\nimport type {Entry, Format} from './view.ts';\n\nexport const refCountSymbol = Symbol('rc');\nexport const idSymbol = Symbol('id');\n\ntype MetaEntry = Writable<Entry> & {\n  [refCountSymbol]: number;\n  [idSymbol]?: string | undefined;\n};\ntype MetaEntryList = MetaEntry[];\n\n/**\n * `applyChange` does not consume the `relationships` of `ChildChange#node`,\n * `EditChange#node` and `EditChange#oldNode`.  The `ViewChange` type\n * documents and enforces this via the type system.\n */\nexport type ViewChange =\n  | AddViewChange\n  | RemoveViewChange\n  | ChildViewChange\n  | EditViewChange;\n\nexport type RowOnlyNode = {row: Row};\n\nexport type AddViewChange = {\n  type: 'add';\n  node: Node;\n};\n\nexport type RemoveViewChange = {\n  type: 'remove';\n  node: Node;\n};\n\ntype ChildViewChange = {\n  type: 'child';\n  node: RowOnlyNode;\n  child: {\n    relationshipName: string;\n    change: ViewChange;\n  };\n};\n\ntype EditViewChange = {\n  type: 'edit';\n  node: RowOnlyNode;\n  oldNode: RowOnlyNode;\n};\n\n/**\n * This is a subset of WeakMap but restricted to what we need.\n * @deprecated Not used anymore. This will be removed in the future.\n */\nexport interface RefCountMap {\n  get(entry: Entry): number | undefined;\n  set(entry: Entry, refCount: number): void;\n  delete(entry: Entry): boolean;\n}\n\nexport function applyChange(\n  parentEntry: Entry,\n  change: ViewChange,\n  schema: SourceSchema,\n  relationship: string,\n  format: Format,\n  withIDs = false,\n): void {\n  if (schema.isHidden) {\n    switch (change.type) {\n      case 'add':\n      case 'remove':\n        for (const [relationship, children] of Object.entries(\n          change.node.relationships,\n        )) {\n          const childSchema = must(schema.relationships[relationship]);\n          for (const node of children()) {\n            applyChange(\n              parentEntry,\n              {type: change.type, node},\n              childSchema,\n              relationship,\n              format,\n              withIDs,\n            );\n          }\n        }\n        return;\n      case 'edit':\n        // If hidden at this level it means that the hidden row was changed. If\n        // the row was changed in such a way that it would change the\n        // relationships then the edit would have been split into remove and\n        // add.\n        return;\n      case 'child': {\n        const childSchema = must(\n          schema.relationships[change.child.relationshipName],\n        );\n        applyChange(\n          parentEntry,\n          change.child.change,\n          childSchema,\n          relationship,\n          format,\n          withIDs,\n        );\n        return;\n      }\n      default:\n        unreachable(change);\n    }\n  }\n\n  const {singular, relationships: childFormats} = format;\n  switch (change.type) {\n    case 'add': {\n      let newEntry: MetaEntry | undefined;\n\n      if (singular) {\n        const oldEntry = parentEntry[relationship] as MetaEntry | undefined;\n        if (oldEntry !== undefined) {\n          assert(\n            schema.compareRows(oldEntry, change.node.row) === 0,\n            `Singular relationship '${relationship}' should not have multiple rows. You may need to declare this relationship with the \\`many\\` helper instead of the \\`one\\` helper in your schema.`,\n          );\n          // adding same again.\n          oldEntry[refCountSymbol]++;\n        } else {\n          newEntry = makeNewMetaEntry(change.node.row, schema, withIDs, 1);\n\n          (parentEntry as Writable<Entry>)[relationship] = newEntry;\n        }\n      } else {\n        newEntry = add(\n          change.node.row,\n          getChildEntryList(parentEntry, relationship),\n          schema,\n          withIDs,\n        );\n      }\n\n      if (newEntry) {\n        for (const [relationship, children] of Object.entries(\n          change.node.relationships,\n        )) {\n          // TODO: Is there a flag to make TypeScript complain that dictionary access might be undefined?\n          const childSchema = must(schema.relationships[relationship]);\n          const childFormat = childFormats[relationship];\n          if (childFormat === undefined) {\n            continue;\n          }\n\n          const newView = childFormat.singular\n            ? undefined\n            : ([] as MetaEntryList);\n          newEntry[relationship] = newView;\n\n          for (const node of children()) {\n            applyChange(\n              newEntry,\n              {type: 'add', node},\n              childSchema,\n              relationship,\n              childFormat,\n              withIDs,\n            );\n          }\n        }\n      }\n      break;\n    }\n    case 'remove': {\n      if (singular) {\n        const oldEntry = parentEntry[relationship] as MetaEntry | undefined;\n        assert(oldEntry !== undefined, 'node does not exist');\n        const rc = oldEntry[refCountSymbol];\n        if (rc === 1) {\n          (parentEntry as Writable<Entry>)[relationship] = undefined;\n        }\n        oldEntry[refCountSymbol]--;\n      } else {\n        removeAndUpdateRefCount(\n          getChildEntryList(parentEntry, relationship),\n          change.node.row,\n          schema.compareRows,\n        );\n      }\n      // Needed to ensure cleanup of operator state is fully done.\n      drainStreams(change.node);\n      break;\n    }\n    case 'child': {\n      let existing: MetaEntry;\n      if (singular) {\n        existing = getSingularEntry(parentEntry, relationship);\n      } else {\n        const view = getChildEntryList(parentEntry, relationship);\n        const {pos, found} = binarySearch(\n          view,\n          change.node.row,\n          schema.compareRows,\n        );\n        assert(found, 'node does not exist');\n        existing = view[pos];\n      }\n\n      const childSchema = must(\n        schema.relationships[change.child.relationshipName],\n      );\n      const childFormat = format.relationships[change.child.relationshipName];\n      if (childFormat !== undefined) {\n        applyChange(\n          existing,\n          change.child.change,\n          childSchema,\n          change.child.relationshipName,\n          childFormat,\n          withIDs,\n        );\n      }\n      break;\n    }\n    case 'edit': {\n      if (singular) {\n        const existing = parentEntry[relationship];\n        assertMetaEntry(existing);\n        applyEdit(existing, change, schema, withIDs);\n      } else {\n        const view = getChildEntryList(parentEntry, relationship);\n        // The position of the row in the list may have changed due to the edit.\n        if (schema.compareRows(change.oldNode.row, change.node.row) !== 0) {\n          const {pos: oldPos, found: oldFound} = binarySearch(\n            view,\n            change.oldNode.row,\n            schema.compareRows,\n          );\n          assert(oldFound, 'old node does not exist');\n          const oldEntry = view[oldPos];\n          const {pos, found} = binarySearch(\n            view,\n            change.node.row,\n            schema.compareRows,\n          );\n          // A special case:\n          // when refCount is 1 (so the row is being moved\n          // without leaving a placeholder behind), and the new pos is\n          // the same as the old, or directly after the old (so after the remove\n          // of the old it would be in the same pos):\n          // the row does not need to be moved, it can just be edited in place.\n          if (\n            oldEntry[refCountSymbol] === 1 &&\n            (pos === oldPos || pos - 1 === oldPos)\n          ) {\n            applyEdit(oldEntry, change, schema, withIDs);\n          } else {\n            // Move the row.  If the row has > 1 ref count, an edit should\n            // be received for each ref count.  On the first edit, the original\n            // row is moved, the edit is applied to it and its ref count is set\n            // to 1.  A shallow copy of the row is left at the old pos for\n            // processing of the remaining edit, and the copy's ref count\n            // is decremented.  As each edit is received the ref count of the\n            // copy is decrement, and the ref count of the row at the new\n            // position is incremented.  When the copy's ref count goes to 0,\n            // it is removed.\n            oldEntry[refCountSymbol]--;\n            let adjustedPos = pos;\n            if (oldEntry[refCountSymbol] === 0) {\n              view.splice(oldPos, 1);\n              adjustedPos = oldPos < pos ? pos - 1 : pos;\n            }\n\n            let entryToEdit;\n            if (found) {\n              entryToEdit = view[adjustedPos];\n            } else {\n              view.splice(adjustedPos, 0, oldEntry);\n              entryToEdit = oldEntry;\n              if (oldEntry[refCountSymbol] > 0) {\n                const oldEntryCopy = {...oldEntry};\n                view[oldPos] = oldEntryCopy;\n              }\n            }\n            entryToEdit[refCountSymbol]++;\n            applyEdit(entryToEdit, change, schema, withIDs);\n          }\n        } else {\n          // Position could not have changed, so simply edit in place.\n          const {pos, found} = binarySearch(\n            view,\n            change.oldNode.row,\n            schema.compareRows,\n          );\n          assert(found, 'node does not exist');\n          applyEdit(view[pos], change, schema, withIDs);\n        }\n      }\n\n      break;\n    }\n    default:\n      unreachable(change);\n  }\n}\n\nfunction applyEdit(\n  existing: MetaEntry,\n  change: EditViewChange,\n  schema: SourceSchema,\n  withIDs: boolean,\n) {\n  Object.assign(existing, change.node.row);\n  if (withIDs) {\n    existing[idSymbol] = makeID(change.node.row, schema);\n  }\n}\n\nfunction add(\n  row: Row,\n  view: MetaEntryList,\n  schema: SourceSchema,\n  withIDs: boolean,\n): MetaEntry | undefined {\n  const {pos, found} = binarySearch(view, row, schema.compareRows);\n\n  if (found) {\n    view[pos][refCountSymbol]++;\n    return undefined;\n  }\n  const newEntry = makeNewMetaEntry(row, schema, withIDs, 1);\n  view.splice(pos, 0, newEntry);\n  return newEntry;\n}\n\nfunction removeAndUpdateRefCount(\n  view: MetaEntryList,\n  row: Row,\n  compareRows: Comparator,\n): MetaEntry {\n  const {pos, found} = binarySearch(view, row, compareRows);\n  assert(found, 'node does not exist');\n  const oldEntry = view[pos];\n  const rc = oldEntry[refCountSymbol];\n  if (rc === 1) {\n    view.splice(pos, 1);\n  }\n  oldEntry[refCountSymbol]--;\n\n  return oldEntry;\n}\n\n// TODO: Do not return an object. It puts unnecessary pressure on the GC.\nfunction binarySearch(\n  view: MetaEntryList,\n  target: Row,\n  comparator: Comparator,\n) {\n  let low = 0;\n  let high = view.length - 1;\n  while (low <= high) {\n    const mid = (low + high) >>> 1;\n    const comparison = comparator(view[mid] as Row, target as Row);\n    if (comparison < 0) {\n      low = mid + 1;\n    } else if (comparison > 0) {\n      high = mid - 1;\n    } else {\n      return {pos: mid, found: true};\n    }\n  }\n  return {pos: low, found: false};\n}\n\nfunction getChildEntryList(\n  parentEntry: Entry,\n  relationship: string,\n): MetaEntryList {\n  const view = parentEntry[relationship];\n  assertArray(view);\n  return view as MetaEntryList;\n}\n\nfunction assertMetaEntry(v: unknown): asserts v is MetaEntry {\n  assertNumber((v as Partial<MetaEntry>)[refCountSymbol]);\n}\n\nfunction getSingularEntry(parentEntry: Entry, relationship: string): MetaEntry {\n  const e = parentEntry[relationship];\n  assertNumber((e as Partial<MetaEntry>)[refCountSymbol]);\n  return e as MetaEntry;\n}\n\nfunction makeNewMetaEntry(\n  row: Row,\n  schema: SourceSchema,\n  withIDs: boolean,\n  rc: number,\n): MetaEntry {\n  if (withIDs) {\n    return {...row, [refCountSymbol]: rc, [idSymbol]: makeID(row, schema)};\n  }\n  return {...row, [refCountSymbol]: rc};\n}\nfunction makeID(row: Row, schema: SourceSchema) {\n  // optimization for case of non-compound primary key\n  if (schema.primaryKey.length === 1) {\n    return JSON.stringify(row[schema.primaryKey[0]]);\n  }\n  return JSON.stringify(schema.primaryKey.map(k => row[k]));\n}\n","import type {LogContext} from '@rocicorp/logger';\n\nexport type TimeUnit = 's' | 'm' | 'h' | 'd' | 'y';\n\n/**\n * Time To Live. This is used for query expiration.\n * - `forever` means the query will never expire.\n * - `none` means the query will expire immediately.\n * - A number means the query will expire after that many milliseconds.\n * - A negative number means the query will never expire, this is same as 'forever'.\n * - A string like `1s` means the query will expire after that many seconds.\n * - A string like `1m` means the query will expire after that many minutes.\n * - A string like `1h` means the query will expire after that many hours.\n * - A string like `1d` means the query will expire after that many days.\n * - A string like `1y` means the query will expire after that many years.\n */\nexport type TTL = `${number}${TimeUnit}` | 'forever' | 'none' | number;\n\nexport const DEFAULT_TTL: TTL = '5m';\nexport const DEFAULT_TTL_MS = 1_000 * 60 * 5;\n\nexport const DEFAULT_PRELOAD_TTL: TTL = 'none';\nexport const DEFAULT_PRELOAD_TTL_MS = 0;\n\nexport const MAX_TTL: TTL = '10m';\nexport const MAX_TTL_MS = 1_000 * 60 * 10;\n\nconst multiplier = {\n  s: 1000,\n  m: 60 * 1000,\n  h: 60 * 60 * 1000,\n  d: 24 * 60 * 60 * 1000,\n  y: 365 * 24 * 60 * 60 * 1000,\n} as const;\n\nexport function parseTTL(ttl: TTL): number {\n  if (typeof ttl === 'number') {\n    return Number.isNaN(ttl) ? 0 : !Number.isFinite(ttl) || ttl < 0 ? -1 : ttl;\n  }\n  if (ttl === 'none') {\n    return 0;\n  }\n  if (ttl === 'forever') {\n    return -1;\n  }\n  const multi = multiplier[ttl[ttl.length - 1] as TimeUnit];\n  return Number(ttl.slice(0, -1)) * multi;\n}\n\nexport function compareTTL(a: TTL, b: TTL): number {\n  const ap = parseTTL(a);\n  const bp = parseTTL(b);\n  if (ap === -1 && bp !== -1) {\n    return 1;\n  }\n  if (ap !== -1 && bp === -1) {\n    return -1;\n  }\n  return ap - bp;\n}\n\nexport function normalizeTTL(ttl: TTL): TTL {\n  if (typeof ttl === 'string') {\n    return ttl;\n  }\n\n  if (ttl < 0) {\n    return 'forever';\n  }\n\n  if (ttl === 0) {\n    return 'none';\n  }\n\n  let shortest = ttl.toString();\n  const lengthOfNumber = shortest.length;\n  for (const unit of ['y', 'd', 'h', 'm', 's'] as const) {\n    const multi = multiplier[unit];\n    const value = ttl / multi;\n    const candidate = `${value}${unit}`;\n    if (candidate.length < shortest.length) {\n      shortest = candidate;\n    }\n  }\n\n  return (shortest.length < lengthOfNumber ? shortest : ttl) as TTL;\n}\n\nexport function clampTTL(ttl: TTL, lc?: Pick<LogContext, 'warn'>): number {\n  const parsedTTL = parseTTL(ttl);\n  if (parsedTTL === -1 || parsedTTL > 10 * 60 * 1000) {\n    // 10 minutes in milliseconds\n    lc?.warn?.(`TTL (${ttl}) is too high, clamping to ${MAX_TTL}`);\n    return parseTTL(MAX_TTL);\n  }\n  return parsedTTL;\n}\n","import * as valita from '@badrap/valita';\nimport {skipAssertJSONValue} from './config.ts';\nimport type {ReadonlyJSONObject, ReadonlyJSONValue} from './json.ts';\nimport {isJSONObject, isJSONValue} from './json.ts';\nimport * as v from './valita.ts';\n\nconst path: (string | number)[] = [];\n\nexport const jsonSchema: valita.Type<ReadonlyJSONValue> = v\n  .unknown()\n  .chain(v => {\n    if (skipAssertJSONValue) {\n      return valita.ok(v as ReadonlyJSONValue);\n    }\n    const rv = isJSONValue(v, path)\n      ? valita.ok(v)\n      : valita.err({\n          message: `Not a JSON value`,\n          path: path.slice(),\n        });\n    path.length = 0;\n    return rv;\n  });\n\nexport const jsonObjectSchema: valita.Type<ReadonlyJSONObject> = v\n  .unknown()\n  .chain(v => {\n    if (skipAssertJSONValue) {\n      return valita.ok(v as ReadonlyJSONObject);\n    }\n    const rv = isJSONObject(v, path)\n      ? valita.ok(v)\n      : valita.err({\n          message: `Not a JSON object`,\n          path: path.slice(),\n        });\n    path.length = 0;\n    return rv;\n  });\n","import * as v from './valita.ts';\n\n/**\n * Valita schema for TDigest JSON representation.\n * Matches the structure returned by TDigest.toJSON().\n */\nexport const tdigestSchema = v.tuple([v.number()]).concat(v.array(v.number()));\n\nexport type TDigestJSON = v.Infer<typeof tdigestSchema>;\n","/**\n * Wire-format representation of the zql AST interface.\n *\n * `v.Type<...>` types are explicitly declared to facilitate Typescript verification\n * that the schemas satisfy the zql type definitions. (Incidentally, explicit types\n * are also required for recursive schema definitions.)\n */\n\nimport {compareUTF8} from 'compare-utf8';\nimport {defined} from '../../shared/src/arrays.ts';\nimport {assert} from '../../shared/src/asserts.ts';\nimport {must} from '../../shared/src/must.ts';\nimport * as v from '../../shared/src/valita.ts';\nimport type {NameMapper} from '../../zero-schema/src/name-mapper.ts';\nimport {rowSchema, type Row} from './data.ts';\n\nexport const selectorSchema = v.string();\nexport const toStaticParam = Symbol();\n\nconst orderingElementSchema = v.readonly(\n  v.tuple([selectorSchema, v.literalUnion('asc', 'desc')]),\n);\n\nexport const orderingSchema = v.readonlyArray(orderingElementSchema);\nexport type System = 'permissions' | 'client' | 'test';\n\nexport const primitiveSchema = v.union(\n  v.string(),\n  v.number(),\n  v.boolean(),\n  v.null(),\n);\n\nexport const equalityOpsSchema = v.literalUnion('=', '!=', 'IS', 'IS NOT');\n\nexport const orderOpsSchema = v.literalUnion('<', '>', '<=', '>=');\n\nexport const likeOpsSchema = v.literalUnion(\n  'LIKE',\n  'NOT LIKE',\n  'ILIKE',\n  'NOT ILIKE',\n);\n\nexport const inOpsSchema = v.literalUnion('IN', 'NOT IN');\n\nexport const simpleOperatorSchema = v.union(\n  equalityOpsSchema,\n  orderOpsSchema,\n  likeOpsSchema,\n  inOpsSchema,\n);\n\nconst literalReferenceSchema: v.Type<LiteralReference> = v.readonlyObject({\n  type: v.literal('literal'),\n  value: v.union(\n    v.string(),\n    v.number(),\n    v.boolean(),\n    v.null(),\n    v.readonlyArray(v.union(v.string(), v.number(), v.boolean())),\n  ),\n});\nconst columnReferenceSchema: v.Type<ColumnReference> = v.readonlyObject({\n  type: v.literal('column'),\n  name: v.string(),\n});\n\n/**\n * A parameter is a value that is not known at the time the query is written\n * and is resolved at runtime.\n *\n * Static parameters refer to something provided by the caller.\n * Static parameters are injected when the query pipeline is built from the AST\n * and do not change for the life of that pipeline.\n *\n * An example static parameter is the current authentication data.\n * When a user is authenticated, queries on the server have access\n * to the user's authentication data in order to evaluate authorization rules.\n * Authentication data doesn't change over the life of a query as a change\n * in auth data would represent a log-in / log-out of the user.\n *\n * AncestorParameters refer to rows encountered while running the query.\n * They are used by subqueries to refer to rows emitted by parent queries.\n */\nconst parameterReferenceSchema = v.readonlyObject({\n  type: v.literal('static'),\n  // The \"namespace\" of the injected parameter.\n  // Write authorization will send the value of a row\n  // prior to the mutation being run (preMutationRow).\n  // Read and write authorization will both send the\n  // current authentication data (authData).\n  anchor: v.literalUnion('authData', 'preMutationRow'),\n  field: v.union(v.string(), v.array(v.string())),\n});\n\nconst conditionValueSchema = v.union(\n  literalReferenceSchema,\n  columnReferenceSchema,\n  parameterReferenceSchema,\n);\n\nexport type Parameter = v.Infer<typeof parameterReferenceSchema>;\n\nexport const simpleConditionSchema: v.Type<SimpleCondition> = v.readonlyObject({\n  type: v.literal('simple'),\n  op: simpleOperatorSchema,\n  left: conditionValueSchema,\n  right: v.union(parameterReferenceSchema, literalReferenceSchema),\n});\n\ntype ConditionValue = v.Infer<typeof conditionValueSchema>;\n\nexport const correlatedSubqueryConditionOperatorSchema: v.Type<CorrelatedSubqueryConditionOperator> =\n  v.literalUnion('EXISTS', 'NOT EXISTS');\n\nexport const correlatedSubqueryConditionSchema: v.Type<CorrelatedSubqueryCondition> =\n  v.readonlyObject({\n    type: v.literal('correlatedSubquery'),\n    related: v.lazy(() => correlatedSubquerySchema),\n    op: correlatedSubqueryConditionOperatorSchema,\n  });\n\nexport const conditionSchema: v.Type<Condition> = v.union(\n  simpleConditionSchema,\n  v.lazy(() => conjunctionSchema),\n  v.lazy(() => disjunctionSchema),\n  correlatedSubqueryConditionSchema,\n);\n\nconst conjunctionSchema: v.Type<Conjunction> = v.readonlyObject({\n  type: v.literal('and'),\n  conditions: v.readonlyArray(conditionSchema),\n});\n\nconst disjunctionSchema: v.Type<Disjunction> = v.readonlyObject({\n  type: v.literal('or'),\n  conditions: v.readonlyArray(conditionSchema),\n});\n\nexport type CompoundKey = readonly [string, ...string[]];\n\nfunction mustCompoundKey(field: readonly string[]): CompoundKey {\n  assert(Array.isArray(field) && field.length >= 1);\n  return field as unknown as CompoundKey;\n}\n\nexport const compoundKeySchema: v.Type<CompoundKey> = v.readonly(\n  v.tuple([v.string()]).concat(v.array(v.string())),\n);\n\nconst correlationSchema = v.readonlyObject({\n  parentField: compoundKeySchema,\n  childField: compoundKeySchema,\n});\n\n// Split out so that its inferred type can be checked against\n// Omit<CorrelatedSubquery, 'correlation'> in ast-type-test.ts.\n// The mutually-recursive reference of the 'other' field to astSchema\n// is the only thing added in v.lazy.  The v.lazy is necessary due to the\n// mutually-recursive types, but v.lazy prevents inference of the resulting\n// type.\nexport const correlatedSubquerySchemaOmitSubquery = v.readonlyObject({\n  correlation: correlationSchema,\n  hidden: v.boolean().optional(),\n  system: v.literalUnion('permissions', 'client', 'test').optional(),\n});\n\nexport const correlatedSubquerySchema: v.Type<CorrelatedSubquery> =\n  correlatedSubquerySchemaOmitSubquery.extend({\n    subquery: v.lazy(() => astSchema),\n  });\n\nexport const astSchema: v.Type<AST> = v.readonlyObject({\n  schema: v.string().optional(),\n  table: v.string(),\n  alias: v.string().optional(),\n  where: conditionSchema.optional(),\n  related: v.readonlyArray(correlatedSubquerySchema).optional(),\n  limit: v.number().optional(),\n  orderBy: orderingSchema.optional(),\n  start: v\n    .object({\n      row: rowSchema,\n      exclusive: v.boolean(),\n    })\n    .optional(),\n});\n\nexport type Bound = {\n  row: Row;\n  exclusive: boolean;\n};\n\n/**\n * As in SQL you can have multiple orderings. We don't currently\n * support ordering on anything other than the root query.\n */\nexport type OrderPart = readonly [field: string, direction: 'asc' | 'desc'];\nexport type Ordering = readonly OrderPart[];\n\nexport type SimpleOperator = EqualityOps | OrderOps | LikeOps | InOps;\nexport type EqualityOps = '=' | '!=' | 'IS' | 'IS NOT';\nexport type OrderOps = '<' | '>' | '<=' | '>=';\nexport type LikeOps = 'LIKE' | 'NOT LIKE' | 'ILIKE' | 'NOT ILIKE';\nexport type InOps = 'IN' | 'NOT IN';\n\nexport type AST = {\n  readonly schema?: string | undefined;\n  readonly table: string;\n\n  // A query would be aliased if the AST is a subquery.\n  // e.g., when two subqueries select from the same table\n  // they need an alias to differentiate them.\n  // `SELECT\n  //   [SELECT * FROM issue WHERE issue.id = outer.parentId] AS parent\n  //   [SELECT * FROM issue WHERE issue.parentId = outer.id] AS children\n  //  FROM issue as outer`\n  readonly alias?: string | undefined;\n\n  // `select` is missing given we return all columns for now.\n\n  // The PipelineBuilder will pick what to use to correlate\n  // a subquery with a parent query. It can choose something from the\n  // where conditions or choose the _first_ `related` entry.\n  // Choosing the first `related` entry is almost always the best choice if\n  // one exists.\n  readonly where?: Condition | undefined;\n\n  readonly related?: readonly CorrelatedSubquery[] | undefined;\n  readonly start?: Bound | undefined;\n  readonly limit?: number | undefined;\n  readonly orderBy?: Ordering | undefined;\n};\n\nexport type Correlation = {\n  readonly parentField: CompoundKey;\n  readonly childField: CompoundKey;\n};\n\nexport type CorrelatedSubquery = {\n  /**\n   * Only equality correlation are supported for now.\n   * E.g., direct foreign key relationships.\n   */\n  readonly correlation: Correlation;\n  readonly subquery: AST;\n  readonly system?: System | undefined;\n  // If a hop in the subquery chain should be hidden from the output view.\n  // A common example is junction edges. The query API provides the illusion\n  // that they don't exist: `issue.related('labels')` instead of `issue.related('issue_labels').related('labels')`.\n  // To maintain this illusion, the junction edge should be hidden.\n  // When `hidden` is set to true, this hop will not be included in the output view\n  // but its children will be.\n  readonly hidden?: boolean | undefined;\n};\n\nexport type ValuePosition = LiteralReference | Parameter | ColumnReference;\n\nexport type ColumnReference = {\n  readonly type: 'column';\n  /**\n   * Not a path yet as we're currently not allowing\n   * comparisons across tables. This will need to\n   * be a path through the tree in the near future.\n   */\n  readonly name: string;\n};\n\nexport type LiteralReference = {\n  readonly type: 'literal';\n  readonly value: LiteralValue;\n};\n\nexport type LiteralValue =\n  | string\n  | number\n  | boolean\n  | null\n  | ReadonlyArray<string | number | boolean>;\n\n/**\n * Starting only with SimpleCondition for now.\n * ivm1 supports Conjunctions and Disjunctions.\n * We'll support them in the future.\n */\nexport type Condition =\n  | SimpleCondition\n  | Conjunction\n  | Disjunction\n  | CorrelatedSubqueryCondition;\n\nexport type SimpleCondition = {\n  readonly type: 'simple';\n  readonly op: SimpleOperator;\n  readonly left: ValuePosition;\n\n  /**\n   * `null` is absent since we do not have an `IS` or `IS NOT`\n   * operator defined and `null != null` in SQL.\n   */\n  readonly right: Exclude<ValuePosition, ColumnReference>;\n};\n\nexport type Conjunction = {\n  type: 'and';\n  conditions: readonly Condition[];\n};\n\nexport type Disjunction = {\n  type: 'or';\n  conditions: readonly Condition[];\n};\n\nexport type CorrelatedSubqueryCondition = {\n  type: 'correlatedSubquery';\n  related: CorrelatedSubquery;\n  op: CorrelatedSubqueryConditionOperator;\n};\n\nexport type CorrelatedSubqueryConditionOperator = 'EXISTS' | 'NOT EXISTS';\n\ninterface ASTTransform {\n  tableName(orig: string): string;\n  columnName(origTable: string, origColumn: string): string;\n  related(subqueries: CorrelatedSubquery[]): readonly CorrelatedSubquery[];\n  where(cond: Condition): Condition | undefined;\n  // conjunction or disjunction, called when traversing the return value of where()\n  conditions(conds: Condition[]): readonly Condition[];\n}\n\nfunction transformAST(ast: AST, transform: ASTTransform): Required<AST> {\n  // Name mapping functions (e.g. to server names)\n  const {tableName, columnName} = transform;\n  const colName = (c: string) => columnName(ast.table, c);\n  const key = (table: string, k: CompoundKey) => {\n    const serverKey = k.map(col => columnName(table, col));\n    return mustCompoundKey(serverKey);\n  };\n\n  const where = ast.where ? transform.where(ast.where) : undefined;\n  const transformed = {\n    schema: ast.schema,\n    table: tableName(ast.table),\n    alias: ast.alias,\n    where: where ? transformWhere(where, ast.table, transform) : undefined,\n    related: ast.related\n      ? transform.related(\n          ast.related.map(\n            r =>\n              ({\n                correlation: {\n                  parentField: key(ast.table, r.correlation.parentField),\n                  childField: key(r.subquery.table, r.correlation.childField),\n                },\n                hidden: r.hidden,\n                subquery: transformAST(r.subquery, transform),\n                system: r.system,\n              }) satisfies Required<CorrelatedSubquery>,\n          ),\n        )\n      : undefined,\n    start: ast.start\n      ? {\n          ...ast.start,\n          row: Object.fromEntries(\n            Object.entries(ast.start.row).map(([col, val]) => [\n              colName(col),\n              val,\n            ]),\n          ),\n        }\n      : undefined,\n    limit: ast.limit,\n    orderBy: ast.orderBy?.map(([col, dir]) => [colName(col), dir] as const),\n  };\n\n  return transformed;\n}\n\nfunction transformWhere(\n  where: Condition,\n  table: string,\n  transform: ASTTransform,\n): Condition {\n  // Name mapping functions (e.g. to server names)\n  const {columnName} = transform;\n  const condValue = (c: ConditionValue) =>\n    c.type !== 'column' ? c : {...c, name: columnName(table, c.name)};\n  const key = (table: string, k: CompoundKey) => {\n    const serverKey = k.map(col => columnName(table, col));\n    return mustCompoundKey(serverKey);\n  };\n\n  if (where.type === 'simple') {\n    return {...where, left: condValue(where.left)};\n  } else if (where.type === 'correlatedSubquery') {\n    const {correlation, subquery} = where.related;\n    return {\n      ...where,\n      related: {\n        ...where.related,\n        correlation: {\n          parentField: key(table, correlation.parentField),\n          childField: key(subquery.table, correlation.childField),\n        },\n        subquery: transformAST(subquery, transform),\n      },\n    };\n  }\n\n  return {\n    type: where.type,\n    conditions: transform.conditions(\n      where.conditions.map(c => transformWhere(c, table, transform)),\n    ),\n  };\n}\n\nconst normalizeCache = new WeakMap<AST, Required<AST>>();\n\nconst NORMALIZE_TRANSFORM: ASTTransform = {\n  tableName: t => t,\n  columnName: (_, c) => c,\n  related: sortedRelated,\n  where: flattened,\n  conditions: c => c.sort(cmpCondition),\n};\n\nexport function normalizeAST(ast: AST): Required<AST> {\n  let normalized = normalizeCache.get(ast);\n  if (!normalized) {\n    normalized = transformAST(ast, NORMALIZE_TRANSFORM);\n    normalizeCache.set(ast, normalized);\n  }\n  return normalized;\n}\n\nexport function mapAST(ast: AST, mapper: NameMapper) {\n  return transformAST(ast, {\n    tableName: table => mapper.tableName(table),\n    columnName: (table, col) => mapper.columnName(table, col),\n    related: r => r,\n    where: w => w,\n    conditions: c => c,\n  });\n}\n\nexport function mapCondition(\n  cond: Condition,\n  table: string,\n  mapper: NameMapper,\n) {\n  return transformWhere(cond, table, {\n    tableName: table => mapper.tableName(table),\n    columnName: (table, col) => mapper.columnName(table, col),\n    related: r => r,\n    where: w => w,\n    conditions: c => c,\n  });\n}\n\nfunction sortedRelated(\n  related: CorrelatedSubquery[],\n): readonly CorrelatedSubquery[] {\n  return related.sort(cmpRelated);\n}\n\nfunction cmpCondition(a: Condition, b: Condition): number {\n  if (a.type === 'simple') {\n    if (b.type !== 'simple') {\n      return -1; // Order SimpleConditions first\n    }\n\n    return (\n      compareValuePosition(a.left, b.left) ||\n      compareUTF8MaybeNull(a.op, b.op) ||\n      compareValuePosition(a.right, b.right)\n    );\n  }\n\n  if (b.type === 'simple') {\n    return 1; // Order SimpleConditions first\n  }\n\n  if (a.type === 'correlatedSubquery') {\n    if (b.type !== 'correlatedSubquery') {\n      return -1; // Order subquery before conjuctions/disjuctions\n    }\n    return cmpRelated(a.related, b.related) || compareUTF8MaybeNull(a.op, b.op);\n  }\n  if (b.type === 'correlatedSubquery') {\n    return -1; // Order correlatedSubquery before conjuctions/disjuctions\n  }\n\n  const val = compareUTF8MaybeNull(a.type, b.type);\n  if (val !== 0) {\n    return val;\n  }\n  for (\n    let l = 0, r = 0;\n    l < a.conditions.length && r < b.conditions.length;\n    l++, r++\n  ) {\n    const val = cmpCondition(a.conditions[l], b.conditions[r]);\n    if (val !== 0) {\n      return val;\n    }\n  }\n  // prefixes first\n  return a.conditions.length - b.conditions.length;\n}\n\nfunction compareValuePosition(a: ValuePosition, b: ValuePosition): number {\n  if (a.type !== b.type) {\n    return compareUTF8(a.type, b.type);\n  }\n  switch (a.type) {\n    case 'literal':\n      assert(b.type === 'literal');\n      return compareUTF8(String(a.value), String(b.value));\n    case 'column':\n      assert(b.type === 'column');\n      return compareUTF8(a.name, b.name);\n    case 'static':\n      throw new Error(\n        'Static parameters should be resolved before normalization',\n      );\n  }\n}\n\nfunction cmpRelated(a: CorrelatedSubquery, b: CorrelatedSubquery): number {\n  return compareUTF8(must(a.subquery.alias), must(b.subquery.alias));\n}\n\n/**\n * Returns a flattened version of the Conditions in which nested Conjunctions with\n * the same operation ('AND' or 'OR') are flattened to the same level. e.g.\n *\n * ```\n * ((a AND b) AND (c AND (d OR (e OR f)))) -> (a AND b AND c AND (d OR e OR f))\n * ```\n *\n * Also flattens singleton Conjunctions regardless of operator, and removes\n * empty Conjunctions.\n */\nfunction flattened(cond: Condition): Condition | undefined {\n  if (cond.type === 'simple' || cond.type === 'correlatedSubquery') {\n    return cond;\n  }\n  const conditions = defined(\n    cond.conditions.flatMap(c =>\n      c.type === cond.type ? c.conditions.map(c => flattened(c)) : flattened(c),\n    ),\n  );\n\n  switch (conditions.length) {\n    case 0:\n      return undefined;\n    case 1:\n      return conditions[0];\n    default:\n      return {\n        type: cond.type,\n        conditions,\n      };\n  }\n}\n\nfunction compareUTF8MaybeNull(a: string | null, b: string | null): number {\n  if (a !== null && b !== null) {\n    return compareUTF8(a, b);\n  }\n  if (b !== null) {\n    return -1;\n  }\n  if (a !== null) {\n    return 1;\n  }\n  return 0;\n}\n","import {assert} from './asserts.ts';\n\n/**\n * Returns `arr` as is if none of the elements are `undefined`.\n * Otherwise returns a new array with only defined elements in `arr`.\n */\nexport function defined<T>(arr: (T | undefined)[]): T[] {\n  // avoid an array copy if possible\n  let i = arr.findIndex(x => x === undefined);\n  if (i < 0) {\n    return arr as T[];\n  }\n  const defined: T[] = arr.slice(0, i) as T[];\n  for (i++; i < arr.length; i++) {\n    const x = arr[i];\n    if (x !== undefined) {\n      defined.push(x);\n    }\n  }\n  return defined;\n}\n\nexport function areEqual<T>(arr1: readonly T[], arr2: readonly T[]): boolean {\n  return arr1.length === arr2.length && arr1.every((e, i) => e === arr2[i]);\n}\n\nexport function zip<T1, T2>(a1: readonly T1[], a2: readonly T2[]): [T1, T2][] {\n  assert(a1.length === a2.length);\n  const result: [T1, T2][] = [];\n  for (let i = 0; i < a1.length; i++) {\n    result.push([a1[i], a2[i]]);\n  }\n  return result;\n}\n\nexport function last<T>(arr: T[]): T | undefined {\n  if (arr.length === 0) {\n    return undefined;\n  }\n  return arr[arr.length - 1];\n}\n\nexport function groupBy<T, K>(\n  arr: readonly T[],\n  keyFn: (el: T) => K,\n): Map<K, T[]> {\n  const groups = new Map<K, T[]>();\n  for (const el of arr) {\n    const key = keyFn(el);\n    let group = groups.get(key);\n    if (group === undefined) {\n      group = [];\n      groups.set(key, group);\n    }\n    group.push(el);\n  }\n  return groups;\n}\n","import {jsonSchema} from '../../shared/src/json-schema.ts';\nimport * as v from '../../shared/src/valita.ts';\n\nexport const valueSchema = v.union(jsonSchema, v.undefined());\n\nexport const rowSchema = v.readonlyRecord(valueSchema);\n\n/**\n * The data types that Zero can represent are limited by two things:\n *\n * 1. The underlying Replicache sync layer currently can only represent JSON\n *    types. This could possibly be expanded in the future, but we do want to be\n *    careful of adding encoding overhead. By using JSON, we are taking\n *    advantage of IndexedDBs fast native JSValue [de]serialization which has\n *    historically been a perf advantage for us.\n *\n * 2. IDs in Zero need to be comparable because we use them for sorting and row\n *    identity. We could expand the set of allowed value types (to include,\n *    i.e., Objects) but we would then need to restrict IDs to only comparable\n *    types.\n *\n * These two facts leave us with the following allowed types. Zero's replication\n * layer must convert other types into these for tables to be used with Zero.\n *\n * For developer convenience we also allow `undefined`, which we treat\n * equivalently to `null`.\n */\nexport type Value = v.Infer<typeof valueSchema>;\n\n/**\n * A Row is represented as a JS Object.\n *\n * We do everything in IVM as loosely typed values because these pipelines are\n * going to be constructed at runtime by other code, so type-safety can't buy us\n * anything.\n *\n * Also since the calling code on the client ultimately wants objects to work\n * with we end up with a lot less copies by using objects throughout.\n */\nexport type Row = v.Infer<typeof rowSchema>;\n","import {jsonSchema} from '../../shared/src/json-schema.ts';\nimport {tdigestSchema} from '../../shared/src/tdigest-schema.ts';\nimport * as v from '../../shared/src/valita.ts';\nimport {astSchema} from './ast.ts';\n\nconst serverMetricsSchema = v.object({\n  'query-materialization-server': tdigestSchema,\n  'query-update-server': tdigestSchema,\n});\n\nexport type ServerMetrics = v.Infer<typeof serverMetricsSchema>;\n\nconst inspectQueryRowSchema = v.object({\n  clientID: v.string(),\n  queryID: v.string(),\n  // This is the server return AST for custom queries\n  // TODO: Return server generated AST\n  ast: astSchema.nullable(),\n  // not null for custom queries\n  name: v.string().nullable(),\n  // not null for custom queries\n  args: v.readonlyArray(jsonSchema).nullable(),\n  got: v.boolean(),\n  deleted: v.boolean(),\n  ttl: v.number(),\n  inactivatedAt: v.number().nullable(),\n  rowCount: v.number(),\n  metrics: serverMetricsSchema.nullable().optional(),\n});\n\nexport type InspectQueryRow = v.Infer<typeof inspectQueryRowSchema>;\n\nconst inspectBaseDownSchema = v.object({\n  id: v.string(),\n});\n\nexport const inspectQueriesDownSchema = inspectBaseDownSchema.extend({\n  op: v.literal('queries'),\n  value: v.array(inspectQueryRowSchema),\n});\n\nexport type InspectQueriesDown = v.Infer<typeof inspectQueriesDownSchema>;\n\nexport const inspectMetricsDownSchema = inspectBaseDownSchema.extend({\n  op: v.literal('metrics'),\n  value: serverMetricsSchema,\n});\n\nexport type InspectMetricsDown = v.Infer<typeof inspectMetricsDownSchema>;\n\nexport const inspectVersionDownSchema = inspectBaseDownSchema.extend({\n  op: v.literal('version'),\n  value: v.string(),\n});\n\nexport const inspectDownBodySchema = v.union(\n  inspectQueriesDownSchema,\n  inspectMetricsDownSchema,\n  inspectVersionDownSchema,\n);\n\nexport const inspectDownMessageSchema = v.tuple([\n  v.literal('inspect'),\n  inspectDownBodySchema,\n]);\n\nexport type InspectDownMessage = v.Infer<typeof inspectDownMessageSchema>;\n\nexport type InspectDownBody = v.Infer<typeof inspectDownBodySchema>;\n","export function getNonCryptoRandomValues(array: Uint8Array) {\n  if (array === null) {\n    throw new TypeError('array cannot be null');\n  }\n\n  // Fill the array with random values\n  for (let i = 0; i < array.length; i++) {\n    array[i] = Math.floor(Math.random() * 256); // Random byte (0-255)\n  }\n\n  return array;\n}\n\nexport function randomCharacters(length: number) {\n  let result = '';\n  const characters =\n    'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789';\n  const charactersLength = characters.length;\n  let counter = 0;\n  while (counter < length) {\n    result += characters.charAt(Math.floor(Math.random() * charactersLength));\n    counter += 1;\n  }\n  return result;\n}\n","// This is taken from https://github.com/ai/nanoid/blob/main/index.browser.js We\n// copy this because we want to use `--platform=neutral` which doesn't work with\n// the npm package.\n// Also we changed the random number generator to use Math.random() for compat\n// with React Native.\n\nimport {getNonCryptoRandomValues} from '../../../shared/src/random-values.ts';\n\nexport function nanoid(size = 21): string {\n  // Use our custom getRandomValues function to fill a Uint8Array with random values.\n  const randomBytes = getNonCryptoRandomValues(new Uint8Array(size));\n\n  return randomBytes.reduce((id, byte) => {\n    // It is incorrect to use bytes exceeding the alphabet size.\n    // The following mask reduces the random byte in the 0-255 value\n    // range to the 0-63 value range. Therefore, adding hacks, such\n    // as empty string fallback or magic numbers, is unneccessary because\n    // the bitmask trims bytes down to the alphabet size.\n    byte &= 63;\n    if (byte < 36) {\n      // `0-9a-z`\n      id += byte.toString(36);\n    } else if (byte < 62) {\n      // `A-Z`\n      id += (byte - 26).toString(36).toUpperCase();\n    } else if (byte > 62) {\n      id += '-';\n    } else {\n      id += '_';\n    }\n    return id;\n  }, '');\n}\n","import {xxHash32} from 'js-xxhash';\n\nexport const h32 = (s: string) => xxHash32(s, 0);\nexport const h64 = (s: string) => hash(s, 2);\nexport const h128 = (s: string) => hash(s, 4);\n\n/**\n * xxHash32 only computes 32-bit values. Run it n times with different seeds to\n * get a larger hash with better collision resistance.\n */\nfunction hash(str: string, words: number): bigint {\n  let hash = 0n;\n  for (let i = 0; i < words; i++) {\n    hash = (hash << 32n) + BigInt(xxHash32(str, i));\n  }\n  return hash;\n}\n","import * as v from '../../shared/src/valita.ts';\n\nexport const primaryKeySchema = v.readonly(\n  v.tuple([v.string()]).concat(v.array(v.string())),\n);\n\nexport type PrimaryKey = v.Infer<typeof primaryKeySchema>;\n\nexport const primaryKeyValueSchema = v.union(\n  v.string(),\n  v.number(),\n  v.boolean(),\n);\n\nexport type PrimaryKeyValue = v.Infer<typeof primaryKeyValueSchema>;\n\nexport const primaryKeyValueRecordSchema = v.readonlyRecord(\n  primaryKeyValueSchema,\n);\n\nexport type PrimaryKeyValueRecord = v.Infer<typeof primaryKeyValueRecordSchema>;\n","import {h128} from '../../../shared/src/hash.ts';\nimport * as v from '../../../shared/src/valita.ts';\nimport type {CompoundKey} from '../../../zero-protocol/src/ast.ts';\nimport type {Row} from '../../../zero-protocol/src/data.ts';\nimport {primaryKeyValueSchema} from '../../../zero-protocol/src/primary-key.ts';\nimport type {MutationID} from '../../../zero-protocol/src/push.ts';\n\nexport const DESIRED_QUERIES_KEY_PREFIX = 'd/';\nexport const GOT_QUERIES_KEY_PREFIX = 'g/';\nexport const ENTITIES_KEY_PREFIX = 'e/';\nexport const MUTATIONS_KEY_PREFIX = 'm/';\n\nexport function toDesiredQueriesKey(clientID: string, hash: string): string {\n  return DESIRED_QUERIES_KEY_PREFIX + clientID + '/' + hash;\n}\n\nexport function desiredQueriesPrefixForClient(clientID: string): string {\n  return DESIRED_QUERIES_KEY_PREFIX + clientID + '/';\n}\n\nexport function toGotQueriesKey(hash: string): string {\n  return GOT_QUERIES_KEY_PREFIX + hash;\n}\n\nexport function toMutationResponseKey(mid: MutationID): string {\n  return MUTATIONS_KEY_PREFIX + mid.clientID + '/' + mid.id;\n}\n\nexport function toPrimaryKeyString(\n  tableName: string,\n  primaryKey: CompoundKey,\n  value: Row,\n): string {\n  if (primaryKey.length === 1) {\n    return (\n      ENTITIES_KEY_PREFIX +\n      tableName +\n      '/' +\n      v.parse(value[primaryKey[0]], primaryKeyValueSchema)\n    );\n  }\n\n  const values = primaryKey.map(k => v.parse(value[k], primaryKeyValueSchema));\n  const str = JSON.stringify(values);\n\n  const idSegment = h128(str);\n  return ENTITIES_KEY_PREFIX + tableName + '/' + idSegment;\n}\n\nexport function sourceNameFromKey(key: string): string {\n  const slash = key.indexOf('/', ENTITIES_KEY_PREFIX.length);\n  return key.slice(ENTITIES_KEY_PREFIX.length, slash);\n}\n","// Apache License 2.0\n// https://github.com/influxdata/tdigest\n\n// Centroid average position of all points in a shape\nexport class Centroid {\n  mean: number;\n  weight: number;\n\n  constructor(mean: number, weight: number) {\n    this.mean = mean;\n    this.weight = weight;\n  }\n\n  add(r: Centroid): void {\n    if (r.weight < 0) {\n      throw new Error('centroid weight cannot be less than zero');\n    }\n    if (this.weight !== 0) {\n      this.weight += r.weight;\n      this.mean += (r.weight * (r.mean - this.mean)) / this.weight;\n    } else {\n      this.weight = r.weight;\n      this.mean = r.mean;\n    }\n  }\n}\n\n/** CentroidList is sorted by the mean of the centroid, ascending. */\nexport type CentroidList = Centroid[];\n\nexport function sortCentroidList(centroids: CentroidList): void {\n  centroids.sort((a, b) => a.mean - b.mean);\n}\n","// Apache License 2.0\n// https://github.com/influxdata/tdigest\n\nimport {binarySearch} from './binary-search.ts';\nimport {Centroid, sortCentroidList, type CentroidList} from './centroid.ts';\nimport type {TDigestJSON} from './tdigest-schema.ts';\n\nexport interface ReadonlyTDigest {\n  readonly count: () => number;\n  readonly quantile: (q: number) => number;\n  readonly cdf: (x: number) => number;\n}\n\n// TDigest is a data structure for accurate on-line accumulation of\n// rank-based statistics such as quantiles and trimmed means.\nexport class TDigest {\n  readonly compression: number;\n\n  #maxProcessed: number;\n  #maxUnprocessed: number;\n  #processed!: CentroidList;\n  #unprocessed!: CentroidList;\n  #cumulative!: number[];\n  #processedWeight!: number;\n  #unprocessedWeight!: number;\n  #min!: number;\n  #max!: number;\n\n  constructor(compression: number = 1000) {\n    this.compression = compression;\n    this.#maxProcessed = processedSize(0, this.compression);\n    this.#maxUnprocessed = unprocessedSize(0, this.compression);\n    this.reset();\n  }\n\n  /**\n   * fromJSON creates a TDigest from a JSON-serializable representation.\n   * The data should be an object with compression and centroids array.\n   */\n  static fromJSON(data: Readonly<TDigestJSON>): TDigest {\n    const digest = new TDigest(data[0]);\n    if (data.length % 2 !== 1) {\n      throw new Error('Invalid centroids array');\n    }\n    for (let i = 1; i < data.length; i += 2) {\n      digest.add(data[i], data[i + 1]);\n    }\n    return digest;\n  }\n\n  reset(): void {\n    this.#processed = [];\n    this.#unprocessed = [];\n    this.#cumulative = [];\n    this.#processedWeight = 0;\n    this.#unprocessedWeight = 0;\n    this.#min = Number.MAX_VALUE;\n    this.#max = -Number.MAX_VALUE;\n  }\n\n  add(mean: number, weight: number = 1) {\n    this.addCentroid(new Centroid(mean, weight));\n  }\n\n  /** AddCentroidList can quickly add multiple centroids. */\n  addCentroidList(centroidList: CentroidList) {\n    for (const c of centroidList) {\n      this.addCentroid(c);\n    }\n  }\n\n  /**\n   * AddCentroid adds a single centroid.\n   * Weights which are not a number or are <= 0 are ignored, as are NaN means.\n   */\n  addCentroid(c: Centroid): void {\n    if (\n      Number.isNaN(c.mean) ||\n      c.weight <= 0 ||\n      Number.isNaN(c.weight) ||\n      !Number.isFinite(c.weight)\n    ) {\n      return;\n    }\n\n    this.#unprocessed.push(new Centroid(c.mean, c.weight));\n    this.#unprocessedWeight += c.weight;\n\n    if (\n      this.#processed.length > this.#maxProcessed ||\n      this.#unprocessed.length > this.#maxUnprocessed\n    ) {\n      this.#process();\n    }\n  }\n\n  /**\n   *  Merges the supplied digest into this digest. Functionally equivalent to\n   * calling t.AddCentroidList(t2.Centroids(nil)), but avoids making an extra\n   * copy of the CentroidList.\n   **/\n  merge(t2: TDigest) {\n    t2.#process();\n    this.addCentroidList(t2.#processed);\n  }\n\n  #process() {\n    if (\n      this.#unprocessed.length > 0 ||\n      this.#processed.length > this.#maxProcessed\n    ) {\n      // Append all processed centroids to the unprocessed list and sort\n      this.#unprocessed.push(...this.#processed);\n      sortCentroidList(this.#unprocessed);\n\n      // Reset processed list with first centroid\n      this.#processed.length = 0;\n      this.#processed.push(this.#unprocessed[0]);\n\n      this.#processedWeight += this.#unprocessedWeight;\n      this.#unprocessedWeight = 0;\n      let soFar = this.#unprocessed[0].weight;\n      let limit = this.#processedWeight * this.#integratedQ(1);\n      for (let i = 1; i < this.#unprocessed.length; i++) {\n        const centroid = this.#unprocessed[i];\n        const projected = soFar + centroid.weight;\n        if (projected <= limit) {\n          soFar = projected;\n          this.#processed[this.#processed.length - 1].add(centroid);\n        } else {\n          const k1 = this.#integratedLocation(soFar / this.#processedWeight);\n          limit = this.#processedWeight * this.#integratedQ(k1 + 1);\n          soFar += centroid.weight;\n          this.#processed.push(centroid);\n        }\n      }\n      this.#min = Math.min(this.#min, this.#processed[0].mean);\n      this.#max = Math.max(\n        this.#max,\n        this.#processed[this.#processed.length - 1].mean,\n      );\n      this.#unprocessed.length = 0;\n    }\n  }\n\n  /**\n   * Centroids returns a copy of processed centroids.\n   * Useful when aggregating multiple t-digests.\n   *\n   * Centroids are appended to the passed CentroidList; if you're re-using a\n   * buffer, be sure to pass cl[:0].\n   */\n  centroids(cl: CentroidList = []): CentroidList {\n    this.#process();\n    return cl.concat(this.#processed);\n  }\n\n  count(): number {\n    this.#process();\n\n    // this.process always updates this.processedWeight to the total count of all\n    // centroids, so we don't need to re-count here.\n    return this.#processedWeight;\n  }\n\n  /**\n   * toJSON returns a JSON-serializable representation of the digest.\n   * This processes the digest and returns an object with compression and centroid data.\n   */\n  toJSON(): TDigestJSON {\n    this.#process();\n    const data: TDigestJSON = [this.compression];\n    for (const centroid of this.#processed) {\n      data.push(centroid.mean, centroid.weight);\n    }\n    return data;\n  }\n\n  #updateCumulative() {\n    // Weight can only increase, so the final cumulative value will always be\n    // either equal to, or less than, the total weight. If they are the same,\n    // then nothing has changed since the last update.\n    if (\n      this.#cumulative.length > 0 &&\n      this.#cumulative[this.#cumulative.length - 1] === this.#processedWeight\n    ) {\n      return;\n    }\n    const n = this.#processed.length + 1;\n    if (this.#cumulative.length > n) {\n      this.#cumulative.length = n;\n    }\n\n    let prev = 0;\n    for (let i = 0; i < this.#processed.length; i++) {\n      const centroid = this.#processed[i];\n      const cur = centroid.weight;\n      this.#cumulative[i] = prev + cur / 2;\n      prev += cur;\n    }\n    this.#cumulative[this.#processed.length] = prev;\n  }\n\n  // Quantile returns the (approximate) quantile of\n  // the distribution. Accepted values for q are between 0 and 1.\n  // Returns NaN if Count is zero or bad inputs.\n  quantile(q: number): number {\n    this.#process();\n    this.#updateCumulative();\n    if (q < 0 || q > 1 || this.#processed.length === 0) {\n      return NaN;\n    }\n    if (this.#processed.length === 1) {\n      return this.#processed[0].mean;\n    }\n    const index = q * this.#processedWeight;\n    if (index <= this.#processed[0].weight / 2) {\n      return (\n        this.#min +\n        ((2 * index) / this.#processed[0].weight) *\n          (this.#processed[0].mean - this.#min)\n      );\n    }\n\n    const lower = binarySearch(\n      this.#cumulative.length,\n      (i: number) => -this.#cumulative[i] + index,\n    );\n\n    if (lower + 1 !== this.#cumulative.length) {\n      const z1 = index - this.#cumulative[lower - 1];\n      const z2 = this.#cumulative[lower] - index;\n      return weightedAverage(\n        this.#processed[lower - 1].mean,\n        z2,\n        this.#processed[lower].mean,\n        z1,\n      );\n    }\n\n    const z1 =\n      index - this.#processedWeight - this.#processed[lower - 1].weight / 2;\n    const z2 = this.#processed[lower - 1].weight / 2 - z1;\n    return weightedAverage(\n      this.#processed[this.#processed.length - 1].mean,\n      z1,\n      this.#max,\n      z2,\n    );\n  }\n\n  /**\n   * CDF returns the cumulative distribution function for a given value x.\n   */\n  cdf(x: number): number {\n    this.#process();\n    this.#updateCumulative();\n    switch (this.#processed.length) {\n      case 0:\n        return 0;\n      case 1: {\n        const width = this.#max - this.#min;\n        if (x <= this.#min) {\n          return 0;\n        }\n        if (x >= this.#max) {\n          return 1;\n        }\n        if (x - this.#min <= width) {\n          // min and max are too close together to do any viable interpolation\n          return 0.5;\n        }\n        return (x - this.#min) / width;\n      }\n    }\n\n    if (x <= this.#min) {\n      return 0;\n    }\n    if (x >= this.#max) {\n      return 1;\n    }\n    const m0 = this.#processed[0].mean;\n    // Left Tail\n    if (x <= m0) {\n      if (m0 - this.#min > 0) {\n        return (\n          (((x - this.#min) / (m0 - this.#min)) * this.#processed[0].weight) /\n          this.#processedWeight /\n          2\n        );\n      }\n      return 0;\n    }\n    // Right Tail\n    const mn = this.#processed[this.#processed.length - 1].mean;\n    if (x >= mn) {\n      if (this.#max - mn > 0) {\n        return (\n          1 -\n          (((this.#max - x) / (this.#max - mn)) *\n            this.#processed[this.#processed.length - 1].weight) /\n            this.#processedWeight /\n            2\n        );\n      }\n      return 1;\n    }\n\n    const upper = binarySearch(\n      this.#processed.length,\n      // Treat equals as greater than, so we can use the upper index\n      // This is equivalent to:\n      //   i => this.#processed[i].mean > x ? -1 : 1,\n      i => x - this.#processed[i].mean || 1,\n    );\n\n    const z1 = x - this.#processed[upper - 1].mean;\n    const z2 = this.#processed[upper].mean - x;\n    return (\n      weightedAverage(\n        this.#cumulative[upper - 1],\n        z2,\n        this.#cumulative[upper],\n        z1,\n      ) / this.#processedWeight\n    );\n  }\n\n  #integratedQ(k: number): number {\n    return (\n      (Math.sin(\n        (Math.min(k, this.compression) * Math.PI) / this.compression -\n          Math.PI / 2,\n      ) +\n        1) /\n      2\n    );\n  }\n\n  #integratedLocation(q: number): number {\n    return (this.compression * (Math.asin(2 * q - 1) + Math.PI / 2)) / Math.PI;\n  }\n}\n\n// Calculate number of bytes needed for a tdigest of size c,\n// where c is the compression value\nexport function byteSizeForCompression(comp: number): number {\n  const c = comp | 0;\n  // // A centroid is 2 float64s, so we need 16 bytes for each centroid\n  // float_size := 8\n  // centroid_size := 2 * float_size\n\n  // // Unprocessed and processed can grow up to length c\n  // unprocessed_size := centroid_size * c\n  // processed_size := unprocessed_size\n\n  // // the cumulative field can also be of length c, but each item is a single float64\n  // cumulative_size := float_size * c // <- this could also be unprocessed_size / 2\n\n  // return unprocessed_size + processed_size + cumulative_size\n\n  // // or, more succinctly:\n  // return float_size * c * 5\n\n  // or even more succinctly\n  return c * 40;\n}\n\nfunction weightedAverage(\n  x1: number,\n  w1: number,\n  x2: number,\n  w2: number,\n): number {\n  if (x1 <= x2) {\n    return weightedAverageSorted(x1, w1, x2, w2);\n  }\n  return weightedAverageSorted(x2, w2, x1, w1);\n}\n\nfunction weightedAverageSorted(\n  x1: number,\n  w1: number,\n  x2: number,\n  w2: number,\n): number {\n  const x = (x1 * w1 + x2 * w2) / (w1 + w2);\n  return Math.max(x1, Math.min(x, x2));\n}\n\nfunction processedSize(size: number, compression: number): number {\n  if (size === 0) {\n    return Math.ceil(compression) * 2;\n  }\n  return size;\n}\n\nfunction unprocessedSize(size: number, compression: number): number {\n  if (size === 0) {\n    return Math.ceil(compression) * 8;\n  }\n  return size;\n}\n","import type {ValueType} from '../../zero-protocol/src/client-schema.ts';\nimport type {PrimaryKey} from '../../zero-protocol/src/primary-key.ts';\n\nexport type {ValueType} from '../../zero-protocol/src/client-schema.ts';\n\n/**\n * `related` calls need to know what the available relationships are.\n * The `schema` type encodes this information.\n */\nexport type SchemaValue<T = unknown> =\n  | {\n      type: ValueType;\n      serverName?: string | undefined;\n      optional?: boolean | undefined;\n    }\n  | SchemaValueWithCustomType<T>;\n\nexport type SchemaValueWithCustomType<T> = {\n  type: ValueType;\n  serverName?: string | undefined;\n  optional?: boolean;\n  customType: T;\n};\n\nexport type TableSchema = {\n  readonly name: string;\n  readonly serverName?: string | undefined;\n  readonly columns: Record<string, SchemaValue>;\n  readonly primaryKey: PrimaryKey;\n};\n\nexport type RelationshipsSchema = {\n  readonly [name: string]: Relationship;\n};\n\nexport type TypeNameToTypeMap = {\n  string: string;\n  number: number;\n  boolean: boolean;\n  null: null;\n\n  // In schema-v2, the user will be able to specify the TS type that\n  // the JSON should match and `any`` will no\n  // longer be used here.\n  // ReadOnlyJSONValue is not used as it causes\n  // infinite depth errors to pop up for users of our APIs.\n\n  // eslint-disable-next-line @typescript-eslint/no-explicit-any\n  json: any;\n};\n\nexport type ColumnTypeName<T extends SchemaValue | ValueType> =\n  T extends SchemaValue ? T['type'] : T;\n\n/**\n * Given a schema value, return the TypeScript type.\n *\n * This allows us to create the correct return type for a\n * query that has a selection.\n */\nexport type SchemaValueToTSType<T extends SchemaValue | ValueType> =\n  T extends ValueType\n    ? TypeNameToTypeMap[T]\n    : T extends {\n          optional: true;\n        }\n      ?\n          | (T extends SchemaValueWithCustomType<infer V>\n              ? V\n              : TypeNameToTypeMap[ColumnTypeName<T>])\n          | null\n      : T extends SchemaValueWithCustomType<infer V>\n        ? V\n        : TypeNameToTypeMap[ColumnTypeName<T>];\n\ntype Connection = {\n  readonly sourceField: readonly string[];\n  readonly destField: readonly string[];\n  readonly destSchema: string;\n  readonly cardinality: Cardinality;\n};\n\nexport type Cardinality = 'one' | 'many';\n\nexport type Relationship =\n  | readonly [Connection]\n  | readonly [Connection, Connection];\n// | readonly [Connection, Connection, Connection];\n\nexport type LastInTuple<T extends Relationship> = T extends readonly [infer L]\n  ? L\n  : T extends readonly [unknown, infer L]\n    ? L\n    : T extends readonly [unknown, unknown, infer L]\n      ? L\n      : never;\n\nexport type AtLeastOne<T> = readonly [T, ...T[]];\n\nexport function atLeastOne<T>(arr: readonly T[]): AtLeastOne<T> {\n  if (arr.length === 0) {\n    throw new Error('Expected at least one element');\n  }\n  return arr as AtLeastOne<T>;\n}\n\nexport function isOneHop(r: Relationship): r is readonly [Connection] {\n  return r.length === 1;\n}\n\nexport function isTwoHop(\n  r: Relationship,\n): r is readonly [Connection, Connection] {\n  return r.length === 2;\n}\n\nexport type Opaque<BaseType, BrandType = unknown> = BaseType & {\n  readonly [base]: BaseType;\n  readonly [brand]: BrandType;\n};\n\ndeclare const base: unique symbol;\ndeclare const brand: unique symbol;\n\nexport type IsOpaque<T> = T extends {\n  // eslint-disable-next-line @typescript-eslint/no-explicit-any\n  readonly [brand]: any;\n}\n  ? true\n  : false;\n\nexport type ExpandRecursiveSkipOpaque<T> =\n  IsOpaque<T> extends true\n    ? T\n    : T extends object\n      ? T extends infer O\n        ? {[K in keyof O]: ExpandRecursiveSkipOpaque<O[K]>}\n        : never\n      : T;\n","/* eslint-disable @typescript-eslint/no-explicit-any */\nimport type {Expand, ExpandRecursive} from '../../../shared/src/expand.ts';\nimport type {ReadonlyJSONValue} from '../../../shared/src/json.ts';\nimport {type AST, type SimpleOperator} from '../../../zero-protocol/src/ast.ts';\nimport type {Schema as ZeroSchema} from '../../../zero-schema/src/builder/schema-builder.ts';\nimport type {\n  LastInTuple,\n  SchemaValueToTSType,\n  SchemaValueWithCustomType,\n  TableSchema,\n} from '../../../zero-schema/src/table-schema.ts';\nimport type {Format, ViewFactory} from '../ivm/view.ts';\nimport type {ExpressionFactory, ParameterReference} from './expression.ts';\nimport type {CustomQueryID} from './named.ts';\nimport type {QueryDelegate} from './query-delegate.ts';\nimport type {TTL} from './ttl.ts';\nimport type {TypedView} from './typed-view.ts';\n\ntype Selector<E extends TableSchema> = keyof E['columns'];\nexport type NoCompoundTypeSelector<T extends TableSchema> = Exclude<\n  Selector<T>,\n  JsonSelectors<T> | ArraySelectors<T>\n>;\n\ntype JsonSelectors<E extends TableSchema> = {\n  [K in keyof E['columns']]: E['columns'][K] extends {type: 'json'} ? K : never;\n}[keyof E['columns']];\n\ntype ArraySelectors<E extends TableSchema> = {\n  [K in keyof E['columns']]: E['columns'][K] extends SchemaValueWithCustomType<\n    any[]\n  >\n    ? K\n    : never;\n}[keyof E['columns']];\n\nexport type QueryReturn<Q> = Q extends Query<any, any, infer R> ? R : never;\nexport type QueryTable<Q> = Q extends Query<any, infer T, any> ? T : never;\nexport const delegateSymbol = Symbol('delegate');\n\nexport type GetFilterType<\n  TSchema extends TableSchema,\n  TColumn extends keyof TSchema['columns'],\n  TOperator extends SimpleOperator,\n> = TOperator extends 'IS' | 'IS NOT'\n  ? // SchemaValueToTSType adds null if the type is optional, but we add null\n    // no matter what for dx reasons. See:\n    // https://github.com/rocicorp/mono/pull/3576#discussion_r1925792608\n    SchemaValueToTSType<TSchema['columns'][TColumn]> | null\n  : TOperator extends 'IN' | 'NOT IN'\n    ? // We don't want to compare to null in where clauses because it causes\n      // confusing results:\n      // https://zero.rocicorp.dev/docs/reading-data#comparing-to-null\n      readonly Exclude<SchemaValueToTSType<TSchema['columns'][TColumn]>, null>[]\n    : Exclude<SchemaValueToTSType<TSchema['columns'][TColumn]>, null>;\n\nexport type AvailableRelationships<\n  TTable extends string,\n  TSchema extends ZeroSchema,\n> = keyof TSchema['relationships'][TTable] & string;\n\nexport type DestTableName<\n  TTable extends string,\n  TSchema extends ZeroSchema,\n  TRelationship extends string,\n> = LastInTuple<TSchema['relationships'][TTable][TRelationship]>['destSchema'];\n\ntype DestRow<\n  TTable extends string,\n  TSchema extends ZeroSchema,\n  TRelationship extends string,\n> = TSchema['relationships'][TTable][TRelationship][0]['cardinality'] extends 'many'\n  ? PullRow<DestTableName<TTable, TSchema, TRelationship>, TSchema>\n  : PullRow<DestTableName<TTable, TSchema, TRelationship>, TSchema> | undefined;\n\ntype AddSubreturn<TExistingReturn, TSubselectReturn, TAs extends string> = {\n  readonly [K in TAs]: undefined extends TSubselectReturn\n    ? TSubselectReturn\n    : readonly TSubselectReturn[];\n} extends infer TNewRelationship\n  ? undefined extends TExistingReturn\n    ? (Exclude<TExistingReturn, undefined> & TNewRelationship) | undefined\n    : TExistingReturn & TNewRelationship\n  : never;\n\nexport type PullTableSchema<\n  TTable extends string,\n  TSchemas extends ZeroSchema,\n> = TSchemas['tables'][TTable];\n\nexport type PullRow<TTable extends string, TSchema extends ZeroSchema> = {\n  readonly [K in keyof PullTableSchema<\n    TTable,\n    TSchema\n  >['columns']]: SchemaValueToTSType<\n    PullTableSchema<TTable, TSchema>['columns'][K]\n  >;\n};\n\nexport type Row<T extends TableSchema | Query<ZeroSchema, string, any>> =\n  T extends TableSchema\n    ? {\n        readonly [K in keyof T['columns']]: SchemaValueToTSType<\n          T['columns'][K]\n        >;\n      }\n    : T extends Query<ZeroSchema, string, infer TReturn>\n      ? TReturn\n      : never;\n\n/**\n * A hybrid query that runs on both client and server.\n * Results are returned immediately from the client followed by authoritative\n * results from the server.\n *\n * Queries are transactional in that all queries update at once when a new transaction\n * has been committed on the client or server. No query results will reflect stale state.\n *\n * A query can be:\n * - {@linkcode materialize | materialize}\n * - awaited (`then`/{@linkcode run})\n * - {@linkcode preload | preloaded}\n *\n * The normal way to use a query would be through your UI framework's bindings (e.g., useQuery(q))\n * or within a custom mutator.\n *\n * `materialize` and `run/then` are provided for more advanced use cases.\n * Remember that any `view` returned by `materialize` must be destroyed.\n *\n * A query can be run as a 1-shot query by awaiting it. E.g.,\n *\n * ```ts\n * const result = await z.query.issue.limit(10);\n * ```\n *\n * For more information on how to use queries, see the documentation:\n * https://zero.rocicorp.dev/docs/reading-data\n *\n * @typeParam TSchema The database schema type extending ZeroSchema\n * @typeParam TTable The name of the table being queried, must be a key of TSchema['tables']\n * @typeParam TReturn The return type of the query, defaults to PullRow<TTable, TSchema>\n */\nexport interface Query<\n  TSchema extends ZeroSchema,\n  TTable extends keyof TSchema['tables'] & string,\n  TReturn = PullRow<TTable, TSchema>,\n> extends PromiseLike<HumanReadable<TReturn>> {\n  /**\n   * Format is used to specify the shape of the query results. This is used by\n   * {@linkcode one} and it also describes the shape when using\n   * {@linkcode related}.\n   */\n  readonly format: Format;\n\n  /**\n   * A string that uniquely identifies this query. This can be used to determine\n   * if two queries are the same.\n   *\n   * The hash of a custom query, on the client, is the hash of its AST.\n   * The hash of a custom query, on the server, is the hash of its name and args.\n   *\n   * The first allows many client-side queries to be pinned to the same backend query.\n   * The second ensures we do not invoke a named query on the backend more than once for the same `name:arg` pairing.\n   *\n   * If the query.hash was of `name:args` then `useQuery` would de-dupe\n   * queries with divergent ASTs.\n   *\n   * QueryManager will hash based on `name:args` since it is speaking with\n   * the server which tracks queries by `name:args`.\n   */\n  hash(): string;\n  readonly ast: AST;\n  readonly customQueryID: CustomQueryID | undefined;\n\n  nameAndArgs(\n    name: string,\n    args: ReadonlyArray<ReadonlyJSONValue>,\n  ): Query<TSchema, TTable, TReturn>;\n  [delegateSymbol](delegate: QueryDelegate): Query<TSchema, TTable, TReturn>;\n\n  /**\n   * Related is used to add a related query to the current query. This is used\n   * for subqueries and joins. These relationships are defined in the\n   * relationships section of the schema. The result of the query will\n   * include the related rows in the result set as a sub object of the row.\n   *\n   * ```typescript\n   * const row = await z.query.users\n   *   .related('posts');\n   * // {\n   * //   id: '1',\n   * //   posts: [\n   * //     ...\n   * //   ]\n   * // }\n   * ```\n   * If you want to add a subquery to the related query, you can do so by\n   * providing a callback function that receives the related query as an argument.\n   *\n   * ```typescript\n   * const row = await z.query.users\n   *   .related('posts', q => q.where('published', true));\n   * // {\n   * //   id: '1',\n   * //   posts: [\n   * //     {published: true, ...},\n   * //     ...\n   * //   ]\n   * // }\n   * ```\n   *\n   * @param relationship The name of the relationship\n   */\n  related<TRelationship extends AvailableRelationships<TTable, TSchema>>(\n    relationship: TRelationship,\n  ): Query<\n    TSchema,\n    TTable,\n    AddSubreturn<\n      TReturn,\n      DestRow<TTable, TSchema, TRelationship>,\n      TRelationship\n    >\n  >;\n  related<\n    TRelationship extends AvailableRelationships<TTable, TSchema>,\n    TSub extends Query<TSchema, string, any>,\n  >(\n    relationship: TRelationship,\n    cb: (\n      q: Query<\n        TSchema,\n        DestTableName<TTable, TSchema, TRelationship>,\n        DestRow<TTable, TSchema, TRelationship>\n      >,\n    ) => TSub,\n  ): Query<\n    TSchema,\n    TTable,\n    AddSubreturn<\n      TReturn,\n      TSub extends Query<TSchema, string, infer TSubReturn>\n        ? TSubReturn\n        : never,\n      TRelationship\n    >\n  >;\n\n  /**\n   * Represents a condition to filter the query results.\n   *\n   * @param field The column name to filter on.\n   * @param op The operator to use for filtering.\n   * @param value The value to compare against.\n   *\n   * @returns A new query instance with the applied filter.\n   *\n   * @example\n   *\n   * ```typescript\n   * const query = db.query('users')\n   *   .where('age', '>', 18)\n   *   .where('name', 'LIKE', '%John%');\n   * ```\n   */\n  where<\n    TSelector extends NoCompoundTypeSelector<PullTableSchema<TTable, TSchema>>,\n    TOperator extends SimpleOperator,\n  >(\n    field: TSelector,\n    op: TOperator,\n    value:\n      | GetFilterType<PullTableSchema<TTable, TSchema>, TSelector, TOperator>\n      | ParameterReference,\n  ): Query<TSchema, TTable, TReturn>;\n  /**\n   * Represents a condition to filter the query results.\n   *\n   * This overload is used when the operator is '='.\n   *\n   * @param field The column name to filter on.\n   * @param value The value to compare against.\n   *\n   * @returns A new query instance with the applied filter.\n   *\n   * @example\n   * ```typescript\n   * const query = db.query('users')\n   *  .where('age', 18)\n   * ```\n   */\n  where<\n    TSelector extends NoCompoundTypeSelector<PullTableSchema<TTable, TSchema>>,\n  >(\n    field: TSelector,\n    value:\n      | GetFilterType<PullTableSchema<TTable, TSchema>, TSelector, '='>\n      | ParameterReference,\n  ): Query<TSchema, TTable, TReturn>;\n\n  /**\n   * Represents a condition to filter the query results.\n   *\n   * @param expressionFactory A function that takes a query builder and returns an expression.\n   *\n   * @returns A new query instance with the applied filter.\n   *\n   * @example\n   * ```typescript\n   * const query = db.query('users')\n   *   .where(({cmp, or}) => or(cmp('age', '>', 18), cmp('name', 'LIKE', '%John%')));\n   * ```\n   */\n  where(\n    expressionFactory: ExpressionFactory<TSchema, TTable>,\n  ): Query<TSchema, TTable, TReturn>;\n\n  whereExists(\n    relationship: AvailableRelationships<TTable, TSchema>,\n  ): Query<TSchema, TTable, TReturn>;\n  whereExists<TRelationship extends AvailableRelationships<TTable, TSchema>>(\n    relationship: TRelationship,\n    cb: (\n      q: Query<TSchema, DestTableName<TTable, TSchema, TRelationship>>,\n    ) => Query<TSchema, string>,\n  ): Query<TSchema, TTable, TReturn>;\n\n  /**\n   * Skips the rows of the query until row matches the given row. If opts is\n   * provided, it determines whether the match is inclusive.\n   *\n   * @param row The row to start from. This is a partial row object and only the provided\n   *            fields will be used for the comparison.\n   * @param opts Optional options object that specifies whether the match is inclusive.\n   *             If `inclusive` is true, the row will be included in the result.\n   *             If `inclusive` is false, the row will be excluded from the result and the result\n   *             will start from the next row.\n   *\n   * @returns A new query instance with the applied start condition.\n   */\n  start(\n    row: Partial<PullRow<TTable, TSchema>>,\n    opts?: {inclusive: boolean} | undefined,\n  ): Query<TSchema, TTable, TReturn>;\n\n  /**\n   * Limits the number of rows returned by the query.\n   * @param limit The maximum number of rows to return.\n   *\n   * @returns A new query instance with the applied limit.\n   */\n  limit(limit: number): Query<TSchema, TTable, TReturn>;\n\n  /**\n   * Orders the results by a specified column. If multiple orderings are\n   * specified, the results will be ordered by the first column, then the\n   * second column, and so on.\n   *\n   * @param field The column name to order by.\n   * @param direction The direction to order the results (ascending or descending).\n   *\n   * @returns A new query instance with the applied order.\n   */\n  orderBy<TSelector extends Selector<PullTableSchema<TTable, TSchema>>>(\n    field: TSelector,\n    direction: 'asc' | 'desc',\n  ): Query<TSchema, TTable, TReturn>;\n\n  /**\n   * Limits the number of rows returned by the query to a single row and then\n   * unpacks the result so that you do not get an array of rows but a single\n   * row. This is useful when you expect only one row to be returned and want to\n   * work with the row directly.\n   *\n   * If the query returns no rows, the result will be `undefined`.\n   *\n   * @returns A new query instance with the applied limit to one row.\n   */\n  one(): Query<TSchema, TTable, TReturn | undefined>;\n\n  /**\n   * Creates a materialized view of the query. This is a view that will be kept\n   * in memory and updated as the query results change.\n   *\n   * Most of the time you will want to use the `useQuery` hook or the\n   * `run`/`then` method to get the results of a query. This method is only\n   * needed if you want to access to lower level APIs of the view.\n   *\n   * @param ttl Time To Live. This is the amount of time to keep the rows\n   *            associated with this query after `TypedView.destroy`\n   *            has been called.\n   */\n  materialize(ttl?: TTL): TypedView<HumanReadable<TReturn>>;\n  /**\n   * Creates a custom materialized view using a provided factory function. This\n   * allows framework-specific bindings (like SolidJS, Vue, etc.) to create\n   * optimized views.\n   *\n   * @param factory A function that creates a custom view implementation\n   * @param ttl Optional Time To Live for the view's data after destruction\n   * @returns A custom view instance of type {@linkcode T}\n   *\n   * @example\n   * ```ts\n   * const view = query.materialize(createSolidViewFactory, '1m');\n   * ```\n   */\n  materialize<T>(\n    factory: ViewFactory<TSchema, TTable, TReturn, T>,\n    ttl?: TTL,\n  ): T;\n\n  /**\n   * Executes the query and returns the result once. The `options` parameter\n   * specifies whether to wait for complete results or return immediately,\n   * and the time to live for the query.\n   *\n   * - `{type: 'unknown'}`: Returns a snapshot of the data immediately.\n   * - `{type: 'complete'}`: Waits for the latest, complete results from the server.\n   *\n   * By default, `run` uses `{type: 'unknown'}` to avoid waiting for the server.\n   *\n   * `Query` implements `PromiseLike`, and calling `then` on it will invoke `run`\n   * with the default behavior (`unknown`).\n   *\n   * @param options Options to control the result type.\n   * @param options.type The type of result to return.\n   * @param options.ttl Time To Live. This is the amount of time to keep the rows\n   *                  associated with this query after the returned promise has\n   *                  resolved.\n   * @returns A promise resolving to the query result.\n   *\n   * @example\n   * ```js\n   * const result = await query.run({type: 'complete', ttl: '1m'});\n   * ```\n   */\n  run(options?: RunOptions): Promise<HumanReadable<TReturn>>;\n\n  /**\n   * Preload loads the data into the clients cache without keeping it in memory.\n   * This is useful for preloading data that will be used later.\n   *\n   * @param options Options for preloading the query.\n   * @param options.ttl Time To Live. This is the amount of time to keep the rows\n   *                  associated with this query after {@linkcode cleanup} has\n   *                  been called.\n   */\n  preload(options?: PreloadOptions): {\n    cleanup: () => void;\n    complete: Promise<void>;\n  };\n}\n\nexport type PreloadOptions = {\n  /**\n   * Time To Live. This is the amount of time to keep the rows associated with\n   * this query after {@linkcode cleanup} has been called.\n   */\n  ttl?: TTL | undefined;\n};\n\nexport type MaterializeOptions = PreloadOptions;\n\n/**\n * A helper type that tries to make the type more readable.\n */\nexport type HumanReadable<T> = undefined extends T ? Expand<T> : Expand<T>[];\n\n/**\n * A helper type that tries to make the type more readable.\n */\n// Note: opaque types expand incorrectly.\nexport type HumanReadableRecursive<T> = undefined extends T\n  ? ExpandRecursive<T>\n  : ExpandRecursive<T>[];\n\n/**\n * The kind of results we want to wait for when using {@linkcode run} on {@linkcode Query}.\n *\n * `unknown` means we don't want to wait for the server to return results. The result is a\n * snapshot of the data at the time the query was run.\n *\n * `complete` means we want to ensure that we have the latest result from the server. The\n * result is a complete and up-to-date view of the data. In some cases this means that we\n * have to wait for the server to return results. To ensure that we have the result for\n * this query you can preload it before calling run. See {@link preload}.\n *\n * By default, `run` uses `{type: 'unknown'}` to avoid waiting for the server.\n *\n * The `ttl` option is used to specify the time to live for the query. This is the amount of\n * time to keep the rows associated with this query after the promise has resolved.\n */\nexport type RunOptions = {\n  type: 'unknown' | 'complete';\n  ttl?: TTL;\n};\n\nexport const DEFAULT_RUN_OPTIONS_UNKNOWN = {\n  type: 'unknown',\n} as const;\n\nexport const DEFAULT_RUN_OPTIONS_COMPLETE = {\n  type: 'complete',\n} as const;\n","/* eslint-disable @typescript-eslint/naming-convention */\n/* eslint-disable @typescript-eslint/no-explicit-any */\nimport {resolver} from '@rocicorp/resolver';\nimport {assert} from '../../../shared/src/asserts.ts';\nimport type {ReadonlyJSONValue} from '../../../shared/src/json.ts';\nimport {must} from '../../../shared/src/must.ts';\nimport type {Writable} from '../../../shared/src/writable.ts';\nimport type {\n  AST,\n  CompoundKey,\n  Condition,\n  Ordering,\n  Parameter,\n  SimpleOperator,\n  System,\n} from '../../../zero-protocol/src/ast.ts';\nimport type {Row as IVMRow} from '../../../zero-protocol/src/data.ts';\nimport {\n  hashOfAST,\n  hashOfNameAndArgs,\n} from '../../../zero-protocol/src/query-hash.ts';\nimport type {Schema} from '../../../zero-schema/src/builder/schema-builder.ts';\nimport {\n  isOneHop,\n  isTwoHop,\n  type TableSchema,\n} from '../../../zero-schema/src/table-schema.ts';\nimport {buildPipeline} from '../builder/builder.ts';\nimport {NotImplementedError} from '../error.ts';\nimport {ArrayView} from '../ivm/array-view.ts';\nimport type {Input} from '../ivm/operator.ts';\nimport type {Format, ViewFactory} from '../ivm/view.ts';\nimport {assertNoNotExists} from './assert-no-not-exists.ts';\nimport {\n  and,\n  cmp,\n  ExpressionBuilder,\n  simplifyCondition,\n  type ExpressionFactory,\n} from './expression.ts';\nimport type {CustomQueryID} from './named.ts';\nimport type {GotCallback, QueryDelegate} from './query-delegate.ts';\nimport {\n  delegateSymbol,\n  type GetFilterType,\n  type HumanReadable,\n  type MaterializeOptions,\n  type PreloadOptions,\n  type PullRow,\n  type Query,\n  type QueryReturn,\n  type QueryTable,\n  type RunOptions,\n} from './query.ts';\nimport {DEFAULT_PRELOAD_TTL_MS, DEFAULT_TTL_MS, type TTL} from './ttl.ts';\nimport type {TypedView} from './typed-view.ts';\n\nexport type AnyQuery = Query<Schema, string, any>;\n\nexport function materialize<S extends Schema, T, Q>(\n  query: Q,\n  delegate: QueryDelegate,\n  factoryOrOptions?:\n    | ViewFactory<S, QueryTable<Q>, QueryReturn<Q>, T>\n    | MaterializeOptions\n    | undefined,\n  maybeOptions?: MaterializeOptions | undefined,\n) {\n  if (typeof factoryOrOptions === 'function') {\n    return (\n      (query as AnyQuery)\n        // eslint-disable-next-line no-unexpected-multiline\n        [delegateSymbol](delegate)\n        .materialize(factoryOrOptions, maybeOptions?.ttl)\n    );\n  }\n  return (\n    (query as AnyQuery)\n      // eslint-disable-next-line no-unexpected-multiline\n      [delegateSymbol](delegate)\n      .materialize(factoryOrOptions?.ttl)\n  );\n}\n\nconst astSymbol = Symbol();\n\nexport function ast(query: AnyQuery): AST {\n  return (query as AbstractQuery<Schema, string>)[astSymbol];\n}\n\nexport function newQuery<\n  TSchema extends Schema,\n  TTable extends keyof TSchema['tables'] & string,\n>(\n  delegate: QueryDelegate | undefined,\n  schema: TSchema,\n  table: TTable,\n): Query<TSchema, TTable> {\n  return new QueryImpl(\n    delegate,\n    schema,\n    table,\n    {table},\n    defaultFormat,\n    undefined,\n  );\n}\n\nexport function staticParam(\n  anchorClass: 'authData' | 'preMutationRow',\n  field: string | string[],\n): Parameter {\n  return {\n    type: 'static',\n    anchor: anchorClass,\n    // for backwards compatibility\n    field: field.length === 1 ? field[0] : field,\n  };\n}\n\nexport const SUBQ_PREFIX = 'zsubq_';\n\nexport const defaultFormat = {singular: false, relationships: {}} as const;\n\nexport const newQuerySymbol = Symbol();\n\nexport abstract class AbstractQuery<\n  TSchema extends Schema,\n  TTable extends keyof TSchema['tables'] & string,\n  TReturn = PullRow<TTable, TSchema>,\n> implements Query<TSchema, TTable, TReturn>\n{\n  readonly #schema: TSchema;\n  protected readonly _delegate: QueryDelegate | undefined;\n  readonly #tableName: TTable;\n  readonly _ast: AST;\n  readonly format: Format;\n  #hash: string = '';\n  readonly #system: System;\n  readonly #currentJunction: string | undefined;\n  readonly customQueryID: CustomQueryID | undefined;\n\n  constructor(\n    delegate: QueryDelegate | undefined,\n    schema: TSchema,\n    tableName: TTable,\n    ast: AST,\n    format: Format,\n    system: System,\n    customQueryID: CustomQueryID | undefined,\n    currentJunction?: string | undefined,\n  ) {\n    this.#schema = schema;\n    this._delegate = delegate;\n    this.#tableName = tableName;\n    this._ast = ast;\n    this.format = format;\n    this.#system = system;\n    this.#currentJunction = currentJunction;\n    this.customQueryID = customQueryID;\n  }\n\n  [delegateSymbol](delegate: QueryDelegate): Query<TSchema, TTable, TReturn> {\n    return this[newQuerySymbol](\n      delegate,\n      this.#schema,\n      this.#tableName,\n      this._ast,\n      this.format,\n      this.customQueryID,\n      this.#currentJunction,\n    );\n  }\n\n  nameAndArgs(\n    name: string,\n    args: ReadonlyArray<ReadonlyJSONValue>,\n  ): Query<TSchema, TTable, TReturn> {\n    return this[newQuerySymbol](\n      this._delegate,\n      this.#schema,\n      this.#tableName,\n      this._ast,\n      this.format,\n      {\n        name,\n        args: args as ReadonlyArray<ReadonlyJSONValue>,\n      },\n      this.#currentJunction,\n    );\n  }\n\n  get [astSymbol](): AST {\n    return this._ast;\n  }\n\n  get ast() {\n    return this._completeAst();\n  }\n\n  hash(): string {\n    if (!this.#hash) {\n      this.#hash = hashOfAST(this._completeAst());\n    }\n    return this.#hash;\n  }\n\n  // TODO(arv): Put this in the delegate?\n  protected abstract [newQuerySymbol]<\n    TSchema extends Schema,\n    TTable extends keyof TSchema['tables'] & string,\n    TReturn,\n  >(\n    delegate: QueryDelegate | undefined,\n    schema: TSchema,\n    table: TTable,\n    ast: AST,\n    format: Format,\n    customQueryID: CustomQueryID | undefined,\n    currentJunction: string | undefined,\n  ): AbstractQuery<TSchema, TTable, TReturn>;\n\n  one = (): Query<TSchema, TTable, TReturn | undefined> =>\n    this[newQuerySymbol](\n      this._delegate,\n      this.#schema,\n      this.#tableName,\n      {\n        ...this._ast,\n        limit: 1,\n      },\n      {\n        ...this.format,\n        singular: true,\n      },\n      this.customQueryID,\n      this.#currentJunction,\n    );\n\n  whereExists = (\n    relationship: string,\n    cb?: (q: AnyQuery) => AnyQuery,\n  ): Query<TSchema, TTable, TReturn> =>\n    this.where(({exists}) => exists(relationship, cb));\n\n  related = (\n    relationship: string,\n    cb?: (q: AnyQuery) => AnyQuery,\n  ): AnyQuery => {\n    if (relationship.startsWith(SUBQ_PREFIX)) {\n      throw new Error(\n        `Relationship names may not start with \"${SUBQ_PREFIX}\". That is a reserved prefix.`,\n      );\n    }\n    cb = cb ?? (q => q);\n\n    const related = this.#schema.relationships[this.#tableName][relationship];\n    assert(related, 'Invalid relationship');\n    if (isOneHop(related)) {\n      const {destSchema, destField, sourceField, cardinality} = related[0];\n      let q: AnyQuery = this[newQuerySymbol](\n        this._delegate,\n        this.#schema,\n        destSchema,\n        {\n          table: destSchema,\n          alias: relationship,\n        },\n        {\n          relationships: {},\n          singular: cardinality === 'one',\n        },\n        this.customQueryID,\n        undefined,\n      ) as AnyQuery;\n      if (cardinality === 'one') {\n        q = q.one();\n      }\n      const sq = cb(q) as AbstractQuery<Schema, string>;\n      assert(\n        isCompoundKey(sourceField),\n        'The source of a relationship must specify at last 1 field',\n      );\n      assert(\n        isCompoundKey(destField),\n        'The destination of a relationship must specify at last 1 field',\n      );\n      assert(\n        sourceField.length === destField.length,\n        'The source and destination of a relationship must have the same number of fields',\n      );\n\n      return this[newQuerySymbol](\n        this._delegate,\n        this.#schema,\n        this.#tableName,\n        {\n          ...this._ast,\n          related: [\n            ...(this._ast.related ?? []),\n            {\n              system: this.#system,\n              correlation: {\n                parentField: sourceField,\n                childField: destField,\n              },\n              subquery: addPrimaryKeysToAst(\n                this.#schema.tables[destSchema],\n                sq._ast,\n              ),\n            },\n          ],\n        },\n        {\n          ...this.format,\n          relationships: {\n            ...this.format.relationships,\n            [relationship]: sq.format,\n          },\n        },\n        this.customQueryID,\n        this.#currentJunction,\n      );\n    }\n\n    if (isTwoHop(related)) {\n      const [firstRelation, secondRelation] = related;\n      const {destSchema} = secondRelation;\n      const junctionSchema = firstRelation.destSchema;\n      const sq = cb(\n        this[newQuerySymbol](\n          this._delegate,\n          this.#schema,\n          destSchema,\n          {\n            table: destSchema,\n            alias: relationship,\n          },\n          {\n            relationships: {},\n            singular: secondRelation.cardinality === 'one',\n          },\n          this.customQueryID,\n          relationship,\n        ),\n      ) as unknown as QueryImpl<Schema, string>;\n\n      assert(isCompoundKey(firstRelation.sourceField), 'Invalid relationship');\n      assert(isCompoundKey(firstRelation.destField), 'Invalid relationship');\n      assert(isCompoundKey(secondRelation.sourceField), 'Invalid relationship');\n      assert(isCompoundKey(secondRelation.destField), 'Invalid relationship');\n\n      return this[newQuerySymbol](\n        this._delegate,\n        this.#schema,\n        this.#tableName,\n        {\n          ...this._ast,\n          related: [\n            ...(this._ast.related ?? []),\n            {\n              system: this.#system,\n              correlation: {\n                parentField: firstRelation.sourceField,\n                childField: firstRelation.destField,\n              },\n              hidden: true,\n              subquery: {\n                table: junctionSchema,\n                alias: relationship,\n                orderBy: addPrimaryKeys(\n                  this.#schema.tables[junctionSchema],\n                  undefined,\n                ),\n                related: [\n                  {\n                    system: this.#system,\n                    correlation: {\n                      parentField: secondRelation.sourceField,\n                      childField: secondRelation.destField,\n                    },\n                    subquery: addPrimaryKeysToAst(\n                      this.#schema.tables[destSchema],\n                      sq._ast,\n                    ),\n                  },\n                ],\n              },\n            },\n          ],\n        },\n        {\n          ...this.format,\n          relationships: {\n            ...this.format.relationships,\n            [relationship]: sq.format,\n          },\n        },\n        this.customQueryID,\n        this.#currentJunction,\n      );\n    }\n\n    throw new Error(`Invalid relationship ${relationship}`);\n  };\n\n  where = (\n    fieldOrExpressionFactory: string | ExpressionFactory<TSchema, TTable>,\n    opOrValue?: SimpleOperator | GetFilterType<any, any, any> | Parameter,\n    value?: GetFilterType<any, any, any> | Parameter,\n  ): Query<TSchema, TTable, TReturn> => {\n    let cond: Condition;\n\n    if (typeof fieldOrExpressionFactory === 'function') {\n      cond = fieldOrExpressionFactory(\n        new ExpressionBuilder(this._exists) as ExpressionBuilder<\n          TSchema,\n          TTable\n        >,\n      );\n    } else {\n      assert(opOrValue !== undefined, 'Invalid condition');\n      cond = cmp(fieldOrExpressionFactory, opOrValue, value);\n    }\n\n    const existingWhere = this._ast.where;\n    if (existingWhere) {\n      cond = and(existingWhere, cond);\n    }\n\n    const where = simplifyCondition(cond);\n\n    if (this.#system === 'client') {\n      // We need to do this after the DNF since the DNF conversion might change\n      // an EXISTS to a NOT EXISTS condition (and vice versa).\n      assertNoNotExists(where);\n    }\n\n    return this[newQuerySymbol](\n      this._delegate,\n      this.#schema,\n      this.#tableName,\n      {\n        ...this._ast,\n        where,\n      },\n      this.format,\n      this.customQueryID,\n      this.#currentJunction,\n    );\n  };\n\n  start = (\n    row: Partial<PullRow<TTable, TSchema>>,\n    opts?: {inclusive: boolean} | undefined,\n  ): Query<TSchema, TTable, TReturn> =>\n    this[newQuerySymbol](\n      this._delegate,\n      this.#schema,\n      this.#tableName,\n      {\n        ...this._ast,\n        start: {\n          row,\n          exclusive: !opts?.inclusive,\n        },\n      },\n      this.format,\n      this.customQueryID,\n      this.#currentJunction,\n    );\n\n  limit = (limit: number): Query<TSchema, TTable, TReturn> => {\n    if (limit < 0) {\n      throw new Error('Limit must be non-negative');\n    }\n    if ((limit | 0) !== limit) {\n      throw new Error('Limit must be an integer');\n    }\n    if (this.#currentJunction) {\n      throw new NotImplementedError(\n        'Limit is not supported in junction relationships yet. Junction relationship being limited: ' +\n          this.#currentJunction,\n      );\n    }\n\n    return this[newQuerySymbol](\n      this._delegate,\n      this.#schema,\n      this.#tableName,\n      {\n        ...this._ast,\n        limit,\n      },\n      this.format,\n      this.customQueryID,\n      this.#currentJunction,\n    );\n  };\n\n  orderBy = <TSelector extends keyof TSchema['tables'][TTable]['columns']>(\n    field: TSelector,\n    direction: 'asc' | 'desc',\n  ): Query<TSchema, TTable, TReturn> => {\n    if (this.#currentJunction) {\n      throw new NotImplementedError(\n        'Order by is not supported in junction relationships yet. Junction relationship being ordered: ' +\n          this.#currentJunction,\n      );\n    }\n    return this[newQuerySymbol](\n      this._delegate,\n      this.#schema,\n      this.#tableName,\n      {\n        ...this._ast,\n        orderBy: [...(this._ast.orderBy ?? []), [field as string, direction]],\n      },\n      this.format,\n      this.customQueryID,\n      this.#currentJunction,\n    );\n  };\n\n  protected _exists = (\n    relationship: string,\n    cb: (query: AnyQuery) => AnyQuery = q => q,\n  ): Condition => {\n    const related = this.#schema.relationships[this.#tableName][relationship];\n    assert(related, 'Invalid relationship');\n\n    if (isOneHop(related)) {\n      const {destSchema, sourceField, destField} = related[0];\n      assert(isCompoundKey(sourceField), 'Invalid relationship');\n      assert(isCompoundKey(destField), 'Invalid relationship');\n\n      const sq = cb(\n        this[newQuerySymbol](\n          this._delegate,\n          this.#schema,\n          destSchema,\n          {\n            table: destSchema,\n            alias: `${SUBQ_PREFIX}${relationship}`,\n          },\n          defaultFormat,\n          this.customQueryID,\n          undefined,\n        ),\n      ) as unknown as QueryImpl<any, any>;\n      return {\n        type: 'correlatedSubquery',\n        related: {\n          system: this.#system,\n          correlation: {\n            parentField: sourceField,\n            childField: destField,\n          },\n          subquery: addPrimaryKeysToAst(\n            this.#schema.tables[destSchema],\n            sq._ast,\n          ),\n        },\n        op: 'EXISTS',\n      };\n    }\n\n    if (isTwoHop(related)) {\n      const [firstRelation, secondRelation] = related;\n      assert(isCompoundKey(firstRelation.sourceField), 'Invalid relationship');\n      assert(isCompoundKey(firstRelation.destField), 'Invalid relationship');\n      assert(isCompoundKey(secondRelation.sourceField), 'Invalid relationship');\n      assert(isCompoundKey(secondRelation.destField), 'Invalid relationship');\n      const {destSchema} = secondRelation;\n      const junctionSchema = firstRelation.destSchema;\n      const queryToDest = cb(\n        this[newQuerySymbol](\n          this._delegate,\n          this.#schema,\n          destSchema,\n          {\n            table: destSchema,\n            alias: `${SUBQ_PREFIX}zhidden_${relationship}`,\n          },\n          defaultFormat,\n          this.customQueryID,\n          relationship,\n        ) as AnyQuery,\n      );\n\n      return {\n        type: 'correlatedSubquery',\n        related: {\n          system: this.#system,\n          correlation: {\n            parentField: firstRelation.sourceField,\n            childField: firstRelation.destField,\n          },\n          subquery: {\n            table: junctionSchema,\n            alias: `${SUBQ_PREFIX}${relationship}`,\n            orderBy: addPrimaryKeys(\n              this.#schema.tables[junctionSchema],\n              undefined,\n            ),\n            where: {\n              type: 'correlatedSubquery',\n              related: {\n                system: this.#system,\n                correlation: {\n                  parentField: secondRelation.sourceField,\n                  childField: secondRelation.destField,\n                },\n\n                subquery: addPrimaryKeysToAst(\n                  this.#schema.tables[destSchema],\n                  (queryToDest as QueryImpl<any, any>)._ast,\n                ),\n              },\n              op: 'EXISTS',\n            },\n          },\n        },\n        op: 'EXISTS',\n      };\n    }\n\n    throw new Error(`Invalid relationship ${relationship}`);\n  };\n\n  #completedAST: AST | undefined;\n\n  protected _completeAst(): AST {\n    if (!this.#completedAST) {\n      const finalOrderBy = addPrimaryKeys(\n        this.#schema.tables[this.#tableName],\n        this._ast.orderBy,\n      );\n      if (this._ast.start) {\n        const {row} = this._ast.start;\n        const narrowedRow: Writable<IVMRow> = {};\n        for (const [field] of finalOrderBy) {\n          narrowedRow[field] = row[field];\n        }\n        this.#completedAST = {\n          ...this._ast,\n          start: {\n            ...this._ast.start,\n            row: narrowedRow,\n          },\n          orderBy: finalOrderBy,\n        };\n      } else {\n        this.#completedAST = {\n          ...this._ast,\n          orderBy: addPrimaryKeys(\n            this.#schema.tables[this.#tableName],\n            this._ast.orderBy,\n          ),\n        };\n      }\n    }\n    return this.#completedAST;\n  }\n\n  then<TResult1 = HumanReadable<TReturn>, TResult2 = never>(\n    onFulfilled?:\n      | ((value: HumanReadable<TReturn>) => TResult1 | PromiseLike<TResult1>)\n      | undefined\n      | null,\n    onRejected?:\n      | ((reason: any) => TResult2 | PromiseLike<TResult2>)\n      | undefined\n      | null,\n  ): PromiseLike<TResult1 | TResult2> {\n    return this.run().then(onFulfilled, onRejected);\n  }\n\n  abstract materialize(\n    ttl?: TTL | undefined,\n  ): TypedView<HumanReadable<TReturn>>;\n  abstract materialize<T>(\n    factory: ViewFactory<TSchema, TTable, TReturn, T>,\n    ttl?: TTL | undefined,\n  ): T;\n\n  abstract run(options?: RunOptions): Promise<HumanReadable<TReturn>>;\n\n  abstract preload(): {\n    cleanup: () => void;\n    complete: Promise<void>;\n  };\n}\n\nconst completedAstSymbol = Symbol();\n\nexport function completedAST(q: Query<Schema, string, any>) {\n  return (q as QueryImpl<Schema, string>)[completedAstSymbol];\n}\n\nexport class QueryImpl<\n  TSchema extends Schema,\n  TTable extends keyof TSchema['tables'] & string,\n  TReturn = PullRow<TTable, TSchema>,\n> extends AbstractQuery<TSchema, TTable, TReturn> {\n  readonly #system: System;\n\n  constructor(\n    delegate: QueryDelegate | undefined,\n    schema: TSchema,\n    tableName: TTable,\n    ast: AST = {table: tableName},\n    format: Format = defaultFormat,\n    system: System = 'client',\n    customQueryID?: CustomQueryID | undefined,\n    currentJunction?: string | undefined,\n  ) {\n    super(\n      delegate,\n      schema,\n      tableName,\n      ast,\n      format,\n      system,\n      customQueryID,\n      currentJunction,\n    );\n    this.#system = system;\n  }\n\n  get [completedAstSymbol](): AST {\n    return this._completeAst();\n  }\n\n  protected [newQuerySymbol]<\n    TSchema extends Schema,\n    TTable extends string,\n    TReturn,\n  >(\n    delegate: QueryDelegate | undefined,\n    schema: TSchema,\n    tableName: TTable,\n    ast: AST,\n    format: Format,\n    customQueryID: CustomQueryID | undefined,\n    currentJunction: string | undefined,\n  ): QueryImpl<TSchema, TTable, TReturn> {\n    return new QueryImpl(\n      delegate,\n      schema,\n      tableName,\n      ast,\n      format,\n      this.#system,\n      customQueryID,\n      currentJunction,\n    );\n  }\n\n  materialize<T>(\n    factoryOrTTL?: ViewFactory<TSchema, TTable, TReturn, T> | TTL,\n    ttl: TTL = DEFAULT_TTL_MS,\n  ): T {\n    const delegate = must(\n      this._delegate,\n      'materialize requires a query delegate to be set',\n    );\n    let factory: ViewFactory<TSchema, TTable, TReturn, T> | undefined;\n    if (typeof factoryOrTTL === 'function') {\n      factory = factoryOrTTL;\n    } else {\n      ttl = factoryOrTTL ?? DEFAULT_TTL_MS;\n    }\n    const ast = this._completeAst();\n    const queryID = this.customQueryID\n      ? hashOfNameAndArgs(this.customQueryID.name, this.customQueryID.args)\n      : this.hash();\n    const queryCompleteResolver = resolver<true>();\n    let queryComplete = delegate.defaultQueryComplete;\n    const updateTTL = (newTTL: TTL) => {\n      this.customQueryID\n        ? delegate.updateCustomQuery(this.customQueryID, newTTL)\n        : delegate.updateServerQuery(ast, newTTL);\n    };\n\n    const gotCallback: GotCallback = got => {\n      if (got) {\n        delegate.addMetric(\n          'query-materialization-end-to-end',\n          performance.now() - t0,\n          queryID,\n          ast,\n        );\n        queryComplete = true;\n        queryCompleteResolver.resolve(true);\n      }\n    };\n\n    let removeCommitObserver: (() => void) | undefined;\n    const onDestroy = () => {\n      input.destroy();\n      removeCommitObserver?.();\n      removeAddedQuery();\n    };\n\n    const t0 = performance.now();\n\n    const removeAddedQuery = this.customQueryID\n      ? delegate.addCustomQuery(ast, this.customQueryID, ttl, gotCallback)\n      : delegate.addServerQuery(ast, ttl, gotCallback);\n\n    const input = buildPipeline(ast, delegate, queryID);\n\n    const view = delegate.batchViewUpdates(() =>\n      (factory ?? arrayViewFactory)(\n        this,\n        input,\n        this.format,\n        onDestroy,\n        cb => {\n          removeCommitObserver = delegate.onTransactionCommit(cb);\n        },\n        queryComplete || queryCompleteResolver.promise,\n        updateTTL,\n      ),\n    );\n\n    delegate.addMetric(\n      'query-materialization-client',\n      performance.now() - t0,\n      queryID,\n    );\n\n    return view as T;\n  }\n\n  run(options?: RunOptions): Promise<HumanReadable<TReturn>> {\n    const delegate = must(\n      this._delegate,\n      'run requires a query delegate to be set',\n    );\n    delegate.assertValidRunOptions(options);\n    const v: TypedView<HumanReadable<TReturn>> = this.materialize(options?.ttl);\n    if (options?.type === 'complete') {\n      return new Promise(resolve => {\n        v.addListener((data, type) => {\n          if (type === 'complete') {\n            v.destroy();\n            resolve(data as HumanReadable<TReturn>);\n          }\n        });\n      });\n    }\n\n    options?.type satisfies 'unknown' | undefined;\n\n    const ret = v.data;\n    v.destroy();\n    return Promise.resolve(ret);\n  }\n\n  preload(options?: PreloadOptions): {\n    cleanup: () => void;\n    complete: Promise<void>;\n  } {\n    const delegate = must(\n      this._delegate,\n      'preload requires a query delegate to be set',\n    );\n    const ttl = options?.ttl ?? DEFAULT_PRELOAD_TTL_MS;\n    const ast = this._completeAst();\n    const {resolve, promise: complete} = resolver<void>();\n    if (this.customQueryID) {\n      const cleanup = delegate.addCustomQuery(\n        ast,\n        this.customQueryID,\n        ttl,\n        got => {\n          if (got) {\n            resolve();\n          }\n        },\n      );\n      return {\n        cleanup,\n        complete,\n      };\n    }\n\n    const cleanup = delegate.addServerQuery(ast, ttl, got => {\n      if (got) {\n        resolve();\n      }\n    });\n    return {\n      cleanup,\n      complete,\n    };\n  }\n}\n\nfunction addPrimaryKeys(\n  schema: TableSchema,\n  orderBy: Ordering | undefined,\n): Ordering {\n  orderBy = orderBy ?? [];\n  const {primaryKey} = schema;\n  const primaryKeysToAdd = new Set(primaryKey);\n\n  for (const [field] of orderBy) {\n    primaryKeysToAdd.delete(field);\n  }\n\n  if (primaryKeysToAdd.size === 0) {\n    return orderBy;\n  }\n\n  return [\n    ...orderBy,\n    ...[...primaryKeysToAdd].map(key => [key, 'asc'] as [string, 'asc']),\n  ];\n}\n\nfunction addPrimaryKeysToAst(schema: TableSchema, ast: AST): AST {\n  return {\n    ...ast,\n    orderBy: addPrimaryKeys(schema, ast.orderBy),\n  };\n}\n\nfunction arrayViewFactory<\n  TSchema extends Schema,\n  TTable extends string,\n  TReturn,\n>(\n  _query: AbstractQuery<TSchema, TTable, TReturn>,\n  input: Input,\n  format: Format,\n  onDestroy: () => void,\n  onTransactionCommit: (cb: () => void) => void,\n  queryComplete: true | Promise<true>,\n  updateTTL: (ttl: TTL) => void,\n): TypedView<HumanReadable<TReturn>> {\n  const v = new ArrayView<HumanReadable<TReturn>>(\n    input,\n    format,\n    queryComplete,\n    updateTTL,\n  );\n  v.onDestroy = onDestroy;\n  onTransactionCommit(() => {\n    v.flush();\n  });\n  return v;\n}\n\nfunction isCompoundKey(field: readonly string[]): field is CompoundKey {\n  return Array.isArray(field) && field.length >= 1;\n}\n","import {h64} from '../../shared/src/hash.ts';\nimport {normalizeAST, type AST} from './ast.ts';\n\nconst hashCache = new WeakMap<AST, string>();\n\nexport function hashOfAST(ast: AST): string {\n  const normalized = normalizeAST(ast);\n  const cached = hashCache.get(normalized);\n  if (cached) {\n    return cached;\n  }\n  const hash = h64(JSON.stringify(normalized)).toString(36);\n  hashCache.set(normalized, hash);\n  return hash;\n}\n\nexport function hashOfNameAndArgs(\n  name: string,\n  args: readonly unknown[],\n): string {\n  const argsString = JSON.stringify(args);\n  return h64(`${name}:${argsString}`).toString(36);\n}\n","import type {FetchRequest, Input, InputBase, Output} from './operator.ts';\nimport {drainStreams, type Node} from './data.ts';\nimport type {Change} from './change.ts';\nimport type {SourceSchema} from './schema.ts';\nimport type {Stream} from './stream.ts';\nimport type {BuilderDelegate} from '../builder/builder.ts';\n\n/**\n * The `where` clause of a ZQL query is implemented using a sub-graph of\n * `FilterOperators`.  This sub-graph starts with a `FilterStart` operator,\n * that adapts from the normal `Operator` `Output`, to the\n * `FilterOperator` `FilterInput`, and ends with a `FilterEnd` operator that\n * adapts from a `FilterOperator` `FilterOutput` to a normal `Operator` `Input`.\n * `FilterOperator'`s do not have `fetch` or `cleanup` instead they have a\n * `filter(node: Node, cleanup: boolean): boolean` method.\n * They also have `push` which is just like normal `Operator` push.\n * Not having a `fetch` means these `FilterOperator`'s cannot modify\n * `Node` `row`s or `relationship`s, but they shouldn't, they should just\n * filter.\n *\n * This `FilterOperator` abstraction enables much more efficient processing of\n * `fetch` for `where` clauses containing OR conditions.\n *\n * See https://github.com/rocicorp/mono/pull/4339\n */\n\nexport interface FilterInput extends InputBase {\n  /** Tell the input where to send its output. */\n  setFilterOutput(output: FilterOutput): void;\n}\n\nexport interface FilterOutput extends Output {\n  filter(node: Node, cleanup: boolean): boolean;\n}\n\nexport interface FilterOperator extends FilterInput, FilterOutput {}\n\n/**\n * An implementation of FilterOutput that throws if push or filter is called.\n * It is used as the initial value for for an operator's output before it is\n * set.\n */\nexport const throwFilterOutput: FilterOutput = {\n  push(_change: Change): void {\n    throw new Error('Output not set');\n  },\n\n  filter(_node: Node, _cleanup): boolean {\n    throw new Error('Output not set');\n  },\n};\n\nexport class FilterStart implements FilterInput, Output {\n  readonly #input: Input;\n  #output: FilterOutput = throwFilterOutput;\n\n  constructor(input: Input) {\n    this.#input = input;\n    input.setOutput(this);\n  }\n\n  setFilterOutput(output: FilterOutput) {\n    this.#output = output;\n  }\n\n  destroy(): void {\n    this.#input.destroy();\n  }\n\n  getSchema(): SourceSchema {\n    return this.#input.getSchema();\n  }\n\n  push(change: Change) {\n    this.#output.push(change);\n  }\n\n  *fetch(req: FetchRequest): Stream<Node> {\n    for (const node of this.#input.fetch(req)) {\n      if (this.#output.filter(node, false)) {\n        yield node;\n      }\n    }\n  }\n\n  *cleanup(req: FetchRequest): Stream<Node> {\n    for (const node of this.#input.cleanup(req)) {\n      if (this.#output.filter(node, true)) {\n        yield node;\n      } else {\n        drainStreams(node);\n      }\n    }\n  }\n}\n\nexport class FilterEnd implements Input, FilterOutput {\n  readonly #start: FilterStart;\n  readonly #input: FilterInput;\n\n  #output: Output = throwFilterOutput;\n\n  constructor(start: FilterStart, input: FilterInput) {\n    this.#start = start;\n    this.#input = input;\n    input.setFilterOutput(this);\n  }\n\n  *fetch(req: FetchRequest): Stream<Node> {\n    for (const node of this.#start.fetch(req)) {\n      yield node;\n    }\n  }\n\n  *cleanup(req: FetchRequest): Stream<Node> {\n    for (const node of this.#start.cleanup(req)) {\n      yield node;\n    }\n  }\n\n  filter(_node: Node, _cleanup: boolean) {\n    return true;\n  }\n\n  setOutput(output: Output) {\n    this.#output = output;\n  }\n\n  destroy(): void {\n    this.#input.destroy();\n  }\n\n  getSchema(): SourceSchema {\n    return this.#input.getSchema();\n  }\n\n  push(change: Change) {\n    this.#output.push(change);\n  }\n}\n\nexport function buildFilterPipeline(\n  input: Input,\n  delegate: BuilderDelegate,\n  pipeline: (filterInput: FilterInput) => FilterInput,\n): Input {\n  const filterStart = new FilterStart(input);\n  delegate.addEdge(input, filterStart);\n  const middle = pipeline(filterStart);\n  delegate.addEdge(filterStart, middle);\n  const filterEnd = new FilterEnd(filterStart, middle);\n  delegate.addEdge(middle, filterEnd);\n  return filterEnd;\n}\n","import type {JSONValue} from '../../../shared/src/json.ts';\nimport type {Row} from '../../../zero-protocol/src/data.ts';\nimport type {Change} from './change.ts';\nimport type {Constraint} from './constraint.ts';\nimport type {Node} from './data.ts';\nimport type {SourceSchema} from './schema.ts';\nimport type {Stream} from './stream.ts';\n\n/**\n * Input to an operator.\n */\nexport interface InputBase {\n  /** The schema of the data this input returns. */\n  getSchema(): SourceSchema;\n\n  /**\n   * Completely destroy the input. Destroying an input\n   * causes it to call destroy on its upstreams, fully\n   * cleaning up a pipeline.\n   */\n  destroy(): void;\n}\n\nexport interface Input extends InputBase {\n  /** Tell the input where to send its output. */\n  setOutput(output: Output): void;\n\n  /**\n   * Fetch data. May modify the data in place.\n   * Returns nodes sorted in order of `SourceSchema.compareRows`.\n   */\n  fetch(req: FetchRequest): Stream<Node>;\n\n  /**\n   * Cleanup maintained state. This is called when `output` will no longer need\n   * the data returned by {@linkcode fetch}. The receiving operator should clean up any\n   * resources it has allocated to service such requests.\n   *\n   * This is different from {@linkcode destroy} which means this input will no longer\n   * be called at all, for any input.\n   *\n   * Returns the same thing as {@linkcode fetch}. This allows callers to properly\n   * propagate the cleanup message through the graph.\n   */\n  cleanup(req: FetchRequest): Stream<Node>;\n}\n\nexport type FetchRequest = {\n  readonly constraint?: Constraint | undefined;\n  /** If supplied, `start.row` must have previously been output by fetch or push. */\n  readonly start?: Start | undefined;\n\n  /** Whether to fetch in reverse order of the SourceSchema's sort. */\n  readonly reverse?: boolean | undefined;\n};\n\nexport type Start = {\n  readonly row: Row;\n  readonly basis: 'at' | 'after';\n};\n\n/**\n * An output for an operator. Typically another Operator but can also be\n * the code running the pipeline.\n */\nexport interface Output {\n  /**\n   * Push incremental changes to data previously received with fetch().\n   * Consumers must apply all pushed changes or incremental result will\n   * be incorrect.\n   * Callers must maintain some invariants for correct operation:\n   * - Only add rows which do not already exist (by deep equality).\n   * - Only remove rows which do exist (by deep equality).\n   */\n  push(change: Change): void;\n}\n\n/**\n * An implementation of Output that throws if pushed to. It is used as the\n * initial value for for an operator's output before it is set.\n */\nexport const throwOutput: Output = {\n  push(_change: Change): void {\n    throw new Error('Output not set');\n  },\n};\n\n/**\n * Operators are arranged into pipelines.\n * They are stateful.\n * Each operator is an input to the next operator in the chain and an output\n * to the previous.\n */\nexport interface Operator extends Input, Output {}\n\n/**\n * Operators get access to storage that they can store their internal\n * state in.\n */\nexport interface Storage {\n  set(key: string, value: JSONValue): void;\n  get(key: string, def?: JSONValue): JSONValue | undefined;\n  /**\n   * If options is not specified, defaults to scanning all entries.\n   */\n  scan(options?: {prefix: string}): Stream<[string, JSONValue]>;\n  del(key: string): void;\n}\n","/**\n * streams are lazy forward-only iterables.\n * Once a stream reaches the end it can't be restarted.\n * They are iterable, not iterator, so that they can be used in for-each,\n * and so that we know when consumer has stopped iterating the stream. This allows us\n * to clean up resources like sql statements.\n */\nexport type Stream<T> = Iterable<T>;\n\nexport function* take<T>(stream: Stream<T>, limit: number): Stream<T> {\n  if (limit < 1) {\n    return;\n  }\n  let count = 0;\n  for (const v of stream) {\n    yield v;\n    if (++count === limit) {\n      break;\n    }\n  }\n}\n\nexport function first<T>(stream: Stream<T>): T | undefined {\n  const it = stream[Symbol.iterator]();\n  const {value} = it.next();\n  it.return?.();\n  return value;\n}\n","import {areEqual} from '../../../shared/src/arrays.ts';\nimport {assert, unreachable} from '../../../shared/src/asserts.ts';\nimport type {CompoundKey} from '../../../zero-protocol/src/ast.ts';\nimport {type Change} from './change.ts';\nimport {normalizeUndefined, type Node, type NormalizedValue} from './data.ts';\nimport {\n  throwFilterOutput,\n  type FilterInput,\n  type FilterOperator,\n  type FilterOutput,\n} from './filter-operators.ts';\nimport {type Storage} from './operator.ts';\nimport type {SourceSchema} from './schema.ts';\nimport {first} from './stream.ts';\n\ntype SizeStorageKeyPrefix = `row/${string}/`;\n/**\n * Key is of format\n * `row/${JSON.stringify(parentJoinKeyValues)}/${JSON.stringify(primaryKeyValues)}`\n * This format allows us to look up an existing cached size for a given set of\n * `parentJoinKeyValues` by scanning for prefix\n * `row/${JSON.stringify(parentJoinKeyValues)}/` and using the first result, and\n * to look up the cached size for a specific row by the full key.\n * If the parent join and primary key are the same, then format is changed to\n * `row//${JSON.stringify(primaryKeyValues)}` to shorten the key, since there\n * is no point in looking up an existing cached size by\n * `parentJoinKeyValues` if the specific rows cached size is missing.\n */\ntype SizeStorageKey = `${SizeStorageKeyPrefix}${string}`;\n\ninterface ExistsStorage {\n  get(key: SizeStorageKey): number | undefined;\n  set(key: SizeStorageKey, value: number): void;\n  del(key: SizeStorageKey): void;\n  scan({prefix}: {prefix: SizeStorageKeyPrefix}): Iterable<[string, number]>;\n}\n\n/**\n * The Exists operator filters data based on whether or not a relationship is\n * non-empty.\n */\nexport class Exists implements FilterOperator {\n  readonly #input: FilterInput;\n  readonly #relationshipName: string;\n  readonly #storage: ExistsStorage;\n  readonly #not: boolean;\n  readonly #parentJoinKey: CompoundKey;\n  readonly #noSizeReuse: boolean;\n\n  #output: FilterOutput = throwFilterOutput;\n\n  /**\n   * This instance variable is `true` when this operator is processing a `push`,\n   * and is used to disable reuse of cached sizes across rows with the\n   * same parent join key value.\n   * This is necessary because during a push relationships can be inconsistent\n   * due to push communicating changes (which may change multiple Nodes) one\n   * Node at a time.\n   */\n  #inPush = false;\n\n  constructor(\n    input: FilterInput,\n    storage: Storage,\n    relationshipName: string,\n    parentJoinKey: CompoundKey,\n    type: 'EXISTS' | 'NOT EXISTS',\n  ) {\n    this.#input = input;\n    this.#relationshipName = relationshipName;\n    this.#input.setFilterOutput(this);\n    this.#storage = storage as ExistsStorage;\n    assert(\n      this.#input.getSchema().relationships[relationshipName],\n      `Input schema missing ${relationshipName}`,\n    );\n    this.#not = type === 'NOT EXISTS';\n    this.#parentJoinKey = parentJoinKey;\n\n    // If the parentJoinKey is the primary key, no sense in trying to reuse.\n    this.#noSizeReuse = areEqual(\n      parentJoinKey,\n      this.#input.getSchema().primaryKey,\n    );\n  }\n\n  setFilterOutput(output: FilterOutput): void {\n    this.#output = output;\n  }\n\n  filter(node: Node, cleanup: boolean): boolean {\n    const result = this.#filter(node) && this.#output.filter(node, cleanup);\n    if (cleanup) {\n      this.#delSize(node);\n    }\n    return result;\n  }\n\n  destroy(): void {\n    this.#input.destroy();\n  }\n\n  getSchema(): SourceSchema {\n    return this.#input.getSchema();\n  }\n\n  push(change: Change) {\n    assert(!this.#inPush, 'Unexpected re-entrancy');\n    this.#inPush = true;\n    try {\n      switch (change.type) {\n        // add, remove and edit cannot change the size of the\n        // this.#relationshipName relationship, so simply #pushWithFilter\n        case 'add':\n        case 'edit': {\n          this.#pushWithFilter(change);\n          return;\n        }\n        case 'remove': {\n          const size = this.#getSize(change.node);\n          // If size is undefined, this operator has not output\n          // this row before and so it is unnecessary to output a remove for\n          // it.\n          if (size === undefined) {\n            return;\n          }\n          this.#pushWithFilter(change, size);\n          this.#delSize(change.node);\n          return;\n        }\n        case 'child':\n          // Only add and remove child changes for the\n          // this.#relationshipName relationship, can change the size\n          // of the this.#relationshipName relationship, for other\n          // child changes simply #pushWithFilter\n          if (\n            change.child.relationshipName !== this.#relationshipName ||\n            change.child.change.type === 'edit' ||\n            change.child.change.type === 'child'\n          ) {\n            this.#pushWithFilter(change);\n            return;\n          }\n          switch (change.child.change.type) {\n            case 'add': {\n              let size = this.#getSize(change.node);\n              if (size !== undefined) {\n                size++;\n                this.#setSize(change.node, size);\n              } else {\n                size = this.#fetchSize(change.node);\n              }\n              if (size === 1) {\n                if (this.#not) {\n                  // Since the add child change currently being processed is not\n                  // pushed to output, the added child needs to be excluded from\n                  // the remove being pushed to output (since the child has\n                  // never been added to the output).\n                  this.#output.push({\n                    type: 'remove',\n                    node: {\n                      row: change.node.row,\n                      relationships: {\n                        ...change.node.relationships,\n                        [this.#relationshipName]: () => [],\n                      },\n                    },\n                  });\n                } else {\n                  this.#output.push({\n                    type: 'add',\n                    node: change.node,\n                  });\n                }\n              } else {\n                this.#pushWithFilter(change, size);\n              }\n              return;\n            }\n            case 'remove': {\n              let size = this.#getSize(change.node);\n              if (size !== undefined) {\n                assert(size > 0);\n                size--;\n                this.#setSize(change.node, size);\n              } else {\n                size = this.#fetchSize(change.node);\n              }\n              if (size === 0) {\n                if (this.#not) {\n                  this.#output.push({\n                    type: 'add',\n                    node: change.node,\n                  });\n                } else {\n                  // Since the remove child change currently being processed is\n                  // not pushed to output, the removed child needs to be added to\n                  // the remove being pushed to output.\n                  this.#output.push({\n                    type: 'remove',\n                    node: {\n                      row: change.node.row,\n                      relationships: {\n                        ...change.node.relationships,\n                        [this.#relationshipName]: () => [\n                          change.child.change.node,\n                        ],\n                      },\n                    },\n                  });\n                }\n              } else {\n                this.#pushWithFilter(change, size);\n              }\n              return;\n            }\n          }\n          return;\n        default:\n          unreachable(change);\n      }\n    } finally {\n      this.#inPush = false;\n    }\n  }\n\n  /**\n   * Returns whether or not the node's this.#relationshipName\n   * relationship passes the exist/not exists filter condition.\n   * If the optional `size` is passed it is used.\n   * Otherwise, if there is a stored size for the row it is used.\n   * Otherwise the size is computed by streaming the node's\n   * relationship with this.#relationshipName (this computed size is also\n   * stored).\n   */\n  #filter(node: Node, size?: number): boolean {\n    const exists = (size ?? this.#getOrFetchSize(node)) > 0;\n    return this.#not ? !exists : exists;\n  }\n\n  /**\n   * Pushes a change if this.#filter is true for its row.\n   */\n  #pushWithFilter(change: Change, size?: number): void {\n    if (this.#filter(change.node, size)) {\n      this.#output.push(change);\n    }\n  }\n\n  #getSize(node: Node): number | undefined {\n    return this.#storage.get(this.#makeSizeStorageKey(node));\n  }\n\n  #setSize(node: Node, size: number) {\n    this.#storage.set(this.#makeSizeStorageKey(node), size);\n  }\n\n  #delSize(node: Node) {\n    this.#storage.del(this.#makeSizeStorageKey(node));\n  }\n\n  #getOrFetchSize(node: Node): number {\n    const size = this.#getSize(node);\n    if (size !== undefined) {\n      return size;\n    }\n    return this.#fetchSize(node);\n  }\n\n  #fetchSize(node: Node): number {\n    if (!this.#noSizeReuse && !this.#inPush) {\n      const cachedSizeEntry = first(\n        this.#storage.scan({\n          prefix: this.#makeSizeStorageKeyPrefix(node),\n        }),\n      );\n      if (cachedSizeEntry !== undefined) {\n        this.#setSize(node, cachedSizeEntry[1]);\n        return cachedSizeEntry[1];\n      }\n    }\n\n    const relationship = node.relationships[this.#relationshipName];\n    assert(relationship);\n    let size = 0;\n    for (const _relatedNode of relationship()) {\n      size++;\n    }\n\n    this.#setSize(node, size);\n    return size;\n  }\n\n  #makeSizeStorageKeyPrefix(node: Node): SizeStorageKeyPrefix {\n    return `row/${\n      this.#noSizeReuse\n        ? ''\n        : JSON.stringify(this.#getKeyValues(node, this.#parentJoinKey))\n    }/`;\n  }\n\n  #makeSizeStorageKey(node: Node): SizeStorageKey {\n    return `${this.#makeSizeStorageKeyPrefix(node)}${JSON.stringify(\n      this.#getKeyValues(node, this.#input.getSchema().primaryKey),\n    )}`;\n  }\n\n  #getKeyValues(node: Node, def: CompoundKey): NormalizedValue[] {\n    const values: NormalizedValue[] = [];\n    for (const key of def) {\n      values.push(normalizeUndefined(node.row[key]));\n    }\n    return values;\n  }\n}\n","import {assert} from '../../../shared/src/asserts.ts';\nimport {must} from '../../../shared/src/must.ts';\nimport type {Change} from './change.ts';\nimport {type Node} from './data.ts';\nimport type {FanOut} from './fan-out.ts';\nimport {\n  throwFilterOutput,\n  type FilterInput,\n  type FilterOperator,\n  type FilterOutput,\n} from './filter-operators.ts';\nimport type {SourceSchema} from './schema.ts';\n\n/**\n * The FanIn operator merges multiple streams into one.\n * It eliminates duplicates and must be paired with a fan-out operator\n * somewhere upstream of the fan-in.\n *\n *  issue\n *    |\n * fan-out\n * /      \\\n * a      b\n *  \\    /\n * fan-in\n *   |\n */\nexport class FanIn implements FilterOperator {\n  readonly #inputs: readonly FilterInput[];\n  readonly #schema: SourceSchema;\n  #output: FilterOutput = throwFilterOutput;\n  #accumulatedPushes: Change[] = [];\n\n  constructor(fanOut: FanOut, inputs: FilterInput[]) {\n    this.#inputs = inputs;\n    this.#schema = fanOut.getSchema();\n    for (const input of inputs) {\n      input.setFilterOutput(this);\n      assert(this.#schema === input.getSchema(), `Schema mismatch in fan-in`);\n    }\n  }\n\n  setFilterOutput(output: FilterOutput): void {\n    this.#output = output;\n  }\n\n  destroy(): void {\n    for (const input of this.#inputs) {\n      input.destroy();\n    }\n  }\n\n  getSchema() {\n    return this.#schema;\n  }\n\n  filter(node: Node, cleanup: boolean): boolean {\n    return this.#output.filter(node, cleanup);\n  }\n\n  push(change: Change) {\n    this.#accumulatedPushes.push(change);\n  }\n\n  fanOutDonePushingToAllBranches(fanOutChangeType: Change['type']) {\n    if (this.#inputs.length === 0) {\n      assert(\n        this.#accumulatedPushes.length === 0,\n        'If there are no inputs then fan-in should not receive any pushes.',\n      );\n      return;\n    }\n\n    if (this.#accumulatedPushes.length === 0) {\n      // It is possible for no forks to pass along the push.\n      // E.g., if no filters match in any fork.\n      return;\n    }\n\n    // collapse down to a single change per type\n    const candidatesToPush = new Map<Change['type'], Change>();\n    for (const change of this.#accumulatedPushes) {\n      if (fanOutChangeType === 'child' && change.type !== 'child') {\n        assert(\n          candidatesToPush.has(change.type) === false,\n          () =>\n            `Fan-in:child expected at most one ${change.type} when fan-out is of type child`,\n        );\n      }\n      candidatesToPush.set(change.type, change);\n    }\n\n    this.#accumulatedPushes = [];\n\n    const types = [...candidatesToPush.keys()];\n    /**\n     * Based on the received `fanOutChangeType` only certain output types are valid.\n     *\n     * - remove must result in all removes\n     * - add must result in all adds\n     * - edit must result in add or removes or edits\n     * - child must result in a single add or single remove or many child changes\n     */\n    switch (fanOutChangeType) {\n      case 'remove':\n        assert(\n          types.length === 1 && types[0] === 'remove',\n          'Fan-in:remove expected all removes',\n        );\n        this.#output.push(must(candidatesToPush.get('remove')));\n        return;\n      case 'add':\n        assert(\n          types.length === 1 && types[0] === 'add',\n          'Fan-in:add expected all adds',\n        );\n        this.#output.push(must(candidatesToPush.get('add')));\n        return;\n      case 'edit': {\n        assert(\n          types.every(\n            type => type === 'add' || type === 'remove' || type === 'edit',\n          ),\n          'Fan-in:edit expected all adds, removes, or edits',\n        );\n        const addChange = candidatesToPush.get('add');\n        const removeChange = candidatesToPush.get('remove');\n        const editChange = candidatesToPush.get('edit');\n\n        // If an `edit` is present, it supersedes `add` and `remove`\n        // as it semantically represents both.\n        if (editChange) {\n          this.#output.push(editChange);\n          return;\n        }\n\n        // If `edit` didn't make it through but both `add` and `remove` did,\n        // convert back to an edit.\n        //\n        // When can this happen?\n        //\n        //  EDIT old: a=1, new: a=2\n        //            |\n        //          FanOut\n        //          /    \\\n        //         a=1   a=2\n        //          |     |\n        //        remove  add\n        //          \\     /\n        //           FanIn\n        //\n        // The left filter converts the edit into a remove.\n        // The right filter converts the edit into an add.\n        if (addChange && removeChange) {\n          this.#output.push({\n            type: 'edit',\n            node: addChange.node,\n            oldNode: removeChange.node,\n          } as const);\n          return;\n        }\n\n        this.#output.push(must(addChange ?? removeChange));\n        return;\n      }\n      case 'child': {\n        assert(\n          types.every(\n            type =>\n              type === 'add' || // exists can change child to add or remove\n              type === 'remove' || // exists can change child to add or remove\n              type === 'child', // other operators may preserve the child change\n          ),\n          'Fan-in:child expected all adds, removes, or children',\n        );\n        assert(\n          types.length <= 2,\n          'Fan-in:child expected at most 2 types on a child change from fan-out',\n        );\n\n        // If any branch preserved the original child change, that takes precedence over all other changes.\n        const childChange = candidatesToPush.get('child');\n        if (childChange) {\n          this.#output.push(childChange);\n          return;\n        }\n\n        const addChange = candidatesToPush.get('add');\n        const removeChange = candidatesToPush.get('remove');\n\n        assert(\n          addChange === undefined || removeChange === undefined,\n          'Fan-in:child expected either add or remove, not both',\n        );\n\n        this.#output.push(must(addChange ?? removeChange));\n        return;\n      }\n      default:\n        fanOutChangeType satisfies never;\n    }\n  }\n}\n","import {must} from '../../../shared/src/must.ts';\nimport type {Change} from './change.ts';\nimport type {FanIn} from './fan-in.ts';\nimport type {Node} from './data.ts';\nimport type {\n  FilterInput,\n  FilterOperator,\n  FilterOutput,\n} from './filter-operators.ts';\n\n/**\n * Forks a stream into multiple streams.\n * Is meant to be paired with a `FanIn` operator which will\n * later merge the forks back together.\n */\nexport class FanOut implements FilterOperator {\n  readonly #input: FilterInput;\n  readonly #outputs: FilterOutput[] = [];\n  #fanIn: FanIn | undefined;\n  #destroyCount: number = 0;\n\n  constructor(input: FilterInput) {\n    this.#input = input;\n    input.setFilterOutput(this);\n  }\n\n  setFanIn(fanIn: FanIn) {\n    this.#fanIn = fanIn;\n  }\n\n  setFilterOutput(output: FilterOutput): void {\n    this.#outputs.push(output);\n  }\n\n  destroy(): void {\n    if (this.#destroyCount < this.#outputs.length) {\n      if (this.#destroyCount === 0) {\n        this.#input.destroy();\n      }\n      ++this.#destroyCount;\n    } else {\n      throw new Error('FanOut already destroyed once for each output');\n    }\n  }\n\n  getSchema() {\n    return this.#input.getSchema();\n  }\n\n  filter(node: Node, cleanup: boolean): boolean {\n    let result = false;\n    for (const output of this.#outputs) {\n      result = output.filter(node, cleanup) || result;\n      // Cleanup needs to be forwarded to all outputs, don't short circuit\n      // cleanup.  For non-cleanup we can short-circuit on first true.\n      if (!cleanup && result) {\n        return true;\n      }\n    }\n    return result;\n  }\n\n  push(change: Change) {\n    for (const out of this.#outputs) {\n      out.push(change);\n    }\n    must(\n      this.#fanIn,\n      'fan-out must have a corresponding fan-in set!',\n    ).fanOutDonePushingToAllBranches(change.type);\n  }\n}\n","import type {Row} from '../../../zero-protocol/src/data.ts';\nimport type {EditChange} from './change.ts';\nimport type {Output} from './operator.ts';\n\n/**\n * This takes an {@linkcode EditChange} and a predicate that determines if a row\n * should be present based on the row's data. It then splits the change and\n * pushes the appropriate changes to the output based on the predicate.\n */\nexport function maybeSplitAndPushEditChange(\n  change: EditChange,\n  predicate: (row: Row) => boolean,\n  output: Output,\n) {\n  const oldWasPresent = predicate(change.oldNode.row);\n  const newIsPresent = predicate(change.node.row);\n\n  if (oldWasPresent && newIsPresent) {\n    output.push(change);\n  } else if (oldWasPresent && !newIsPresent) {\n    output.push({\n      type: 'remove',\n      node: change.oldNode,\n    });\n  } else if (!oldWasPresent && newIsPresent) {\n    output.push({\n      type: 'add',\n      node: change.node,\n    });\n  }\n}\n","import {unreachable} from '../../../shared/src/asserts.ts';\nimport type {Row} from '../../../zero-protocol/src/data.ts';\nimport type {Change} from './change.ts';\nimport {maybeSplitAndPushEditChange} from './maybe-split-and-push-edit-change.ts';\nimport type {Output} from './operator.ts';\n\nexport function filterPush(\n  change: Change,\n  output: Output,\n  predicate?: ((row: Row) => boolean) | undefined,\n) {\n  if (!predicate) {\n    output.push(change);\n    return;\n  }\n  switch (change.type) {\n    case 'add':\n    case 'remove':\n      if (predicate(change.node.row)) {\n        output.push(change);\n      }\n      break;\n    case 'child':\n      if (predicate(change.node.row)) {\n        output.push(change);\n      }\n      break;\n    case 'edit':\n      maybeSplitAndPushEditChange(change, predicate, output);\n      break;\n    default:\n      unreachable(change);\n  }\n}\n","import type {Row} from '../../../zero-protocol/src/data.ts';\nimport type {Change} from './change.ts';\nimport {\n  throwFilterOutput,\n  type FilterInput,\n  type FilterOperator,\n  type FilterOutput,\n} from './filter-operators.ts';\nimport {filterPush} from './filter-push.ts';\nimport {type Node} from './data.ts';\nimport type {SourceSchema} from './schema.ts';\n\n/**\n * The Filter operator filters data through a predicate. It is stateless.\n *\n * The predicate must be pure.\n */\nexport class Filter implements FilterOperator {\n  readonly #input: FilterInput;\n  readonly #predicate: (row: Row) => boolean;\n\n  #output: FilterOutput = throwFilterOutput;\n\n  constructor(input: FilterInput, predicate: (row: Row) => boolean) {\n    this.#input = input;\n    this.#predicate = predicate;\n    input.setFilterOutput(this);\n  }\n\n  filter(node: Node, cleanup: boolean): boolean {\n    return this.#predicate(node.row) && this.#output.filter(node, cleanup);\n  }\n\n  setFilterOutput(output: FilterOutput) {\n    this.#output = output;\n  }\n\n  destroy(): void {\n    this.#input.destroy();\n  }\n\n  getSchema(): SourceSchema {\n    return this.#input.getSchema();\n  }\n\n  push(change: Change) {\n    filterPush(change, this.#output, this.#predicate);\n  }\n}\n","import {assert, unreachable} from '../../../shared/src/asserts.ts';\nimport type {CompoundKey, System} from '../../../zero-protocol/src/ast.ts';\nimport type {Row, Value} from '../../../zero-protocol/src/data.ts';\nimport type {PrimaryKey} from '../../../zero-protocol/src/primary-key.ts';\nimport type {Change, ChildChange} from './change.ts';\nimport {compareValues, valuesEqual, type Node} from './data.ts';\nimport {\n  throwOutput,\n  type FetchRequest,\n  type Input,\n  type Output,\n  type Storage,\n} from './operator.ts';\nimport type {SourceSchema} from './schema.ts';\nimport {take, type Stream} from './stream.ts';\n\ntype Args = {\n  parent: Input;\n  child: Input;\n  storage: Storage;\n  // The order of the keys does not have to match but the length must match.\n  // The nth key in parentKey corresponds to the nth key in childKey.\n  parentKey: CompoundKey;\n  childKey: CompoundKey;\n\n  // TODO: Change parentKey & childKey to a correlation\n\n  relationshipName: string;\n  hidden: boolean;\n  system: System;\n};\n\ntype ChildChangeOverlay = {\n  change: Change;\n  position: Row | undefined;\n};\n\n/**\n * The Join operator joins the output from two upstream inputs. Zero's join\n * is a little different from SQL's join in that we output hierarchical data,\n * not a flat table. This makes it a lot more useful for UI programming and\n * avoids duplicating tons of data like left join would.\n *\n * The Nodes output from Join have a new relationship added to them, which has\n * the name #relationshipName. The value of the relationship is a stream of\n * child nodes which are the corresponding values from the child source.\n */\nexport class Join implements Input {\n  readonly #parent: Input;\n  readonly #child: Input;\n  readonly #storage: Storage;\n  readonly #parentKey: CompoundKey;\n  readonly #childKey: CompoundKey;\n  readonly #relationshipName: string;\n  readonly #schema: SourceSchema;\n\n  #output: Output = throwOutput;\n\n  #inprogressChildChange: ChildChangeOverlay | undefined;\n\n  constructor({\n    parent,\n    child,\n    storage,\n    parentKey,\n    childKey,\n    relationshipName,\n    hidden,\n    system,\n  }: Args) {\n    assert(parent !== child, 'Parent and child must be different operators');\n    assert(\n      parentKey.length === childKey.length,\n      'The parentKey and childKey keys must have same length',\n    );\n    this.#parent = parent;\n    this.#child = child;\n    this.#storage = storage;\n    this.#parentKey = parentKey;\n    this.#childKey = childKey;\n    this.#relationshipName = relationshipName;\n\n    const parentSchema = parent.getSchema();\n    const childSchema = child.getSchema();\n    this.#schema = {\n      ...parentSchema,\n      relationships: {\n        ...parentSchema.relationships,\n        [relationshipName]: {\n          ...childSchema,\n          isHidden: hidden,\n          system,\n        },\n      },\n    };\n\n    parent.setOutput({\n      push: (change: Change) => this.#pushParent(change),\n    });\n    child.setOutput({\n      push: (change: Change) => this.#pushChild(change),\n    });\n  }\n\n  destroy(): void {\n    this.#parent.destroy();\n    this.#child.destroy();\n  }\n\n  setOutput(output: Output): void {\n    this.#output = output;\n  }\n\n  getSchema(): SourceSchema {\n    return this.#schema;\n  }\n\n  *fetch(req: FetchRequest): Stream<Node> {\n    for (const parentNode of this.#parent.fetch(req)) {\n      yield this.#processParentNode(\n        parentNode.row,\n        parentNode.relationships,\n        'fetch',\n      );\n    }\n  }\n\n  *cleanup(req: FetchRequest): Stream<Node> {\n    for (const parentNode of this.#parent.cleanup(req)) {\n      yield this.#processParentNode(\n        parentNode.row,\n        parentNode.relationships,\n        'cleanup',\n      );\n    }\n  }\n\n  #pushParent(change: Change): void {\n    switch (change.type) {\n      case 'add':\n        this.#output.push({\n          type: 'add',\n          node: this.#processParentNode(\n            change.node.row,\n            change.node.relationships,\n            'fetch',\n          ),\n        });\n        break;\n      case 'remove':\n        this.#output.push({\n          type: 'remove',\n          node: this.#processParentNode(\n            change.node.row,\n            change.node.relationships,\n            'cleanup',\n          ),\n        });\n        break;\n      case 'child':\n        this.#output.push({\n          type: 'child',\n          node: this.#processParentNode(\n            change.node.row,\n            change.node.relationships,\n            'fetch',\n          ),\n          child: change.child,\n        });\n        break;\n      case 'edit': {\n        // Assert the edit could not change the relationship.\n        assert(\n          rowEqualsForCompoundKey(\n            change.oldNode.row,\n            change.node.row,\n            this.#parentKey,\n          ),\n          `Parent edit must not change relationship.`,\n        );\n        this.#output.push({\n          type: 'edit',\n          oldNode: this.#processParentNode(\n            change.oldNode.row,\n            change.oldNode.relationships,\n            'cleanup',\n          ),\n          node: this.#processParentNode(\n            change.node.row,\n            change.node.relationships,\n            'fetch',\n          ),\n        });\n        break;\n      }\n      default:\n        unreachable(change);\n    }\n  }\n\n  #pushChild(change: Change): void {\n    const pushChildChange = (childRow: Row, change: Change) => {\n      this.#inprogressChildChange = {\n        change,\n        position: undefined,\n      };\n      try {\n        const parentNodes = this.#parent.fetch({\n          constraint: Object.fromEntries(\n            this.#parentKey.map((key, i) => [key, childRow[this.#childKey[i]]]),\n          ),\n        });\n\n        for (const parentNode of parentNodes) {\n          this.#inprogressChildChange.position = parentNode.row;\n          const childChange: ChildChange = {\n            type: 'child',\n            node: this.#processParentNode(\n              parentNode.row,\n              parentNode.relationships,\n              'fetch',\n            ),\n            child: {\n              relationshipName: this.#relationshipName,\n              change,\n            },\n          };\n          this.#output.push(childChange);\n        }\n      } finally {\n        this.#inprogressChildChange = undefined;\n      }\n    };\n\n    switch (change.type) {\n      case 'add':\n      case 'remove':\n        pushChildChange(change.node.row, change);\n        break;\n      case 'child':\n        pushChildChange(change.node.row, change);\n        break;\n      case 'edit': {\n        const childRow = change.node.row;\n        const oldChildRow = change.oldNode.row;\n        // Assert the edit could not change the relationship.\n        assert(\n          rowEqualsForCompoundKey(oldChildRow, childRow, this.#childKey),\n          'Child edit must not change relationship.',\n        );\n        pushChildChange(childRow, change);\n        break;\n      }\n\n      default:\n        unreachable(change);\n    }\n  }\n\n  *#generateChildStreamWithOverlay(\n    stream: Stream<Node>,\n    overlay: Change,\n  ): Stream<Node> {\n    let applied = false;\n    let editOldApplied = false;\n    let editNewApplied = false;\n    for (const child of stream) {\n      let yieldChild = true;\n      if (!applied) {\n        switch (overlay.type) {\n          case 'add': {\n            if (\n              this.#child\n                .getSchema()\n                .compareRows(overlay.node.row, child.row) === 0\n            ) {\n              applied = true;\n              yieldChild = false;\n            }\n            break;\n          }\n          case 'remove': {\n            if (\n              this.#child.getSchema().compareRows(overlay.node.row, child.row) <\n              0\n            ) {\n              applied = true;\n              yield overlay.node;\n            }\n            break;\n          }\n          case 'edit': {\n            if (\n              this.#child\n                .getSchema()\n                .compareRows(overlay.oldNode.row, child.row) < 0\n            ) {\n              editOldApplied = true;\n              if (editNewApplied) {\n                applied = true;\n              }\n              yield overlay.oldNode;\n            }\n            if (\n              this.#child\n                .getSchema()\n                .compareRows(overlay.node.row, child.row) === 0\n            ) {\n              editNewApplied = true;\n              if (editOldApplied) {\n                applied = true;\n              }\n              yieldChild = false;\n            }\n            break;\n          }\n          case 'child': {\n            if (\n              this.#child\n                .getSchema()\n                .compareRows(overlay.node.row, child.row) === 0\n            ) {\n              applied = true;\n              yield {\n                row: child.row,\n                relationships: {\n                  ...child.relationships,\n                  [overlay.child.relationshipName]: () =>\n                    this.#generateChildStreamWithOverlay(\n                      child.relationships[overlay.child.relationshipName](),\n                      overlay.child.change,\n                    ),\n                },\n              };\n              yieldChild = false;\n            }\n            break;\n          }\n        }\n      }\n      if (yieldChild) {\n        yield child;\n      }\n    }\n    if (!applied) {\n      if (overlay.type === 'remove') {\n        applied = true;\n        yield overlay.node;\n      } else if (overlay.type === 'edit') {\n        assert(editNewApplied);\n        editOldApplied = true;\n        applied = true;\n        yield overlay.oldNode;\n      }\n    }\n\n    assert(applied);\n  }\n\n  #processParentNode(\n    parentNodeRow: Row,\n    parentNodeRelations: Record<string, () => Stream<Node>>,\n    mode: ProcessParentMode,\n  ): Node {\n    let method: ProcessParentMode = mode;\n    let storageUpdated = false;\n    const childStream = () => {\n      if (!storageUpdated) {\n        if (mode === 'cleanup') {\n          this.#storage.del(\n            makeStorageKey(\n              this.#parentKey,\n              this.#parent.getSchema().primaryKey,\n              parentNodeRow,\n            ),\n          );\n          const empty =\n            [\n              ...take(\n                this.#storage.scan({\n                  prefix: makeStorageKeyPrefix(parentNodeRow, this.#parentKey),\n                }),\n                1,\n              ),\n            ].length === 0;\n          method = empty ? 'cleanup' : 'fetch';\n        }\n\n        storageUpdated = true;\n        // Defer the work to update storage until the child stream\n        // is actually accessed\n        if (mode === 'fetch') {\n          this.#storage.set(\n            makeStorageKey(\n              this.#parentKey,\n              this.#parent.getSchema().primaryKey,\n              parentNodeRow,\n            ),\n            true,\n          );\n        }\n      }\n\n      const stream = this.#child[method]({\n        constraint: Object.fromEntries(\n          this.#childKey.map((key, i) => [\n            key,\n            parentNodeRow[this.#parentKey[i]],\n          ]),\n        ),\n      });\n\n      if (\n        this.#inprogressChildChange &&\n        this.#isJoinMatch(\n          parentNodeRow,\n          this.#inprogressChildChange.change.node.row,\n        ) &&\n        this.#inprogressChildChange.position &&\n        this.#schema.compareRows(\n          parentNodeRow,\n          this.#inprogressChildChange.position,\n        ) > 0\n      ) {\n        return this.#generateChildStreamWithOverlay(\n          stream,\n          this.#inprogressChildChange.change,\n        );\n      }\n      return stream;\n    };\n\n    return {\n      row: parentNodeRow,\n      relationships: {\n        ...parentNodeRelations,\n        [this.#relationshipName]: childStream,\n      },\n    };\n  }\n\n  #isJoinMatch(parent: Row, child: Row) {\n    for (let i = 0; i < this.#parentKey.length; i++) {\n      if (!valuesEqual(parent[this.#parentKey[i]], child[this.#childKey[i]])) {\n        return false;\n      }\n    }\n    return true;\n  }\n}\n\ntype ProcessParentMode = 'fetch' | 'cleanup';\n\n/** Exported for testing. */\nexport function makeStorageKeyForValues(values: readonly Value[]): string {\n  const json = JSON.stringify(['pKeySet', ...values]);\n  return json.substring(1, json.length - 1) + ',';\n}\n\n/** Exported for testing. */\nexport function makeStorageKeyPrefix(row: Row, key: CompoundKey): string {\n  return makeStorageKeyForValues(key.map(k => row[k]));\n}\n\n/** Exported for testing.\n * This storage key tracks the primary keys seen for each unique\n * value joined on. This is used to know when to cleanup a child's state.\n */\nexport function makeStorageKey(\n  key: CompoundKey,\n  primaryKey: PrimaryKey,\n  row: Row,\n): string {\n  const values: Value[] = key.map(k => row[k]);\n  for (const key of primaryKey) {\n    values.push(row[key]);\n  }\n  return makeStorageKeyForValues(values);\n}\n\nfunction rowEqualsForCompoundKey(a: Row, b: Row, key: CompoundKey): boolean {\n  for (let i = 0; i < key.length; i++) {\n    if (compareValues(a[key[i]], b[key[i]]) !== 0) {\n      return false;\n    }\n  }\n  return true;\n}\n","import type {Row} from '../../../zero-protocol/src/data.ts';\nimport type {AddChange, Change, ChildChange, RemoveChange} from './change.ts';\nimport type {Comparator, Node} from './data.ts';\nimport {maybeSplitAndPushEditChange} from './maybe-split-and-push-edit-change.ts';\nimport {\n  throwOutput,\n  type FetchRequest,\n  type Input,\n  type Operator,\n  type Output,\n  type Start,\n} from './operator.ts';\nimport type {SourceSchema} from './schema.ts';\nimport type {Stream} from './stream.ts';\n\nexport type Bound = {\n  row: Row;\n  exclusive: boolean;\n};\n\n/**\n * Skip sets the start position for the pipeline. No rows before the bound will\n * be output.\n */\nexport class Skip implements Operator {\n  readonly #input: Input;\n  readonly #bound: Bound;\n  readonly #comparator: Comparator;\n\n  #output: Output = throwOutput;\n\n  constructor(input: Input, bound: Bound) {\n    this.#input = input;\n    this.#bound = bound;\n    this.#comparator = input.getSchema().compareRows;\n    input.setOutput(this);\n  }\n\n  getSchema(): SourceSchema {\n    return this.#input.getSchema();\n  }\n\n  fetch(req: FetchRequest): Stream<Node> {\n    return this.#fetchOrCleanup('fetch', req);\n  }\n\n  cleanup(req: FetchRequest): Stream<Node> {\n    return this.#fetchOrCleanup('fetch', req);\n  }\n\n  *#fetchOrCleanup(method: 'fetch' | 'cleanup', req: FetchRequest) {\n    const start = this.#getStart(req);\n    if (start === 'empty') {\n      return;\n    }\n    const nodes = this.#input[method]({...req, start});\n    if (!req.reverse) {\n      yield* nodes;\n      return;\n    }\n    for (const node of nodes) {\n      if (!this.#shouldBePresent(node.row)) {\n        return;\n      }\n      yield node;\n    }\n  }\n\n  setOutput(output: Output): void {\n    this.#output = output;\n  }\n\n  destroy(): void {\n    this.#input.destroy();\n  }\n\n  #shouldBePresent(row: Row): boolean {\n    const cmp = this.#comparator(this.#bound.row, row);\n    return cmp < 0 || (cmp === 0 && !this.#bound.exclusive);\n  }\n\n  push(change: Change): void {\n    const shouldBePresent = (row: Row) => this.#shouldBePresent(row);\n    if (change.type === 'edit') {\n      maybeSplitAndPushEditChange(change, shouldBePresent, this.#output);\n      return;\n    }\n\n    change satisfies AddChange | RemoveChange | ChildChange;\n\n    if (shouldBePresent(change.node.row)) {\n      this.#output.push(change);\n    }\n  }\n\n  #getStart(req: FetchRequest): Start | undefined | 'empty' {\n    const boundStart = {\n      row: this.#bound.row,\n      basis: this.#bound.exclusive ? 'after' : 'at',\n    } as const;\n\n    if (!req.start) {\n      if (req.reverse) {\n        return undefined;\n      }\n      return boundStart;\n    }\n\n    const cmp = this.#comparator(this.#bound.row, req.start.row);\n\n    if (!req.reverse) {\n      // The skip bound is after the requested bound. The requested bound cannot\n      // be relevant because even if it was basis: 'after', the skip bound is\n      // itself after the requested bound. Return the skip bound.\n      if (cmp > 0) {\n        return boundStart;\n      }\n\n      // The skip bound and requested bound are equal. If either is exclusive,\n      // return that bound with exclusive. Otherwise, return the skip bound.\n      if (cmp === 0) {\n        if (this.#bound.exclusive || req.start.basis === 'after') {\n          return {\n            row: this.#bound.row,\n            basis: 'after',\n          };\n        }\n        return boundStart;\n      }\n\n      return req.start;\n    }\n\n    req.reverse satisfies true;\n\n    // bound is after the start, but request is for reverse so results\n    // must be empty\n    if (cmp > 0) {\n      return 'empty';\n    }\n\n    if (cmp === 0) {\n      // if both are inclusive, the result can be the single row at bound\n      // return it as start\n      if (!this.#bound.exclusive && req.start.basis === 'at') {\n        return boundStart;\n      }\n      // otherwise the results must be empty, one or both are exclusive\n      // in opposite directions\n      return 'empty';\n    }\n\n    // bound is before the start, return start\n    return req.start;\n  }\n}\n","import {assert, unreachable} from '../../../shared/src/asserts.ts';\nimport {hasOwn} from '../../../shared/src/has-own.ts';\nimport {must} from '../../../shared/src/must.ts';\nimport type {Row, Value} from '../../../zero-protocol/src/data.ts';\nimport type {PrimaryKey} from '../../../zero-protocol/src/primary-key.ts';\nimport {assertOrderingIncludesPK} from '../builder/builder.ts';\nimport {type Change, type EditChange, type RemoveChange} from './change.ts';\nimport type {Constraint} from './constraint.ts';\nimport {compareValues, type Comparator, type Node} from './data.ts';\nimport {\n  throwOutput,\n  type FetchRequest,\n  type Input,\n  type Operator,\n  type Output,\n  type Storage,\n} from './operator.ts';\nimport type {SourceSchema} from './schema.ts';\nimport {first, take, type Stream} from './stream.ts';\n\nconst MAX_BOUND_KEY = 'maxBound';\n\ntype TakeState = {\n  size: number;\n  bound: Row | undefined;\n};\n\ninterface TakeStorage {\n  get(key: typeof MAX_BOUND_KEY): Row | undefined;\n  get(key: string): TakeState | undefined;\n  set(key: typeof MAX_BOUND_KEY, value: Row): void;\n  set(key: string, value: TakeState): void;\n  del(key: string): void;\n}\n\nexport type PartitionKey = PrimaryKey;\n\n/**\n * The Take operator is for implementing limit queries. It takes the first n\n * nodes of its input as determined by the inputs comparator. It then keeps\n * a *bound* of the last item it has accepted so that it can evaluate whether\n * new incoming pushes should be accepted or rejected.\n *\n * Take can count rows globally or by unique value of some field.\n *\n * Maintains the invariant that its output size is always <= limit, even\n * mid processing of a push.\n */\nexport class Take implements Operator {\n  readonly #input: Input;\n  readonly #storage: TakeStorage;\n  readonly #limit: number;\n  readonly #partitionKey: PartitionKey | undefined;\n  readonly #partitionKeyComparator: Comparator | undefined;\n  // Fetch overlay needed for some split push cases.\n  #rowHiddenFromFetch: Row | undefined;\n\n  #output: Output = throwOutput;\n\n  constructor(\n    input: Input,\n    storage: Storage,\n    limit: number,\n    partitionKey?: PartitionKey | undefined,\n  ) {\n    assert(limit >= 0);\n    assertOrderingIncludesPK(\n      input.getSchema().sort,\n      input.getSchema().primaryKey,\n    );\n    input.setOutput(this);\n    this.#input = input;\n    this.#storage = storage as TakeStorage;\n    this.#limit = limit;\n    this.#partitionKey = partitionKey;\n    this.#partitionKeyComparator =\n      partitionKey && makePartitionKeyComparator(partitionKey);\n  }\n\n  setOutput(output: Output): void {\n    this.#output = output;\n  }\n\n  getSchema(): SourceSchema {\n    return this.#input.getSchema();\n  }\n\n  *fetch(req: FetchRequest): Stream<Node> {\n    if (\n      !this.#partitionKey ||\n      (req.constraint &&\n        constraintMatchesPartitionKey(req.constraint, this.#partitionKey))\n    ) {\n      const takeStateKey = getTakeStateKey(this.#partitionKey, req.constraint);\n      const takeState = this.#storage.get(takeStateKey);\n      if (!takeState) {\n        yield* this.#initialFetch(req);\n        return;\n      }\n      if (takeState.bound === undefined) {\n        return;\n      }\n      for (const inputNode of this.#input.fetch(req)) {\n        if (this.getSchema().compareRows(takeState.bound, inputNode.row) < 0) {\n          return;\n        }\n        if (\n          this.#rowHiddenFromFetch &&\n          this.getSchema().compareRows(\n            this.#rowHiddenFromFetch,\n            inputNode.row,\n          ) === 0\n        ) {\n          continue;\n        }\n        yield inputNode;\n      }\n      return;\n    }\n    // There is a partition key, but the fetch is not constrained or constrained\n    // on a different key.  Thus we don't have a single take state to bound by.\n    // This currently only happens with nested sub-queries\n    // e.g. issues include issuelabels include label.  We could remove this\n    // case if we added a translation layer (powered by some state) in join.\n    // Specifically we need joinKeyValue => parent constraint key\n    const maxBound = this.#storage.get(MAX_BOUND_KEY);\n    if (maxBound === undefined) {\n      return;\n    }\n    for (const inputNode of this.#input.fetch(req)) {\n      if (this.getSchema().compareRows(inputNode.row, maxBound) > 0) {\n        return;\n      }\n      const takeStateKey = getTakeStateKey(this.#partitionKey, inputNode.row);\n      const takeState = this.#storage.get(takeStateKey);\n      if (\n        takeState?.bound !== undefined &&\n        this.getSchema().compareRows(takeState.bound, inputNode.row) >= 0\n      ) {\n        yield inputNode;\n      }\n    }\n  }\n\n  *#initialFetch(req: FetchRequest): Stream<Node> {\n    assert(req.start === undefined);\n    assert(!req.reverse);\n    assert(constraintMatchesPartitionKey(req.constraint, this.#partitionKey));\n\n    if (this.#limit === 0) {\n      return;\n    }\n\n    const takeStateKey = getTakeStateKey(this.#partitionKey, req.constraint);\n    assert(this.#storage.get(takeStateKey) === undefined);\n\n    let size = 0;\n    let bound: Row | undefined;\n    let downstreamEarlyReturn = true;\n    let exceptionThrown = false;\n    try {\n      for (const inputNode of this.#input.fetch(req)) {\n        yield inputNode;\n        bound = inputNode.row;\n        size++;\n        if (size === this.#limit) {\n          break;\n        }\n      }\n      downstreamEarlyReturn = false;\n    } catch (e) {\n      exceptionThrown = true;\n      throw e;\n    } finally {\n      if (!exceptionThrown) {\n        this.#setTakeState(\n          takeStateKey,\n          size,\n          bound,\n          this.#storage.get(MAX_BOUND_KEY),\n        );\n        // If it becomes necessary to support downstream early return, this\n        // assert should be removed, and replaced with code that consumes\n        // the input stream until limit is reached or the input stream is\n        // exhausted so that takeState is properly hydrated.\n        assert(\n          !downstreamEarlyReturn,\n          'Unexpected early return prevented full hydration',\n        );\n      }\n    }\n  }\n\n  *cleanup(req: FetchRequest): Stream<Node> {\n    assert(req.start === undefined);\n    assert(constraintMatchesPartitionKey(req.constraint, this.#partitionKey));\n    const takeStateKey = getTakeStateKey(this.#partitionKey, req.constraint);\n    this.#storage.del(takeStateKey);\n    let size = 0;\n    for (const inputNode of this.#input.cleanup(req)) {\n      if (size === this.#limit) {\n        return;\n      }\n      size++;\n      yield inputNode;\n    }\n  }\n\n  #getStateAndConstraint(row: Row) {\n    const takeStateKey = getTakeStateKey(this.#partitionKey, row);\n    const takeState = this.#storage.get(takeStateKey);\n    let maxBound: Row | undefined;\n    let constraint: Constraint | undefined;\n    if (takeState) {\n      maxBound = this.#storage.get(MAX_BOUND_KEY);\n      constraint =\n        this.#partitionKey &&\n        Object.fromEntries(\n          this.#partitionKey.map(key => [key, row[key]] as const),\n        );\n    }\n\n    return {takeState, takeStateKey, maxBound, constraint} as\n      | {\n          takeState: undefined;\n          takeStateKey: string;\n          maxBound: undefined;\n          constraint: undefined;\n        }\n      | {\n          takeState: TakeState;\n          takeStateKey: string;\n          maxBound: Row | undefined;\n          constraint: Constraint | undefined;\n        };\n  }\n\n  push(change: Change): void {\n    if (change.type === 'edit') {\n      this.#pushEditChange(change);\n      return;\n    }\n\n    const {takeState, takeStateKey, maxBound, constraint} =\n      this.#getStateAndConstraint(change.node.row);\n    if (!takeState) {\n      return;\n    }\n\n    const {compareRows} = this.getSchema();\n\n    if (change.type === 'add') {\n      if (takeState.size < this.#limit) {\n        this.#setTakeState(\n          takeStateKey,\n          takeState.size + 1,\n          takeState.bound === undefined ||\n            compareRows(takeState.bound, change.node.row) < 0\n            ? change.node.row\n            : takeState.bound,\n          maxBound,\n        );\n        this.#output.push(change);\n        return;\n      }\n      // size === limit\n      if (\n        takeState.bound === undefined ||\n        compareRows(change.node.row, takeState.bound) >= 0\n      ) {\n        return;\n      }\n      // added row < bound\n      let beforeBoundNode: Node | undefined;\n      let boundNode: Node;\n      if (this.#limit === 1) {\n        boundNode = must(\n          first(\n            this.#input.fetch({\n              start: {\n                row: takeState.bound,\n                basis: 'at',\n              },\n              constraint,\n            }),\n          ),\n        );\n      } else {\n        [boundNode, beforeBoundNode] = take(\n          this.#input.fetch({\n            start: {\n              row: takeState.bound,\n              basis: 'at',\n            },\n            constraint,\n            reverse: true,\n          }),\n          2,\n        );\n      }\n      const removeChange: RemoveChange = {\n        type: 'remove',\n        node: boundNode,\n      };\n      // Remove before add to maintain invariant that\n      // output size <= limit.\n      this.#setTakeState(\n        takeStateKey,\n        takeState.size,\n        beforeBoundNode === undefined ||\n          compareRows(change.node.row, beforeBoundNode.row) > 0\n          ? change.node.row\n          : beforeBoundNode.row,\n        maxBound,\n      );\n      this.#withRowHiddenFromFetch(change.node.row, () => {\n        this.#output.push(removeChange);\n      });\n      this.#output.push(change);\n    } else if (change.type === 'remove') {\n      if (takeState.bound === undefined) {\n        // change is after bound\n        return;\n      }\n      const compToBound = compareRows(change.node.row, takeState.bound);\n      if (compToBound > 0) {\n        // change is after bound\n        return;\n      }\n      const [beforeBoundNode] = take(\n        this.#input.fetch({\n          start: {\n            row: takeState.bound,\n            basis: 'after',\n          },\n          constraint,\n          reverse: true,\n        }),\n        1,\n      );\n\n      let newBound: {node: Node; push: boolean} | undefined;\n      if (beforeBoundNode) {\n        const push = compareRows(beforeBoundNode.row, takeState.bound) > 0;\n        newBound = {\n          node: beforeBoundNode,\n          push,\n        };\n      }\n      if (!newBound?.push) {\n        for (const node of this.#input.fetch({\n          start: {\n            row: takeState.bound,\n            basis: 'at',\n          },\n          constraint,\n        })) {\n          const push = compareRows(node.row, takeState.bound) > 0;\n          newBound = {\n            node,\n            push,\n          };\n          if (push) {\n            break;\n          }\n        }\n      }\n\n      if (newBound?.push) {\n        this.#output.push(change);\n        this.#setTakeState(\n          takeStateKey,\n          takeState.size,\n          newBound.node.row,\n          maxBound,\n        );\n        this.#output.push({\n          type: 'add',\n          node: newBound.node,\n        });\n        return;\n      }\n      this.#setTakeState(\n        takeStateKey,\n        takeState.size - 1,\n        newBound?.node.row,\n        maxBound,\n      );\n      this.#output.push(change);\n    } else if (change.type === 'child') {\n      // A 'child' change should be pushed to output if its row\n      // is <= bound.\n      if (\n        takeState.bound &&\n        compareRows(change.node.row, takeState.bound) <= 0\n      ) {\n        this.#output.push(change);\n      }\n    }\n  }\n\n  #pushEditChange(change: EditChange): void {\n    assert(\n      !this.#partitionKeyComparator ||\n        this.#partitionKeyComparator(change.oldNode.row, change.node.row) === 0,\n      'Unexpected change of partition key',\n    );\n\n    const {takeState, takeStateKey, maxBound, constraint} =\n      this.#getStateAndConstraint(change.oldNode.row);\n    if (!takeState) {\n      return;\n    }\n\n    assert(takeState.bound, 'Bound should be set');\n    const {compareRows} = this.getSchema();\n    const oldCmp = compareRows(change.oldNode.row, takeState.bound);\n    const newCmp = compareRows(change.node.row, takeState.bound);\n\n    const replaceBoundAndForwardChange = () => {\n      this.#setTakeState(\n        takeStateKey,\n        takeState.size,\n        change.node.row,\n        maxBound,\n      );\n      this.#output.push(change);\n    };\n\n    // The bounds row was changed.\n    if (oldCmp === 0) {\n      // The new row is the new bound.\n      if (newCmp === 0) {\n        // no need to update the state since we are keeping the bounds\n        this.#output.push(change);\n        return;\n      }\n\n      if (newCmp < 0) {\n        if (this.#limit === 1) {\n          replaceBoundAndForwardChange();\n          return;\n        }\n\n        // New row will be in the result but it might not be the bounds any\n        // more. We need to find the row before the bounds to determine the new\n        // bounds.\n\n        const beforeBoundNode = must(\n          first(\n            this.#input.fetch({\n              start: {\n                row: takeState.bound,\n                basis: 'after',\n              },\n              constraint,\n              reverse: true,\n            }),\n          ),\n        );\n\n        this.#setTakeState(\n          takeStateKey,\n          takeState.size,\n          beforeBoundNode.row,\n          maxBound,\n        );\n        this.#output.push(change);\n        return;\n      }\n\n      assert(newCmp > 0);\n      // Find the first item at the old bounds. This will be the new bounds.\n      const newBoundNode = must(\n        first(\n          this.#input.fetch({\n            start: {\n              row: takeState.bound,\n              basis: 'at',\n            },\n            constraint,\n          }),\n        ),\n      );\n\n      // The next row is the new row. We can replace the bounds and keep the\n      // edit change.\n      if (compareRows(newBoundNode.row, change.node.row) === 0) {\n        replaceBoundAndForwardChange();\n        return;\n      }\n\n      // The new row is now outside the bounds, so we need to remove the old\n      // row and add the new bounds row.\n      this.#setTakeState(\n        takeStateKey,\n        takeState.size,\n        newBoundNode.row,\n        maxBound,\n      );\n      this.#withRowHiddenFromFetch(newBoundNode.row, () => {\n        this.#output.push({\n          type: 'remove',\n          node: change.oldNode,\n        });\n      });\n      this.#output.push({\n        type: 'add',\n        node: newBoundNode,\n      });\n      return;\n    }\n\n    if (oldCmp > 0) {\n      assert(newCmp !== 0, 'Invalid state. Row has duplicate primary key');\n\n      // Both old and new outside of bounds\n      if (newCmp > 0) {\n        return;\n      }\n\n      // old was outside, new is inside. Pushing out the old bounds\n      assert(newCmp < 0);\n\n      const [oldBoundNode, newBoundNode] = take(\n        this.#input.fetch({\n          start: {\n            row: takeState.bound,\n            basis: 'at',\n          },\n          constraint,\n          reverse: true,\n        }),\n        2,\n      );\n      // Remove before add to maintain invariant that\n      // output size <= limit.\n      this.#setTakeState(\n        takeStateKey,\n        takeState.size,\n        newBoundNode.row,\n        maxBound,\n      );\n      this.#withRowHiddenFromFetch(change.node.row, () => {\n        this.#output.push({\n          type: 'remove',\n          node: oldBoundNode,\n        });\n      });\n      this.#output.push({\n        type: 'add',\n        node: change.node,\n      });\n\n      return;\n    }\n\n    if (oldCmp < 0) {\n      assert(newCmp !== 0, 'Invalid state. Row has duplicate primary key');\n\n      // Both old and new inside of bounds\n      if (newCmp < 0) {\n        this.#output.push(change);\n        return;\n      }\n\n      // old was inside, new is larger than old bound\n\n      assert(newCmp > 0);\n\n      // at this point we need to find the row after the bound and use that or\n      // the newRow as the new bound.\n      const afterBoundNode = must(\n        first(\n          this.#input.fetch({\n            start: {\n              row: takeState.bound,\n              basis: 'after',\n            },\n            constraint,\n          }),\n        ),\n      );\n\n      // The new row is the new bound. Use an edit change.\n      if (compareRows(afterBoundNode.row, change.node.row) === 0) {\n        replaceBoundAndForwardChange();\n        return;\n      }\n\n      this.#output.push({\n        type: 'remove',\n        node: change.oldNode,\n      });\n      this.#setTakeState(\n        takeStateKey,\n        takeState.size,\n        afterBoundNode.row,\n        maxBound,\n      );\n      this.#output.push({\n        type: 'add',\n        node: afterBoundNode,\n      });\n      return;\n    }\n\n    unreachable();\n  }\n\n  #withRowHiddenFromFetch(row: Row, fn: () => void) {\n    this.#rowHiddenFromFetch = row;\n    try {\n      fn();\n    } finally {\n      this.#rowHiddenFromFetch = undefined;\n    }\n  }\n\n  #setTakeState(\n    takeStateKey: string,\n    size: number,\n    bound: Row | undefined,\n    maxBound: Row | undefined,\n  ) {\n    this.#storage.set(takeStateKey, {\n      size,\n      bound,\n    });\n    if (\n      bound !== undefined &&\n      (maxBound === undefined ||\n        this.getSchema().compareRows(bound, maxBound) > 0)\n    ) {\n      this.#storage.set(MAX_BOUND_KEY, bound);\n    }\n  }\n\n  destroy(): void {\n    this.#input.destroy();\n  }\n}\n\nfunction getTakeStateKey(\n  partitionKey: PartitionKey | undefined,\n  rowOrConstraint: Row | Constraint | undefined,\n): string {\n  // The order must be consistent. We always use the order as defined by the\n  // partition key.\n  const partitionValues: Value[] = [];\n\n  if (partitionKey && rowOrConstraint) {\n    for (const key of partitionKey) {\n      partitionValues.push(rowOrConstraint[key]);\n    }\n  }\n\n  return JSON.stringify(['take', ...partitionValues]);\n}\n\nfunction constraintMatchesPartitionKey(\n  constraint: Constraint | undefined,\n  partitionKey: PartitionKey | undefined,\n): boolean {\n  if (constraint === undefined || partitionKey === undefined) {\n    return constraint === partitionKey;\n  }\n  if (partitionKey.length !== Object.keys(constraint).length) {\n    return false;\n  }\n  for (const key of partitionKey) {\n    if (!hasOwn(constraint, key)) {\n      return false;\n    }\n  }\n  return true;\n}\n\nfunction makePartitionKeyComparator(partitionKey: PartitionKey): Comparator {\n  return (a, b) => {\n    for (const key of partitionKey) {\n      const cmp = compareValues(a[key], b[key]);\n      if (cmp !== 0) {\n        return cmp;\n      }\n    }\n    return 0;\n  };\n}\n","/* eslint-disable @typescript-eslint/no-explicit-any */\nimport {must} from '../../../shared/src/must.ts';\nimport {\n  toStaticParam,\n  type Condition,\n  type LiteralValue,\n  type Parameter,\n  type SimpleOperator,\n} from '../../../zero-protocol/src/ast.ts';\nimport type {Schema} from '../../../zero-schema/src/builder/schema-builder.ts';\nimport type {\n  AvailableRelationships,\n  DestTableName,\n  GetFilterType,\n  NoCompoundTypeSelector,\n  PullTableSchema,\n  Query,\n} from './query.ts';\n\nexport type ParameterReference = {\n  [toStaticParam](): Parameter;\n};\n\n/**\n * A factory function that creates a condition. This is used to create\n * complex conditions that can be passed to the `where` method of a query.\n *\n * @example\n *\n * ```ts\n * const condition: ExpressionFactory<User> = ({and, cmp, or}) =>\n *   and(\n *     cmp('name', '=', 'Alice'),\n *     or(cmp('age', '>', 18), cmp('isStudent', '=', true)),\n *   );\n *\n * const query = z.query.user.where(condition);\n * ```\n */\nexport interface ExpressionFactory<\n  TSchema extends Schema,\n  TTable extends keyof TSchema['tables'] & string,\n> {\n  (eb: ExpressionBuilder<TSchema, TTable>): Condition;\n}\n\nexport class ExpressionBuilder<\n  TSchema extends Schema,\n  TTable extends keyof TSchema['tables'] & string,\n> {\n  readonly #exists: (\n    relationship: string,\n    cb?: (query: Query<TSchema, TTable>) => Query<TSchema, any>,\n  ) => Condition;\n\n  constructor(\n    exists: (\n      relationship: string,\n      cb?: (query: Query<TSchema, TTable>) => Query<TSchema, any>,\n    ) => Condition,\n  ) {\n    this.#exists = exists;\n    this.exists = this.exists.bind(this);\n  }\n\n  get eb() {\n    return this;\n  }\n\n  cmp<\n    TSelector extends NoCompoundTypeSelector<PullTableSchema<TTable, TSchema>>,\n    TOperator extends SimpleOperator,\n  >(\n    field: TSelector,\n    op: TOperator,\n    value:\n      | GetFilterType<PullTableSchema<TTable, TSchema>, TSelector, TOperator>\n      | ParameterReference,\n  ): Condition;\n  cmp<\n    TSelector extends NoCompoundTypeSelector<PullTableSchema<TTable, TSchema>>,\n  >(\n    field: TSelector,\n    value:\n      | GetFilterType<PullTableSchema<TTable, TSchema>, TSelector, '='>\n      | ParameterReference,\n  ): Condition;\n  cmp(\n    field: string,\n    opOrValue: SimpleOperator | ParameterReference | LiteralValue,\n    value?: ParameterReference | LiteralValue,\n  ): Condition {\n    return cmp(field, opOrValue, value);\n  }\n\n  cmpLit(\n    left: ParameterReference | LiteralValue,\n    op: SimpleOperator,\n    right: ParameterReference | LiteralValue,\n  ): Condition {\n    return {\n      type: 'simple',\n      left: isParameterReference(left)\n        ? left[toStaticParam]()\n        : {type: 'literal', value: left},\n      right: isParameterReference(right)\n        ? right[toStaticParam]()\n        : {type: 'literal', value: right},\n      op,\n    };\n  }\n\n  and = and;\n  or = or;\n  not = not;\n\n  exists = <TRelationship extends AvailableRelationships<TTable, TSchema>>(\n    relationship: TRelationship,\n    cb?: (\n      query: Query<TSchema, DestTableName<TTable, TSchema, TRelationship>>,\n    ) => Query<TSchema, any>,\n  ): Condition => this.#exists(relationship, cb);\n}\n\nexport function and(...conditions: (Condition | undefined)[]): Condition {\n  const expressions = filterTrue(filterUndefined(conditions));\n\n  if (expressions.length === 1) {\n    return expressions[0];\n  }\n\n  if (expressions.some(isAlwaysFalse)) {\n    return FALSE;\n  }\n\n  return {type: 'and', conditions: expressions};\n}\n\nexport function or(...conditions: (Condition | undefined)[]): Condition {\n  const expressions = filterFalse(filterUndefined(conditions));\n\n  if (expressions.length === 1) {\n    return expressions[0];\n  }\n\n  if (expressions.some(isAlwaysTrue)) {\n    return TRUE;\n  }\n\n  return {type: 'or', conditions: expressions};\n}\n\nexport function not(expression: Condition): Condition {\n  switch (expression.type) {\n    case 'and':\n      return {\n        type: 'or',\n        conditions: expression.conditions.map(not),\n      };\n    case 'or':\n      return {\n        type: 'and',\n        conditions: expression.conditions.map(not),\n      };\n    case 'correlatedSubquery':\n      return {\n        type: 'correlatedSubquery',\n        related: expression.related,\n        op: negateOperator(expression.op),\n      };\n    case 'simple':\n      return {\n        type: 'simple',\n        op: negateOperator(expression.op),\n        left: expression.left,\n        right: expression.right,\n      };\n  }\n}\n\nexport function cmp(\n  field: string,\n  opOrValue: SimpleOperator | ParameterReference | LiteralValue,\n  value?: ParameterReference | LiteralValue,\n): Condition {\n  let op: SimpleOperator;\n  if (value === undefined) {\n    value = opOrValue;\n    op = '=';\n  } else {\n    op = opOrValue as SimpleOperator;\n  }\n\n  return {\n    type: 'simple',\n    left: {type: 'column', name: field},\n    right: isParameterReference(value)\n      ? value[toStaticParam]()\n      : {type: 'literal', value},\n    op,\n  };\n}\n\nfunction isParameterReference(\n  value: ParameterReference | LiteralValue | null,\n): value is ParameterReference {\n  return (\n    value !== null && typeof value === 'object' && (value as any)[toStaticParam]\n  );\n}\n\nexport const TRUE: Condition = {\n  type: 'and',\n  conditions: [],\n};\n\nconst FALSE: Condition = {\n  type: 'or',\n  conditions: [],\n};\n\nfunction isAlwaysTrue(condition: Condition): boolean {\n  return condition.type === 'and' && condition.conditions.length === 0;\n}\n\nfunction isAlwaysFalse(condition: Condition): boolean {\n  return condition.type === 'or' && condition.conditions.length === 0;\n}\n\nexport function simplifyCondition(c: Condition): Condition {\n  if (c.type === 'simple' || c.type === 'correlatedSubquery') {\n    return c;\n  }\n  if (c.conditions.length === 1) {\n    return simplifyCondition(c.conditions[0]);\n  }\n  const conditions = flatten(c.type, c.conditions.map(simplifyCondition));\n  if (c.type === 'and' && conditions.some(isAlwaysFalse)) {\n    return FALSE;\n  }\n  if (c.type === 'or' && conditions.some(isAlwaysTrue)) {\n    return TRUE;\n  }\n  return {\n    type: c.type,\n    conditions,\n  };\n}\n\nexport function flatten(\n  type: 'and' | 'or',\n  conditions: readonly Condition[],\n): Condition[] {\n  const flattened: Condition[] = [];\n  for (const c of conditions) {\n    if (c.type === type) {\n      flattened.push(...c.conditions);\n    } else {\n      flattened.push(c);\n    }\n  }\n\n  return flattened;\n}\n\nconst negateSimpleOperatorMap = {\n  ['=']: '!=',\n  ['!=']: '=',\n  ['<']: '>=',\n  ['>']: '<=',\n  ['>=']: '<',\n  ['<=']: '>',\n  ['IN']: 'NOT IN',\n  ['NOT IN']: 'IN',\n  ['LIKE']: 'NOT LIKE',\n  ['NOT LIKE']: 'LIKE',\n  ['ILIKE']: 'NOT ILIKE',\n  ['NOT ILIKE']: 'ILIKE',\n  ['IS']: 'IS NOT',\n  ['IS NOT']: 'IS',\n} as const;\n\nconst negateOperatorMap = {\n  ...negateSimpleOperatorMap,\n  ['EXISTS']: 'NOT EXISTS',\n  ['NOT EXISTS']: 'EXISTS',\n} as const;\n\nexport function negateOperator<OP extends keyof typeof negateOperatorMap>(\n  op: OP,\n): (typeof negateOperatorMap)[OP] {\n  return must(negateOperatorMap[op]);\n}\n\nfunction filterUndefined<T>(array: (T | undefined)[]): T[] {\n  return array.filter(e => e !== undefined);\n}\n\nfunction filterTrue(conditions: Condition[]): Condition[] {\n  return conditions.filter(c => !isAlwaysTrue(c));\n}\n\nfunction filterFalse(conditions: Condition[]): Condition[] {\n  return conditions.filter(c => !isAlwaysFalse(c));\n}\n","import {assertString} from '../../../shared/src/asserts.ts';\nimport type {NonNullValue, SimplePredicateNoNull} from './filter.ts';\n\nexport function getLikePredicate(\n  pattern: NonNullValue,\n  flags: 'i' | '',\n): SimplePredicateNoNull {\n  const op = getLikeOp(String(pattern), flags);\n  return (lhs: NonNullValue) => {\n    assertString(lhs);\n    return op(String(lhs));\n  };\n}\n\nfunction getLikeOp(pattern: string, flags: 'i' | ''): (lhs: string) => boolean {\n  // if lhs does not contain '%' or '_' then it is a simple string comparison.\n  // if it does contain '%' or '_' then it is a regex comparison.\n  // '%' is a wildcard for any number of characters\n  // '_' is a wildcard for a single character\n  // Postgres SQL allows escaping using `\\`.\n\n  if (!/_|%|\\\\/.test(pattern)) {\n    if (flags === 'i') {\n      const rhsLower = pattern.toLowerCase();\n      return (lhs: string) => lhs.toLowerCase() === rhsLower;\n    }\n    return (lhs: string) => lhs === pattern;\n  }\n  const re = patternToRegExp(pattern, flags);\n  return (lhs: string) => re.test(lhs);\n}\n\nconst specialCharsRe = /[$()*+.?[\\]\\\\^{|}]/;\n\nfunction patternToRegExp(source: string, flags: '' | 'i' = ''): RegExp {\n  // There are a few cases:\n  // % => .*\n  // _ => .\n  // \\x => \\x for any x except special regexp chars\n  // special regexp chars => \\special regexp chars\n  let pattern = '^';\n  for (let i = 0; i < source.length; i++) {\n    let c = source[i];\n    switch (c) {\n      case '%':\n        pattern += '.*';\n        break;\n      case '_':\n        pattern += '.';\n        break;\n\n      // @ts-expect-error fallthrough\n      case '\\\\':\n        if (i === source.length - 1) {\n          throw new Error('LIKE pattern must not end with escape character');\n        }\n        i++;\n        c = source[i];\n\n      // fall through\n      default:\n        if (specialCharsRe.test(c)) {\n          pattern += '\\\\';\n        }\n        pattern += c;\n\n        break;\n    }\n  }\n  return new RegExp(pattern + '$', flags + 'm');\n}\n","import {assert, unreachable} from '../../../shared/src/asserts.ts';\nimport type {\n  Condition,\n  SimpleCondition,\n  SimpleOperator,\n} from '../../../zero-protocol/src/ast.ts';\nimport type {Row, Value} from '../../../zero-protocol/src/data.ts';\nimport {simplifyCondition} from '../query/expression.ts';\nimport {getLikePredicate} from './like.ts';\n\nexport type NonNullValue = Exclude<Value, null | undefined>;\nexport type SimplePredicate = (rhs: Value) => boolean;\nexport type SimplePredicateNoNull = (rhs: NonNullValue) => boolean;\n\nexport type NoSubqueryCondition =\n  | SimpleCondition\n  | {\n      type: 'and';\n      conditions: readonly NoSubqueryCondition[];\n    }\n  | {\n      type: 'or';\n      conditions: readonly NoSubqueryCondition[];\n    };\n\nexport function createPredicate(\n  condition: NoSubqueryCondition,\n): (row: Row) => boolean {\n  if (condition.type !== 'simple') {\n    const predicates = condition.conditions.map(c => createPredicate(c));\n    return condition.type === 'and'\n      ? (row: Row) => {\n          // and\n          for (const predicate of predicates) {\n            if (!predicate(row)) {\n              return false;\n            }\n          }\n          return true;\n        }\n      : (row: Row) => {\n          // or\n          for (const predicate of predicates) {\n            if (predicate(row)) {\n              return true;\n            }\n          }\n          return false;\n        };\n  }\n  const {left} = condition;\n  const {right} = condition;\n  assert(\n    right.type !== 'static',\n    'static values should be resolved before creating predicates',\n  );\n  assert(\n    left.type !== 'static',\n    'static values should be resolved before creating predicates',\n  );\n\n  switch (condition.op) {\n    case 'IS':\n    case 'IS NOT': {\n      const impl = createIsPredicate(right.value, condition.op);\n      if (left.type === 'literal') {\n        const result = impl(left.value);\n        return () => result;\n      }\n      return (row: Row) => impl(row[left.name]);\n    }\n  }\n\n  if (right.value === null || right.value === undefined) {\n    return (_row: Row) => false;\n  }\n\n  const impl = createPredicateImpl(right.value, condition.op);\n  if (left.type === 'literal') {\n    if (left.value === null || left.value === undefined) {\n      return (_row: Row) => false;\n    }\n    const result = impl(left.value);\n    return () => result;\n  }\n\n  return (row: Row) => {\n    const lhs = row[left.name];\n    if (lhs === null || lhs === undefined) {\n      return false;\n    }\n    return impl(lhs);\n  };\n}\n\nfunction createIsPredicate(\n  rhs: Value | readonly Value[],\n  operator: 'IS' | 'IS NOT',\n): SimplePredicate {\n  switch (operator) {\n    case 'IS':\n      return lhs => lhs === rhs;\n    case 'IS NOT':\n      return lhs => lhs !== rhs;\n  }\n}\n\nfunction createPredicateImpl(\n  rhs: NonNullValue | readonly NonNullValue[],\n  operator: Exclude<SimpleOperator, 'IS' | 'IS NOT'>,\n): SimplePredicateNoNull {\n  switch (operator) {\n    case '=':\n      return lhs => lhs === rhs;\n    case '!=':\n      return lhs => lhs !== rhs;\n    case '<':\n      return lhs => lhs < rhs;\n    case '<=':\n      return lhs => lhs <= rhs;\n    case '>':\n      return lhs => lhs > rhs;\n    case '>=':\n      return lhs => lhs >= rhs;\n    case 'LIKE':\n      return getLikePredicate(rhs, '');\n    case 'NOT LIKE':\n      return not(getLikePredicate(rhs, ''));\n    case 'ILIKE':\n      return getLikePredicate(rhs, 'i');\n    case 'NOT ILIKE':\n      return not(getLikePredicate(rhs, 'i'));\n    case 'IN': {\n      assert(Array.isArray(rhs));\n      const set = new Set(rhs);\n      return lhs => set.has(lhs);\n    }\n    case 'NOT IN': {\n      assert(Array.isArray(rhs));\n      const set = new Set(rhs);\n      return lhs => !set.has(lhs);\n    }\n    default:\n      operator satisfies never;\n      throw new Error(`Unexpected operator: ${operator}`);\n  }\n}\n\nfunction not<T>(f: (lhs: T) => boolean) {\n  return (lhs: T) => !f(lhs);\n}\n\n/**\n * If the condition contains any CorrelatedSubqueryConditions, returns a\n * transformed condition which contains no CorrelatedSubqueryCondition(s) but\n * which will filter a subset of the rows that would be filtered by the original\n * condition, or undefined if no such transformation exists.\n *\n * If the condition does not contain any CorrelatedSubqueryConditions\n * returns the condition unmodified and `conditionsRemoved: false`.\n */\nexport function transformFilters(filters: Condition | undefined): {\n  filters: NoSubqueryCondition | undefined;\n  conditionsRemoved: boolean;\n} {\n  if (!filters) {\n    return {filters: undefined, conditionsRemoved: false};\n  }\n  switch (filters.type) {\n    case 'simple':\n      return {filters, conditionsRemoved: false};\n    case 'correlatedSubquery':\n      return {filters: undefined, conditionsRemoved: true};\n    case 'and':\n    case 'or': {\n      const transformedConditions: NoSubqueryCondition[] = [];\n      let conditionsRemoved = false;\n      for (const cond of filters.conditions) {\n        const transformed = transformFilters(cond);\n        // If any branch of the OR ends up empty, the entire OR needs\n        // to be removed.\n        if (transformed.filters === undefined && filters.type === 'or') {\n          return {filters: undefined, conditionsRemoved: true};\n        }\n        conditionsRemoved = conditionsRemoved || transformed.conditionsRemoved;\n        if (transformed.filters) {\n          transformedConditions.push(transformed.filters);\n        }\n      }\n      return {\n        filters: simplifyCondition({\n          type: filters.type,\n          conditions: transformedConditions,\n        }) as NoSubqueryCondition,\n        conditionsRemoved,\n      };\n    }\n    default:\n      unreachable(filters);\n  }\n}\n","import {assert} from '../../../shared/src/asserts.ts';\nimport type {JSONValue} from '../../../shared/src/json.ts';\nimport {must} from '../../../shared/src/must.ts';\nimport type {\n  AST,\n  ColumnReference,\n  CompoundKey,\n  Condition,\n  Conjunction,\n  CorrelatedSubquery,\n  CorrelatedSubqueryCondition,\n  Disjunction,\n  LiteralValue,\n  Ordering,\n  Parameter,\n  SimpleCondition,\n  ValuePosition,\n} from '../../../zero-protocol/src/ast.ts';\nimport type {Row} from '../../../zero-protocol/src/data.ts';\nimport type {PrimaryKey} from '../../../zero-protocol/src/primary-key.ts';\nimport {Exists} from '../ivm/exists.ts';\nimport {FanIn} from '../ivm/fan-in.ts';\nimport {FanOut} from '../ivm/fan-out.ts';\nimport {\n  buildFilterPipeline,\n  type FilterInput,\n} from '../ivm/filter-operators.ts';\nimport {Filter} from '../ivm/filter.ts';\nimport {Join} from '../ivm/join.ts';\nimport type {Input, InputBase, Storage} from '../ivm/operator.ts';\nimport {Skip} from '../ivm/skip.ts';\nimport type {Source, SourceInput} from '../ivm/source.ts';\nimport {Take} from '../ivm/take.ts';\nimport type {DebugDelegate} from './debug-delegate.ts';\nimport {createPredicate, type NoSubqueryCondition} from './filter.ts';\n\nexport type StaticQueryParameters = {\n  authData: Record<string, JSONValue>;\n  preMutationRow?: Row | undefined;\n};\n\n/**\n * Interface required of caller to buildPipeline. Connects to constructed\n * pipeline to delegate environment to provide sources and storage.\n */\nexport interface BuilderDelegate {\n  readonly applyFiltersAnyway?: boolean | undefined;\n  readonly debug?: DebugDelegate | undefined;\n\n  /**\n   * Called once for each source needed by the AST.\n   * Might be called multiple times with same tableName. It is OK to return\n   * same storage instance in that case.\n   */\n  getSource(tableName: string): Source | undefined;\n\n  /**\n   * Called once for each operator that requires storage. Should return a new\n   * unique storage object for each call.\n   */\n  createStorage(name: string): Storage;\n\n  decorateInput(input: Input, name: string): Input;\n\n  addEdge(source: InputBase, dest: InputBase): void;\n\n  decorateFilterInput(input: FilterInput, name: string): FilterInput;\n\n  decorateSourceInput(input: SourceInput, queryID: string): Input;\n\n  /**\n   * The AST is mapped on-the-wire between client and server names.\n   *\n   * There is no \"wire\" for zqlite tests so this function is provided\n   * to allow tests to remap the AST.\n   */\n  mapAst?: ((ast: AST) => AST) | undefined;\n}\n\n/**\n * Builds a pipeline from an AST. Caller must provide a delegate to create source\n * and storage interfaces as necessary.\n *\n * Usage:\n *\n * ```ts\n * class MySink implements Output {\n *   readonly #input: Input;\n *\n *   constructor(input: Input) {\n *     this.#input = input;\n *     input.setOutput(this);\n *   }\n *\n *   push(change: Change, _: Operator) {\n *     console.log(change);\n *   }\n * }\n *\n * const input = buildPipeline(ast, myDelegate, hash(ast));\n * const sink = new MySink(input);\n * ```\n */\nexport function buildPipeline(\n  ast: AST,\n  delegate: BuilderDelegate,\n  queryID: string,\n): Input {\n  return buildPipelineInternal(\n    delegate.mapAst ? delegate.mapAst(ast) : ast,\n    delegate,\n    queryID,\n    '',\n  );\n}\n\nexport function bindStaticParameters(\n  ast: AST,\n  staticQueryParameters: StaticQueryParameters | undefined,\n) {\n  const visit = (node: AST): AST => ({\n    ...node,\n    where: node.where ? bindCondition(node.where) : undefined,\n    related: node.related?.map(sq => ({\n      ...sq,\n      subquery: visit(sq.subquery),\n    })),\n  });\n\n  function bindCondition(condition: Condition): Condition {\n    if (condition.type === 'simple') {\n      return {\n        ...condition,\n        left: bindValue(condition.left),\n        right: bindValue(condition.right) as Exclude<\n          ValuePosition,\n          ColumnReference\n        >,\n      };\n    }\n    if (condition.type === 'correlatedSubquery') {\n      return {\n        ...condition,\n        related: {\n          ...condition.related,\n          subquery: visit(condition.related.subquery),\n        },\n      };\n    }\n    return {\n      ...condition,\n      conditions: condition.conditions.map(bindCondition),\n    };\n  }\n\n  const bindValue = (value: ValuePosition): ValuePosition => {\n    if (isParameter(value)) {\n      const anchor = must(\n        staticQueryParameters,\n        'Static query params do not exist',\n      )[value.anchor];\n      const resolvedValue = resolveField(anchor, value.field);\n      return {\n        type: 'literal',\n        value: resolvedValue as LiteralValue,\n      };\n    }\n    return value;\n  };\n\n  return visit(ast);\n}\n\nfunction resolveField(\n  anchor: Record<string, JSONValue> | Row | undefined,\n  field: string | string[],\n): unknown {\n  if (anchor === undefined) {\n    return null;\n  }\n\n  if (Array.isArray(field)) {\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    return field.reduce((acc, f) => (acc as any)?.[f], anchor) ?? null;\n  }\n\n  return anchor[field] ?? null;\n}\n\nfunction isParameter(value: ValuePosition): value is Parameter {\n  return value.type === 'static';\n}\n\nfunction buildPipelineInternal(\n  ast: AST,\n  delegate: BuilderDelegate,\n  queryID: string,\n  name: string,\n  partitionKey?: CompoundKey | undefined,\n): Input {\n  const source = delegate.getSource(ast.table);\n  if (!source) {\n    throw new Error(`Source not found: ${ast.table}`);\n  }\n  ast = uniquifyCorrelatedSubqueryConditionAliases(ast);\n\n  const csqsFromCondition = gatherCorrelatedSubqueryQueriesFromCondition(\n    ast.where,\n  );\n  const splitEditKeys: Set<string> = partitionKey\n    ? new Set(partitionKey)\n    : new Set();\n  const aliases = new Set<string>();\n  for (const csq of csqsFromCondition) {\n    aliases.add(csq.subquery.alias || '');\n    for (const key of csq.correlation.parentField) {\n      splitEditKeys.add(key);\n    }\n  }\n  if (ast.related) {\n    for (const csq of ast.related) {\n      for (const key of csq.correlation.parentField) {\n        splitEditKeys.add(key);\n      }\n    }\n  }\n  const conn = source.connect(\n    must(ast.orderBy),\n    ast.where,\n    splitEditKeys,\n    delegate.debug,\n  );\n\n  let end: Input = delegate.decorateSourceInput(conn, queryID);\n  end = delegate.decorateInput(end, `${name}:source(${ast.table})`);\n  const {fullyAppliedFilters} = conn;\n\n  if (ast.start) {\n    const skip = new Skip(end, ast.start);\n    delegate.addEdge(end, skip);\n    end = delegate.decorateInput(skip, `${name}:skip)`);\n  }\n\n  for (const csq of csqsFromCondition) {\n    end = applyCorrelatedSubQuery(csq, delegate, queryID, end, name, true);\n  }\n\n  if (ast.where && (!fullyAppliedFilters || delegate.applyFiltersAnyway)) {\n    end = applyWhere(end, ast.where, delegate, name);\n  }\n\n  if (ast.limit !== undefined) {\n    const takeName = `${name}:take`;\n    const take = new Take(\n      end,\n      delegate.createStorage(takeName),\n      ast.limit,\n      partitionKey,\n    );\n    delegate.addEdge(end, take);\n    end = delegate.decorateInput(take, takeName);\n  }\n\n  if (ast.related) {\n    for (const csq of ast.related) {\n      end = applyCorrelatedSubQuery(csq, delegate, queryID, end, name, false);\n    }\n  }\n\n  return end;\n}\n\nfunction applyWhere(\n  input: Input,\n  condition: Condition,\n  delegate: BuilderDelegate,\n  name: string,\n): Input {\n  return buildFilterPipeline(input, delegate, filterInput =>\n    applyFilter(filterInput, condition, delegate, name),\n  );\n}\n\nfunction applyFilter(\n  input: FilterInput,\n  condition: Condition,\n  delegate: BuilderDelegate,\n  name: string,\n) {\n  switch (condition.type) {\n    case 'and':\n      return applyAnd(input, condition, delegate, name);\n    case 'or':\n      return applyOr(input, condition, delegate, name);\n    case 'correlatedSubquery':\n      return applyCorrelatedSubqueryCondition(input, condition, delegate, name);\n    case 'simple':\n      return applySimpleCondition(input, delegate, condition);\n  }\n}\n\nfunction applyAnd(\n  input: FilterInput,\n  condition: Conjunction,\n  delegate: BuilderDelegate,\n  name: string,\n): FilterInput {\n  for (const subCondition of condition.conditions) {\n    input = applyFilter(input, subCondition, delegate, name);\n  }\n  return input;\n}\n\nexport function applyOr(\n  input: FilterInput,\n  condition: Disjunction,\n  delegate: BuilderDelegate,\n  name: string,\n): FilterInput {\n  const [subqueryConditions, otherConditions] =\n    groupSubqueryConditions(condition);\n  // if there are no subquery conditions, no fan-in / fan-out is needed\n  if (subqueryConditions.length === 0) {\n    const filter = new Filter(\n      input,\n      createPredicate({\n        type: 'or',\n        conditions: otherConditions,\n      }),\n    );\n    delegate.addEdge(input, filter);\n    return filter;\n  }\n\n  const fanOut = new FanOut(input);\n  delegate.addEdge(input, fanOut);\n  const branches = subqueryConditions.map(subCondition =>\n    applyFilter(fanOut, subCondition, delegate, name),\n  );\n  if (otherConditions.length > 0) {\n    const filter = new Filter(\n      fanOut,\n      createPredicate({\n        type: 'or',\n        conditions: otherConditions,\n      }),\n    );\n    delegate.addEdge(fanOut, filter);\n    branches.push(filter);\n  }\n  const ret = new FanIn(fanOut, branches);\n  for (const branch of branches) {\n    delegate.addEdge(branch, ret);\n  }\n  fanOut.setFanIn(ret);\n  return ret;\n}\n\nexport function groupSubqueryConditions(condition: Disjunction) {\n  const partitioned: [\n    subqueryConditions: Condition[],\n    otherConditions: NoSubqueryCondition[],\n  ] = [[], []];\n  for (const subCondition of condition.conditions) {\n    if (isNotAndDoesNotContainSubquery(subCondition)) {\n      partitioned[1].push(subCondition);\n    } else {\n      partitioned[0].push(subCondition);\n    }\n  }\n  return partitioned;\n}\n\nexport function isNotAndDoesNotContainSubquery(\n  condition: Condition,\n): condition is NoSubqueryCondition {\n  if (condition.type === 'correlatedSubquery') {\n    return false;\n  }\n  if (condition.type === 'simple') {\n    return true;\n  }\n  return condition.conditions.every(isNotAndDoesNotContainSubquery);\n}\n\nfunction applySimpleCondition(\n  input: FilterInput,\n  delegate: BuilderDelegate,\n  condition: SimpleCondition,\n): FilterInput {\n  const filter = new Filter(input, createPredicate(condition));\n  delegate.decorateFilterInput(\n    filter,\n    `${valuePosName(condition.left)}:${condition.op}:${valuePosName(condition.right)}`,\n  );\n  delegate.addEdge(input, filter);\n  return filter;\n}\n\nfunction valuePosName(left: ValuePosition) {\n  switch (left.type) {\n    case 'static':\n      return left.field;\n    case 'literal':\n      return left.value;\n    case 'column':\n      return left.name;\n  }\n}\n\nfunction applyCorrelatedSubQuery(\n  sq: CorrelatedSubquery,\n  delegate: BuilderDelegate,\n  queryID: string,\n  end: Input,\n  name: string,\n  fromCondition: boolean,\n) {\n  // TODO: we only omit the join if the CSQ if from a condition since\n  // we want to create an empty array for `related` fields that are `limit(0)`\n  if (sq.subquery.limit === 0 && fromCondition) {\n    return end;\n  }\n\n  assert(sq.subquery.alias, 'Subquery must have an alias');\n  const child = buildPipelineInternal(\n    sq.subquery,\n    delegate,\n    queryID,\n    `${name}.${sq.subquery.alias}`,\n    sq.correlation.childField,\n  );\n  const joinName = `${name}:join(${sq.subquery.alias})`;\n  const join = new Join({\n    parent: end,\n    child,\n    storage: delegate.createStorage(joinName),\n    parentKey: sq.correlation.parentField,\n    childKey: sq.correlation.childField,\n    relationshipName: sq.subquery.alias,\n    hidden: sq.hidden ?? false,\n    system: sq.system ?? 'client',\n  });\n  delegate.addEdge(end, join);\n  delegate.addEdge(child, join);\n  return delegate.decorateInput(join, joinName);\n}\n\nfunction applyCorrelatedSubqueryCondition(\n  input: FilterInput,\n  condition: CorrelatedSubqueryCondition,\n  delegate: BuilderDelegate,\n  name: string,\n): FilterInput {\n  assert(condition.op === 'EXISTS' || condition.op === 'NOT EXISTS');\n  if (condition.related.subquery.limit === 0) {\n    if (condition.op === 'EXISTS') {\n      const filter = new Filter(input, () => false);\n      delegate.addEdge(input, filter);\n      return filter;\n    }\n    const filter = new Filter(input, () => true);\n    delegate.addEdge(input, filter);\n    return filter;\n  }\n  const existsName = `${name}:exists(${condition.related.subquery.alias})`;\n  const exists = new Exists(\n    input,\n    delegate.createStorage(existsName),\n    must(condition.related.subquery.alias),\n    condition.related.correlation.parentField,\n    condition.op,\n  );\n  delegate.addEdge(input, exists);\n  return delegate.decorateFilterInput(exists, existsName);\n}\n\nfunction gatherCorrelatedSubqueryQueriesFromCondition(\n  condition: Condition | undefined,\n) {\n  const csqs: CorrelatedSubquery[] = [];\n  const gather = (condition: Condition) => {\n    if (condition.type === 'correlatedSubquery') {\n      assert(condition.op === 'EXISTS' || condition.op === 'NOT EXISTS');\n      csqs.push({\n        ...condition.related,\n        subquery: {\n          ...condition.related.subquery,\n          limit:\n            condition.related.system === 'permissions'\n              ? PERMISSIONS_EXISTS_LIMIT\n              : EXISTS_LIMIT,\n        },\n      });\n      return;\n    }\n    if (condition.type === 'and' || condition.type === 'or') {\n      for (const c of condition.conditions) {\n        gather(c);\n      }\n      return;\n    }\n  };\n  if (condition) {\n    gather(condition);\n  }\n  return csqs;\n}\n\nconst EXISTS_LIMIT = 3;\nconst PERMISSIONS_EXISTS_LIMIT = 1;\n\nexport function assertOrderingIncludesPK(\n  ordering: Ordering,\n  pk: PrimaryKey,\n): void {\n  const orderingFields = ordering.map(([field]) => field);\n  const missingFields = pk.filter(pkField => !orderingFields.includes(pkField));\n\n  if (missingFields.length > 0) {\n    throw new Error(\n      `Ordering must include all primary key fields. Missing: ${missingFields.join(\n        ', ',\n      )}. ZQL automatically appends primary key fields to the ordering if they are missing \n      so a common cause of this error is a casing mismatch between Postgres and ZQL.\n      E.g., \"userid\" vs \"userID\".\n      You may want to add double-quotes around your Postgres column names to prevent Postgres from lower-casing them:\n      https://www.postgresql.org/docs/current/sql-syntax-lexical.htm`,\n    );\n  }\n}\n\nfunction uniquifyCorrelatedSubqueryConditionAliases(ast: AST): AST {\n  if (!ast.where) {\n    return ast;\n  }\n  const {where} = ast;\n  if (where.type !== 'and' && where.type !== 'or') {\n    return ast;\n  }\n\n  let count = 0;\n  const uniquifyCorrelatedSubquery = (csqc: CorrelatedSubqueryCondition) => ({\n    ...csqc,\n    related: {\n      ...csqc.related,\n      subquery: {\n        ...csqc.related.subquery,\n        alias: (csqc.related.subquery.alias ?? '') + '_' + count++,\n      },\n    },\n  });\n\n  const uniquify = (cond: Condition): Condition => {\n    if (cond.type === 'simple') {\n      return cond;\n    } else if (cond.type === 'correlatedSubquery') {\n      return uniquifyCorrelatedSubquery(cond);\n    }\n    const conditions = [];\n    for (const c of cond.conditions) {\n      conditions.push(uniquify(c));\n    }\n    return {\n      type: cond.type,\n      conditions,\n    };\n  };\n\n  const result = {\n    ...ast,\n    where: uniquify(where),\n  };\n  return result;\n}\n","export class NotImplementedError extends Error {\n  constructor(message: string) {\n    super(message);\n    this.name = 'NotImplementedError';\n  }\n}\n","import {assert} from '../../../shared/src/asserts.ts';\nimport type {Immutable} from '../../../shared/src/immutable.ts';\nimport type {TTL} from '../query/ttl.ts';\nimport type {Listener, TypedView} from '../query/typed-view.ts';\nimport type {Change} from './change.ts';\nimport type {Input, Output} from './operator.ts';\nimport type {SourceSchema} from './schema.ts';\nimport {applyChange} from './view-apply-change.ts';\nimport type {Entry, Format, View} from './view.ts';\n\n/**\n * Implements a materialized view of the output of an operator.\n *\n * It might seem more efficient to use an immutable b-tree for the\n * materialization, but it's not so clear. Inserts in the middle are\n * asymptotically slower in an array, but can often be done with zero\n * allocations, where changes to the b-tree will often require several allocs.\n *\n * Also the plain array view is more convenient for consumers since you can dump\n * it into console to see what it is, rather than having to iterate it.\n */\nexport class ArrayView<V extends View> implements Output, TypedView<V> {\n  readonly #input: Input;\n  readonly #listeners = new Set<Listener<V>>();\n  readonly #schema: SourceSchema;\n  readonly #format: Format;\n\n  // Synthetic \"root\" entry that has a single \"\" relationship, so that we can\n  // treat all changes, including the root change, generically.\n  readonly #root: Entry;\n\n  onDestroy: (() => void) | undefined;\n\n  #dirty = false;\n  #complete = false;\n  readonly #updateTTL: (ttl: TTL) => void;\n\n  constructor(\n    input: Input,\n    format: Format,\n    queryComplete: true | Promise<true>,\n    updateTTL: (ttl: TTL) => void,\n  ) {\n    this.#input = input;\n    this.#schema = input.getSchema();\n    this.#format = format;\n    this.#updateTTL = updateTTL;\n    this.#root = {'': format.singular ? undefined : []};\n    input.setOutput(this);\n\n    if (queryComplete === true) {\n      this.#complete = true;\n    } else {\n      void queryComplete.then(() => {\n        this.#complete = true;\n        this.#fireListeners();\n      });\n    }\n    this.#hydrate();\n  }\n\n  get data() {\n    return this.#root[''] as V;\n  }\n\n  addListener(listener: Listener<V>) {\n    assert(!this.#listeners.has(listener), 'Listener already registered');\n    this.#listeners.add(listener);\n\n    this.#fireListener(listener);\n\n    return () => {\n      this.#listeners.delete(listener);\n    };\n  }\n\n  #fireListeners() {\n    for (const listener of this.#listeners) {\n      this.#fireListener(listener);\n    }\n  }\n\n  #fireListener(listener: Listener<V>) {\n    listener(\n      this.data as Immutable<V>,\n      this.#complete ? 'complete' : 'unknown',\n    );\n  }\n\n  destroy() {\n    this.onDestroy?.();\n  }\n\n  #hydrate() {\n    this.#dirty = true;\n    for (const node of this.#input.fetch({})) {\n      applyChange(\n        this.#root,\n        {type: 'add', node},\n        this.#schema,\n        '',\n        this.#format,\n      );\n    }\n    this.flush();\n  }\n\n  push(change: Change): void {\n    this.#dirty = true;\n    applyChange(this.#root, change, this.#schema, '', this.#format);\n  }\n\n  flush() {\n    if (!this.#dirty) {\n      return;\n    }\n    this.#dirty = false;\n    this.#fireListeners();\n  }\n\n  updateTTL(ttl: TTL) {\n    this.#updateTTL(ttl);\n  }\n}\n","import {unreachable} from '../../../shared/src/asserts.ts';\nimport type {Condition} from '../../../zero-protocol/src/ast.ts';\n\n/**\n * Checks if a condition contains any NOT EXISTS operations.\n *\n * The client-side query engine cannot support NOT EXISTS operations because:\n *\n * 1. Zero only syncs a subset of data to the client, defined by the queries you use\n * 2. On the client, we can't distinguish between a row not existing at all vs.\n *    a row not being synced to the client\n * 3. For NOT EXISTS to work correctly, we would need complete knowledge of what\n *    doesn't exist, which is not reasonable with the partial sync model\n *\n * @param condition The condition to check\n * @throws Error if the condition uses NOT EXISTS operator\n */\nexport function assertNoNotExists(condition: Condition): void {\n  switch (condition.type) {\n    case 'simple':\n      // Simple conditions don't use EXISTS/NOT EXISTS\n      return;\n\n    case 'correlatedSubquery':\n      if (condition.op === 'NOT EXISTS') {\n        throw new Error(\n          'not(exists()) is not supported on the client - see https://bugs.rocicorp.dev/issue/3438',\n        );\n      }\n      // Check if the subquery has a where condition\n      if (condition.related.subquery.where) {\n        assertNoNotExists(condition.related.subquery.where);\n      }\n      return;\n\n    case 'and':\n    case 'or':\n      for (const c of condition.conditions) {\n        assertNoNotExists(c);\n      }\n      return;\n    default:\n      unreachable(condition);\n  }\n}\n"],"names":["assert","v","path","toDisplay","err","atPath","hash","hash","v","assert","assert","hash","v","path","hash","binarySearch","v","getSizeOfEntry","hash","binarySearch","array","entries","getSizeOfEntry","splice","hash","binarySearch","diff","v","hash","v","v","createChunk","value","hash","v","value","entries","hash","createChunk","chunk","diff","valueHash","assert","hash","valueHash","indexRecords","v","v","compareUTF8","compareUTF8","v","node","relationship","binarySearch","v","v","compareUTF8","defined","table","val","compareUTF8","c","array","hash","hash","z1","z2","hash","v","change","key","cmp","cmp","flattened","array","impl","not","take","filter","condition","v","cleanup"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACAA,YAAY,OAAO;;AUAnB,SAAQ,mBAAkB;;AcA1B,SAAQ,YAAW;;AoBAnB,SAAQ,gBAAe;;;AOEvB,SAAQ,gBAAe;;;;;;;;iCAwtBhB,kBAAkB,GAIZ,cAAc;IzCpezB,kGcjOwC;;;;;;;;;;;;;;;GAAA,4HwBPxC,mHAQA,iFK2BS,kFGRA,8CAIe;;;;;;;GAAA,YA+KxB;;;;;;;;GAAA,GAWA,SAGA;;GAAA,mEA+BA,6FChPS,uCCbA,0CGEA,qBAGT,UC2BS,2FAUT,iDAyMC,4EC1OQ,8BAIT,iECoBS,oEAIA,kDAAA;sEA4VT,mHMxXS,2EAAA;AAAA,6DAAA;wFnB2GA,sBAKT;;;;ApDtIK,IAAM,OAAO;AAEb,IAAM,KAAK;AAEX,IAAM,KAAK;AACX,IAAM,SAAS;;ACRtB,IAAA,iBAAA,CAAA;IAAA,qWAAA,EAAA,gBAAA;IAAA,QAAA,IAAAA;IAAA,aAAA,IAAA;IAAA,wBAAA,IAAA;IAAA,IAAA,IAAA;IAAA,cAAA,IAAA;IAAA,OAAA,IAAA;IAAA,UAAA,IAAA;IAAA,eAAA,IAAA;IAAA,gBAAA,IAAA;IAAA,gBAAA,IAAA;IAAA,MAAA,IAAA;IAAA,cAAA,IAAA;AAAA;IAEA,uWAAA,EAAA,gBAAA;;;AAEA,SAAS,UAAU,KAAA,EAAwB;IACzC,OAAQ,OAAO,OAAO;QACpB,KAAK;QACL,KAAK;QACL,KAAK;YACH,OAAO,KAAK,SAAA,CAAU,KAAK;QAC7B,KAAK;YACH,OAAO;QACT,KAAK;YACH,OAAO,MAAM,QAAA,CAAS,IAAI;QAC5B;YACE,IAAI,UAAU,MAAM;gBAClB,OAAO;YACT;YACA,IAAI,MAAM,OAAA,CAAQ,KAAK,GAAG;gBACxB,OAAO;YACT;YACA,OAAO,OAAO;IAClB;AACF;AAIA,SAAS,gBAAgBC,EAAAA,EAAYC,KAAAA,EAAiC;IACpE,IAAI,gDAACA,MAAM,MAAA,GAAQ;QACjB,OAAO,UAAUD,EAAC;IACpB;IAEA,IAAI,MAAMA;IACV,KAAA,MAAW,KAAKC,MAAM;QAEpB,MAAO,GAAA,CAAY,CAAC,CAAA;IACtB;IACA,OAAO,UAAU,GAAG;AACtB;AAEA,SAAS,YACP,IAAA,EACA,QAAA;qBACAC,iEAAuC,CAAA,IAAK,OAAO,CAAC,GACnC;IACjB,IAAI,SAAS,MAAA,KAAW,GAAG;QACzB,OAAOA,WAAU,QAAA,CAAS,CAAC,CAAC;IAC9B;IAEA,MAAM,SAAS,UAAGA,WAChB,QAAA,CAAS,SAAS,MAAA,GAAS,CAAC,CAAA,GAC7B,YAAI,IAAI,EAAA,KAA4C,OAAxCA,WAAU,QAAA,CAAS,SAAS,MAAA,GAAS,CAAC,CAAC,CAAC;IACrD,IAAI,SAAS,MAAA,KAAW,GAAG;QACzB,OAAO;IACT;IACA,OAAO,UAAG,SAAS,KAAA,CAAM,GAAG,CAAA,CAAE,EAAE,GAAA,CAAIA,UAAS,EAAE,IAAA,CAAK,IAAI,CAAC,EAAA,MAAW,OAAN,MAAM;AACtE;AAEA,SAAS,WACPC,IAAAA,EACAH,EAAAA,EACA,MAAA,EACA,IAAA,EACQ;IACR,MAAM,aAAaG,KAAI,MAAA,CAAO,CAAC,CAAA;IAC/B,MAAM,EAAC,MAAAF,KAAAA,CAAI,CAAA,GAAI;IACf,MAAM,wDAASA,MAAM,MAAA,IAAS,OAAqB,OAAdA,MAAK,IAAA,CAAK,GAAG,CAAC,IAAK;IAExD,OAAQ,WAAW,IAAA,EAAM;QACvB,KAAK;YACH,OAAO,mBAAY,YACjB,MACA,WAAW,QAAA,GACM,OAAf,MAAM,EAAA,UAAiC,uBAARD,IAAGC,KAAI,CAAC;QAC7C,KAAK;YAAiB;oBAIhB;gBAHJ,MAAMG,UACJH,SAAQA,MAAK,MAAA,GAAS,IAAI,OAAkC,OAA3BA,MAAK,KAAA,CAAM,GAAG,CAAA,CAAE,EAAE,IAAA,CAAK,GAAG,CAAC,IAAK;gBAEnE,mCAAe,IAAA,sEAAM,MAAA,EAAQ;oBAC3B,OAAO,oBAA6CG,OAAzB,AAA+B,WAApB,IAAA,CAAK,EAAA,CAAG,CAAA,CAAE,CAAC,EAAS;gBAC5D;gBACA,OAAO,gCAAsC,OAANA,OAAM;YAC/C;QAEA,KAAK;YACH,OAAO,0BAIH,MAAM,CAJuB,YAC/B,MACA,WAAW,QAAA,EACX,2BACQ,SAAgC,OAAxB,gBAAgBJ,IAAGC,KAAI,CAAC;QAE5C,KAAK;YAAkB;gBACrB,OAAO,8BAIJ,MAAM,CAHP,WAAW,SAAA,KAAc,WAAW,SAAA,GAChC,WAAW,SAAA,GACX,WAAuC,OAA5B,WAAW,SAAS,EAAA,SAA4B,CACjE,iBADwD,SAAS,kBACxD,4BAAyD,OAA7BD,GAAuB,MAAM;YACpE;QAEA,KAAK;YACH,IAAI,WAAW,IAAA,CAAK,MAAA,KAAW,GAAG;gBAChC,OAAO,uBAA4C,MAAM,CAA3B,WAAW,IAAA,CAAK,CAAC,CAAC,EAAS;YAC3D;YACA,OAAO,gCAAyB,YAC9B,OACA,WAAW,IAAA,GACH,OAAN,MAAM;QAEZ,KAAK;YACH,OAAO,OAAO,IAAA,KAAS,UACnB,0BAA0BA,IAAG,yBAAuB,yBAAQ,QAAQ,IACpE,sBAA4B,OAAN,MAAM;QAElC,KAAK;YAAgB;gBACnB,MAAM,EAAC,KAAA,CAAK,CAAA,GAAI;;gBAChB,MAAM,UAAU,CAAC,QACb,YACA,OAAO,UAAU,WACf,gCACO,OAAA,0CAAN,iBAAiB;gBACxB,OAAO,UAAG,OAAO,SAAG,MAAM,EAAA,UAAiC,OAAxB,gBAAgBA,IAAGC,KAAI,CAAC;YAC7D;IACF;AACF;AAIA,SAAS,0BACP,KAAA,EACA,MAAA,EACA,IAAA,EACQ;IACR,MAAM,WAAyB,CAAC,CAAA;IAChC,KAAA,MAAW,QAAQ,OAAO,OAAA,CAAS;QACjC,MAAM,IAAI,KAAK,GAAA,CAAI,OAAO;YAAC;QAAI,CAAC;QAChC,IAAI,CAAC,EAAE,EAAA,EAAI;YACT,SAAS,IAAA,CAAK;gBAAC;gBAAM,KAAK;YAAC,CAAC;QAC9B;IACF;IACA,IAAI,SAAS,MAAA,EAAQ;QAEnB,SAAS,IAAA,CAAK,OAAO;QACrB,IAAI,SAAS,MAAA,KAAW,KAAK,QAAQ,QAAA,CAAS,CAAC,CAAA,EAAG,QAAA,CAAS,CAAC,CAAC,IAAI,GAAG;YAClE,OAAO,WAAW,QAAA,CAAS,CAAC,CAAA,CAAE,GAAA,EAAK,OAAO,QAAA,CAAS,CAAC,CAAA,CAAE,IAAA,EAAM,IAAI;QAClE;IACF;IAEA,IAAI;QACF,MAAM,MAAM,KAAK,SAAA,CAAU,KAAK;QAChC,OAAO,wBAA2B,OAAH,GAAG;IACpC,EAAA,OAAS,GAAG;QAEV,OAAO;IACT;AACF;AAKA,SAAS,QAAQ,CAAA,EAAe,CAAA,EAAe;IAC7C,MAAM,QAAQ,EAAE,GAAA,CAAI,MAAA,CAAO,CAAC,CAAA,CAAE,IAAA;IAC9B,MAAM,QAAQ,EAAE,GAAA,CAAI,MAAA,CAAO,CAAC,CAAA,CAAE,IAAA;IAC9B,IAAI,MAAM,MAAA,KAAW,MAAM,MAAA,EAAQ;QACjC,OAAO,MAAM,MAAA,GAAS,MAAM,MAAA;IAC9B;IACA,IAAA,IAAS,IAAI,GAAG,IAAI,MAAM,MAAA,EAAQ,IAAK;QACrC,IAAI,KAAA,CAAM,CAAC,CAAA,GAAI,KAAA,CAAM,CAAC,CAAA,EAAG;YACvB,OAAO,CAAA;QACT;QACA,IAAI,KAAA,CAAM,CAAC,CAAA,GAAI,KAAA,CAAM,CAAC,CAAA,EAAG;YACvB,OAAO;QACT;IACF;IACA,OAAO;AACT;AASO,SAAS,MACd,KAAA,EACA,MAAA,EACA,IAAA,EACG;IACH,MAAM,MAAM,KAAK,OAAO,QAAQ,IAAI;IACpC,IAAI,CAAC,IAAI,EAAA,EAAI;QACX,MAAM,IAAI,UAAU,IAAI,KAAK;IAC/B;IACA,OAAO,IAAI,KAAA;AACb;AAEO,SAAS,GACd,KAAA,EACA,MAAA,EACA,IAAA,EACY;IACZ,OAAO,KAAK,OAAO,QAAQ,IAAI,EAAE,EAAA;AACnC;AAEO,SAASF,QACd,KAAA,EACA,MAAA,EACA,IAAA,EACoB;IACpB,MAAM,OAAO,QAAQ,IAAI;AAC3B;AAIO,SAAS,KACd,KAAA,EACA,MAAA,EACA,IAAA,EACW;IACX,MAAM,MAAM,OAAO,GAAA,CAAI,OAAO,OAAO;QAAC;IAAI,IAAI,KAAA,CAAS;IACvD,IAAI,CAAC,IAAI,EAAA,EAAI;QACX,OAAO;YACL,IAAI;YACJ,OAAO,WAAW,KAAK,OAAO,QAAQ,IAAI;QAC5C;IACF;IACA,OAAO;AACT;AAOO,SAAS,aACd,KAAA,EACA,MAAA,EACA,IAAA,EACuB;IACvB,IAAI,QAAQ;IACZ,IAAI,SAAS,eAAe;QAC1B,QAAQ;IACV,OAAA,IAAW,SAAS,SAAS;QAC3B,QAAQ;IACV;IACA,MAAM,MAAM,OAAO,IAAA,CAAK,OAAO,KAAK;IACpC,IAAI,QAAQ,KAAA,GAAW;QACrB,OAAO;YAAC,IAAI;YAAM;QAAK;IACzB,OAAA,IAAW,IAAI,EAAA,EAAI;QACjB,OAAO;IACT;IACA,MAAMI,OAAM,IAAM,+NAAA,WAAA,CAAY,GAAG;IACjC,OAAO;QAAC,IAAI;QAAO,OAAO,WAAWA,MAAK,OAAO,QAAQ,IAAI;IAAC;AAChE;AAKO,SAAS,SAA2B,CAAA,EAAoC;IAC7E,OAAO;AACT;AAEO,SAAS,eACd,CAAA,EACsC;IACtC,OAAS,+NAAA,MAAA,CAAO,CAAC;AACnB;AAEO,SAAS,cACd,CAAA,EAC+B;IAC/B,OAAS,+NAAA,KAAA,CAAM,CAAC;AAClB;AAEO,SAAS,eACd,CAAA,EAC8C;IAC9C,OAAS,+NAAA,MAAA,CAAO,CAAC;AACnB;AAGA,IAAM,eAAe,OAAO,cAAA,CAC1B,OAAO,cAAA,CAAiB,+NAAA,MAAA,CAAO,EAAE,QAAA,CAAS,CAAC,GAC3C,WAAA;AAEK,SAAS,uBACd,GAAA,EACkC;IAClC,OAAO,eAAe;AACxB;AAQO,SAAS,YACd,CAAA,EACA;IACA,MAAM,QAAQ,CAAC;IACf,KAAA,MAAW,CAAC,KAAK,IAAI,CAAA,IAAK,OAAO,OAAA,CAAQ,EAAE,KAAK,EAAG;QACjD,IAAI,KAAK,IAAA,KAAS,UAAU;YAC1B,KAAA,CAAM,GAAG,CAAA,GAAI,YAAY,IAAoB,EAAE,QAAA,CAAS;QAC1D,OAAO;YACL,KAAA,CAAM,GAAG,CAAA,GAAI,KAAK,QAAA,CAAS;QAC7B;IACF;IACA,OAAS,+NAAA,MAAA,CAAO,KAA4D;AAC9E;AAIO,SAAS;IAAA,IAAA,IAAA,OAAA,UAAA,QAAA,WAAA,UAAA,OAAA,OAAA,GAAA,OAAA,MAAA;QACX,SADW,QAAA,SAAA,CAAA,KACX,EACgB;;IACnB,OAAS,+NAAA,KAAA,CAAM,GAAG,SAAS,GAAA,CAAM,+NAAA,OAAO,CAAC;AAC3C;;AC1RO,IAAM,qBAAN,cAAiC,MAAM;IAG5C,YAAYE,KAAAA,CAAY;QACtB,KAAA,CAAM,mBAAuB,CAAE,MAANA,KAAI,iPAH/B,QAAO,iRACE;QAGP,IAAA,CAAK,IAAA,GAAOA;IACd;AACF;AAEA,eAAsB,aACpB,KAAA,EACAA,KAAAA,EACgB;IAChB,MAAM,QAAQ,MAAM,MAAM,QAAA,CAASA,KAAI;IACvC,IAAI,OAAO;QACT,OAAO;IACT;IACA,MAAM,IAAI,mBAAmBA,KAAI;AACnC;AAEA,eAAsB,gBACpB,IAAA,EACA,KAAA,EACe;IACf,MAAMA,QAAO,MAAM,MAAM,OAAA,CAAQ,IAAI;IACrC,IAAA,mWAAA,EAAOA,OAAM,gBAAoB,CAAE,MAAN,IAAI;IACjC,OAAOA;AACT;;AC7CO,SAAS,SACd,KAAA,EACA,EAAA,EACiB;IACjB,OAAO,MAAM,MAAM,IAAA,CAAK,GAAG,EAAE;AAC/B;AAEO,SAAS,0BACd,KAAA,EACA,EAAA,EACiB;IACjB,OAAO,MAAM,MAAM,KAAA,CAAM,GAAG,EAAE;AAChC;AAEO,SAAS,UACd,KAAA,EACA,EAAA,EACiB;IACjB,OAAO,MAAM,MAAM,KAAA,CAAM,GAAG,OAAM,UAAS;QACzC,MAAM,SAAS,MAAM,GAAG,KAAK;QAC7B,MAAM,MAAM,MAAA,CAAO;QACnB,OAAO;IACT,CAAC;AACH;AAOA,eAAsB,MACpB,CAAA,EACA,EAAA,EACiB;IACjB,MAAM,QAAQ,MAAM;IACpB,IAAI;QACF,OAAO,MAAM,GAAG,KAAK;IACvB,SAAE;QACA,MAAM,OAAA,CAAQ;IAChB;AACF;;ACvCO,SAAS,OAAO,UAAA,EAA0B;IAC/C,OAAO;AACT;AAMO,SAAS,OAAO,IAAA,EAAgC;IACrD,IAAI,MAAM,OAAA,CAAQ,IAAI,GAAG;QACvB,KAAK,IAAA,CAAK;QACV,IAAA,IAAS,IAAI,GAAG,IAAI,KAAK,MAAA,EAAQ,IAAK;YACpC,IAAA,mWAAA,EAAO,IAAA,CAAK,IAAI,CAAC,CAAA,KAAM,IAAA,CAAK,CAAC,CAAA,EAAG,+BAA+B;QACjE;QACA,OAAO,OAAO,IAAI;IACpB;IAEA,MAAM,YAAY,CAAC;WAAG,IAAI;KAAA;IAC1B,UAAU,IAAA,CAAK;IAEf,OAAO,OAAO,SAAS;AACzB;AAEO,IAAM,QAAN,MAAyB;IAU9B,YAAYC,KAAAA,EAAY,IAAA,EAAS,IAAA,CAAY;kQATpC;kQACA;QAAA;;;GAAA,6PAMA;QAGP,IAAA,mWAAA,EACE,CAAE,KAAmB,QAAA,CAASA,KAAI,GAClC;QAEF,IAAA,6WAAA,EAAiB,IAAI;QACrB,IAAA,CAAK,IAAA,GAAOA;QACZ,IAAA,CAAK,IAAA,GAAO;QACZ,IAAA,CAAK,IAAA,GAAO;IACd;AACF;AAEO,SAAS,WAAWC,EAAAA,EAA+B;IACxD,IAAI,CAAC,MAAM,OAAA,CAAQA,EAAC,GAAG;QACrB,MAAM,IAAI,MAAM,uBAAuB;IACzC;IACA,IAAIA,GAAE,MAAA,GAAS,GAAG;QAChB,IAAA,yWAAA,EAAaA,EAAAA,CAAE,CAAC,CAAC;QACjB,IAAA,IAAS,IAAI,GAAG,IAAIA,GAAE,MAAA,EAAQ,IAAK;YACjC,IAAA,yWAAA,EAAaA,EAAAA,CAAE,CAAC,CAAC;QACnB;IACF;AACF;AAEO,SAAS,YACd,IAAA,EACA,IAAA,EACA,WAAA,EACU;IACV,MAAMD,QAAO,YAAY;IACzB,OAAO,IAAI,MAAMA,OAAM,MAAM,IAAI;AACnC;;ACjFO,SAAS,eAAuB;IAErC,MAAM,OAAO,KAAK,KAAA,CAAM,KAAK,MAAA,CAAO,IAAI,UAAU;IAClD,MAAM,MAAM,KAAK,KAAA,CAAM,KAAK,MAAA,CAAO,IAAI,UAAU;IAGjD,OAAQ,OAAO,IAAI,KAAK,GAAA,GAAO,OAAO,GAAG;AAC3C;;ACHO,IAAM,gBAAgB;AAwB7B,IAAM,SAAS;AAOf,IAAM,YAAY,IAAI,MAAA,CAAO,aAAa;AACnC,IAAM,YAAY;AAKlB,IAAM,gBAAgB,kCAAkC;AAmB/D,SAAS,iBAAiB,CAAA,EAAoB,GAAA,EAAqB;IACjE,OAAO,EAAE,QAAA,CAAS,EAAE,EAAE,KAAA,CAAM,CAAC,GAAG,EAAE,QAAA,CAAS,KAAK,GAAG;AACrD;AASA,SAAS,oCAAgD;IACvD,IAAI,OAAO;IACX,IAAI,IAAI;IAER,OAAO,MAAM;QACX,IAAI,CAAC,MAAM;YAMT,OAAO,iBAAiB,aAAa,GAAG,EAAE;QAC5C;QACA,MAAM,OAAO,iBAAiB,KAAK,EAAE;QACrC,OAAQ,OAAO;IACjB;AACF;AAYO,SAAS,OAAO,KAAA,EAA+B;IACpD,OAAO,OAAO,UAAU,YAAY,OAAO,IAAA,CAAK,KAAK;AACvD;AAEO,SAAS,WAAW,KAAA,EAAuC;IACzDE,QAAO,OAAO,UAAU;AACjC;AAEO,IAAM,aAAoB,eAAA,MAAA,CAAO,EAAE,MAAA,CAAO,QAAQ,cAAc;;AChFhE,IAAM,wBACJ,eAAe;IACpB,QAAe,eAAA,MAAA,CAAO,EAAE,QAAA,CAAS;IACjC,aAAoB,eAAA,MAAA,CAAO;IAC3B,YAAmB,eAAA,OAAA,CAAQ,EAAE,QAAA,CAAS;AACxC,CAAC;AAQI,IAAM,yBAAgC,eAC3C;AAGK,SAAS,qBACd,CAAA,EACA,CAAA,EACS;QAGN,eAA4B,eAC5B;IAHH,OACE,EAAE,WAAA,KAAgB,EAAE,WAAA,IAAA,oBACjB,UAAA,yDAAc,KAAA,MAAA,oBAAc,UAAA,yDAAc,KAAA,KAAA,gBAC1C,MAAA,iDAAU,EAAA,MAAA,cAAS,EAAE,MAAA,iDAAU,EAAA;AAEtC;AAEO,SAAS,sBACd,CAAA,EACA,CAAA,EACS;IACT,IAAI,OAAO,IAAA,CAAK,CAAC,EAAE,MAAA,KAAW,OAAO,IAAA,CAAK,CAAC,EAAE,MAAA,EAAQ;QACnD,OAAO;IACT;IACA,KAAA,MAAW,CAAC,MAAM,MAAM,CAAA,IAAK,OAAO,OAAA,CAAQ,CAAC,EAAG;QAC9C,MAAM,SAAS,CAAA,CAAE,IAAI,CAAA;QACrB,IAAI,CAAC,UAAU,CAAC,qBAAqB,QAAQ,MAAM,GAAG;YACpD,OAAO;QACT;IACF;IACA,OAAO;AACT;;AC1DA,IAAM,oBAA2B,eAAe;IAAA;;;GAAA,GAK9C,UAAU;IAAA;;GAAA,GAKV,cAAqB,cAAqB,eAAA,MAAA,CAAO,CAAC;IAAA;;GAAA,GAKlD,SAAS;IAAA;;;;;;;;GAAA,GAWT,aAAoB,eAAsB,eAAA,MAAA,CAAO,CAAC;IAAA;;;;;;;;;;;;;;;GAAA,GAkBlD,2BAAkC,eAAA,MAAA,CAAc,eAAA,MAAA,CAAO,CAAC;IAAA;;;;GAAA,GAOxD,UAAiB,eAAA,OAAA,CAAQ;AAC3B,CAAC;AAIM,IAAM,0BAA0B;AAEvC,SAAS,kBAAkB,KAAA,EAA8C;IAChEC,QAAO,OAAO,iBAAiB;AACxC;AAEA,SAAS,0BAA0B,SAAA,EAAoC;IACrE,IAAA,yWAAA,EAAa,SAAS;IACtB,MAAM,eAAe,aAAA,GAAA,IAAI,IAAgC;IACzD,KAAA,MAAW,CAAC,KAAK,KAAK,CAAA,IAAK,OAAO,OAAA,CAAQ,SAAS,EAAG;QACpD,IAAI,UAAU,KAAA,GAAW;YACvB,kBAAkB,KAAK;YACvB,aAAa,GAAA,CAAI,KAAK,KAAK;QAC7B;IACF;IACA,OAAO;AACT;AAEA,SAAS,0BACP,YAAA,EACA,QAAA,EACiB;IACjB,MAAM,YAAgD,CAAC;IACvD,KAAA,MAAW,CAAC,eAAe,WAAW,CAAA,IAAK,aAAa,OAAA,CAAQ,EAAG;QACjE,SAAS,eAAA,CAAgB,YAAY,QAAQ;QAC7C,SAAA,CAAU,aAAa,CAAA,GAAI;YACzB,GAAG,WAAA;YACH,cAAc,CAAC;mBAAG,YAAY,YAAA,CAAa,MAAA,CAAO,CAAC;aAAA;QACrD;IACF;IACA,WAAO,uWAAA,EAAW,SAAS;AAC7B;AAEA,eAAe,sBACbC,KAAAA,EACA,OAAA,EACyB;IACzB,MAAM,QAAQ,MAAM,QAAQ,QAAA,CAASA,KAAI;IACzC,OAAO,wEAA0B,MAAO,IAAI;AAC9C;AAEA,eAAsB,gBAAgB,OAAA,EAAwC;IAC5E,MAAMA,QAAO,MAAM,QAAQ,OAAA,CAAQ,uBAAuB;IAC1D,IAAI,CAACA,OAAM;QACT,OAAO,aAAA,GAAA,IAAI,IAAI;IACjB;IACA,OAAO,sBAAsBA,OAAM,OAAO;AAC5C;AAEA,eAAsB,gBACpB,YAAA,EACA,QAAA,EACyB;IACzB,MAAM,mBAAmB,MAAM,gBAAgB,QAAQ;IACvD,KAAA,MAAW,CAAC,eAAe,WAAW,CAAA,IAAK,aAAc;QACvD,MAAM,kBAAkB,iBAAiB,GAAA,CAAI,aAAa;QAC1D,0BAA0B,aAAa,eAAe;IACxD;IACA,OAAO,yBAAyB,cAAc,QAAQ;AACxD;AAEA,eAAsB,eACpB,aAAA,EACA,WAAA,EACA,QAAA,EACyB;IACzB,MAAM,mBAAmB,MAAM,gBAAgB,QAAQ;IACvD,MAAM,kBAAkB,iBAAiB,GAAA,CAAI,aAAa;IAC1D,0BAA0B,aAAa,eAAe;IACtD,MAAM,kBAAkB,IAAI,IAAI,gBAAgB;IAChD,gBAAgB,GAAA,CAAI,eAAe,WAAW;IAC9C,OAAO,yBAAyB,iBAAiB,QAAQ;AAC3D;AAeA,SAAS,0BACP,WAAA,EACA,eAAA,EACA;IACA,MAAM,kBAAkB,IAAI,IAAI,YAAY,YAAY;IACxD,IAAA,mWAAA,EACE,gBAAgB,IAAA,KAAS,YAAY,YAAA,CAAa,MAAA,EAClD;IAEF,IAAI,oBAAoB,KAAA,GAAW;QACjC,IAAA,mWAAA,EACE,sBAAsB,gBAAgB,OAAA,EAAS,YAAY,OAAO,GAClE;QAEF,IAAA,mWAAA,EACE,kBAAkB,iBAAiB,gBAAgB,YAAY,GAC/D;IAEJ;AACF;AAEA,eAAe,yBACb,YAAA,EACA,QAAA,EACyB;IACzB,MAAM,YAAY,0BAA0B,cAAc,QAAQ;IAClE,MAAM,OAAkB,aAAA,GAAA,IAAI,IAAI;IAChC,KAAA,MAAW,eAAe,aAAa,MAAA,CAAO,EAAG;QAC/C,KAAK,GAAA,CAAI,YAAY,QAAQ;IAC/B;IACA,MAAM,QAAQ,SAAS,WAAA,CAAY,WAAW,OAAO,IAAI,CAAC;IAC1D,MAAM,SAAS,QAAA,CAAS,KAAK;IAC7B,MAAM,SAAS,OAAA,CAAQ,yBAAyB,MAAM,IAAI;IAC1D,OAAO;AACT;AAEO,SAAS,kBACd,eAAA,EACA,YAAA,EACS;IACT,IAAI,aAAa,MAAA,KAAW,gBAAgB,IAAA,EAAM;QAChD,OAAO;IACT;IACA,KAAA,MAAW,eAAe,aAAc;QACtC,IAAI,CAAC,gBAAgB,GAAA,CAAI,WAAW,GAAG;YACrC,OAAO;QACT;IACF;IACA,OAAO;AACT;AAEA,eAAsB,eACpB,EAAA,EACA,OAAA,EACkC;IAClC,MAAM,eAAe,MAAM,gBAAgB,OAAO;IAClD,OAAO,aAAa,GAAA,CAAI,EAAE;AAC5B;AAEO,SAAS,+BAA+B,WAAA,EAA0B;IACvE,KAAA,MAAW,CAAC,UAAU,UAAU,CAAA,IAAK,OAAO,OAAA,CAC1C,YAAY,WAAA,EACX;QACD,MAAM,2BACJ,YAAY,yBAAA,CAA0B,QAAQ,CAAA;QAChD,IACG,6BAA6B,KAAA,KAAa,eAAe,KAC1D,2BAA2B,YAC3B;YACA,OAAO;QACT;IACF;IACA,OAAO;AACT;AASA,eAAsB,mBACpB,aAAA,EACA,QAAA,EACe;IACf,MAAM,cAAc,MAAM,eAAe,eAAe,QAAQ;IAChE,IAAI,CAAC,aAAa;QAEhB;IACF;IACA,MAAM,sBAAsB;QAC1B,GAAG,WAAA;QACH,UAAU;IACZ;IACA,MAAM,eAAe,eAAe,qBAAqB,QAAQ;AACnE;;ACpMO,SAAS,UACd,CAAA,EACA,CAAA,EACS;IACT,IAAI,MAAM,GAAG;QACX,OAAO;IACT;IAEA,IAAI,OAAO,MAAM,OAAO,GAAG;QACzB,OAAO;IACT;IAEA,OAAQ,OAAO,GAAG;QAChB,KAAK;QACL,KAAK;QACL,KAAK;YACH,OAAO;IACX;IAKA,IAAI;IAGJ,IAAI,MAAM,OAAA,CAAQ,CAAC,GAAG;QACpB,IAAI,CAAC,MAAM,OAAA,CAAQ,CAAC,GAAG;YACrB,OAAO;QACT;QACA,IAAI,EAAE,MAAA,KAAW,EAAE,MAAA,EAAQ;YACzB,OAAO;QACT;QACA,IAAA,IAAS,IAAI,GAAG,IAAI,EAAE,MAAA,EAAQ,IAAK;YACjC,IAAI,CAAC,UAAU,CAAA,CAAE,CAAC,CAAA,EAAG,CAAA,CAAE,CAAC,CAAC,GAAG;gBAC1B,OAAO;YACT;QACF;QACA,OAAO;IACT;IAEA,IAAI,MAAM,QAAQ,MAAM,MAAM;QAC5B,OAAO;IACT;IAEA,IAAI,MAAM,OAAA,CAAQ,CAAC,GAAG;QACpB,OAAO;IACT;IAGA,IAAI;IACJ,IAAI;IAKJ,IAAI,QAAQ;IACZ,IAAA,MAAW,OAAO,EAAG;QACnB,QAAI,mWAAA,EAAO,GAAG,GAAG,GAAG;YAClB,IAAI,CAAC,UAAU,CAAA,CAAE,GAAG,CAAA,EAAG,CAAA,CAAE,GAAG,CAAC,GAAG;gBAC9B,OAAO;YACT;YACA;QACF;IACF;IAEA,IAAI,QAAQ;IACZ,IAAA,MAAW,OAAO,EAAG;QACnB,QAAI,mWAAA,EAAO,GAAG,GAAG,GAAG;YAClB;QACF;IACF;IAEA,OAAO,UAAU;AACnB;AAEO,SAAS,gBAAgBC,EAAAA,EAAoC;IAClE,IAAI,mWAAA,EAAqB;QACvB;IACF;IACA,OAAQ,OAAOA,IAAG;QAChB,KAAK;QACL,KAAK;QACL,KAAK;YACH;QACF,KAAK;YACH,IAAIA,OAAM,MAAM;gBACd;YACF;YACA,IAAI,MAAM,OAAA,CAAQA,EAAC,GAAG;gBACpB,OAAO,gBAAgBA,EAAC;YAC1B;YACA,OAAO,yBAAyBA,EAA4B;IAChE;IACA,IAAA,6WAAA,EAAiBA,IAAG,YAAY;AAClC;AAEO,SAAS,iBAAiBA,EAAAA,EAAqC;IACpE,IAAA,yWAAA,EAAaA,EAAC;IACd,yBAAyBA,EAAC;AAC5B;AAEA,SAAS,yBACPA,EAAAA,EACyB;IACzB,IAAA,MAAW,KAAKA,GAAG;QACjB,QAAI,mWAAA,EAAOA,IAAG,CAAC,GAAG;YAChB,MAAM,QAAQA,EAAAA,CAAE,CAAC,CAAA;YACjB,IAAI,UAAU,KAAA,GAAW;gBACvB,gBAAgB,KAAK;YACvB;QACF;IACF;AACF;AAEA,SAAS,gBAAgBA,EAAAA,EAAwC;IAC/D,KAAA,MAAW,QAAQA,GAAG;QACpB,gBAAgB,IAAI;IACtB;AACF;AAWO,SAAS,YAAYA,EAAAA,EAAYC,KAAAA,EAA4B;IAClE,OAAQ,OAAOD,IAAG;QAChB,KAAK;QACL,KAAK;QACL,KAAK;YACH,OAAO;QACT,KAAK;YACH,IAAIA,OAAM,MAAM;gBACd,OAAO;YACT;YACA,IAAI,MAAM,OAAA,CAAQA,EAAC,GAAG;gBACpB,OAAO,YAAYA,IAAGC,KAAI;YAC5B;YACA,OAAO,mBAAmBD,IAA8BC,KAAI;IAChE;IACA,OAAO;AACT;AAEO,SAAS,aAAaD,EAAAA,EAAYC,KAAAA,EAA6B;IACpE,IAAI,OAAOD,OAAM,YAAYA,OAAM,MAAM;QACvC,OAAO;IACT;IACA,OAAO,mBAAmBA,IAA8BC,KAAI;AAC9D;AAEA,SAAS,mBACPD,EAAAA,EACAC,KAAAA,EACiB;IACjB,IAAA,MAAW,KAAKD,GAAG;QACjB,QAAI,mWAAA,EAAOA,IAAG,CAAC,GAAG;YAChBC,MAAK,IAAA,CAAK,CAAC;YACX,MAAM,QAAQD,EAAAA,CAAE,CAAC,CAAA;YACjB,IAAI,UAAU,KAAA,KAAa,CAAC,YAAY,OAAOC,KAAI,GAAG;gBACpD,OAAO;YACT;YACAA,MAAK,GAAA,CAAI;QACX;IACF;IACA,OAAO;AACT;AAEA,SAAS,YAAYD,EAAAA,EAAcC,KAAAA,EAA8B;IAC/D,IAAA,IAAS,IAAI,GAAG,IAAID,GAAE,MAAA,EAAQ,IAAK;QACjCC,MAAK,IAAA,CAAK,CAAC;QACX,IAAI,CAAC,YAAYD,EAAAA,CAAE,CAAC,CAAA,EAAGC,KAAI,GAAG;YAC5B,OAAO;QACT;QACAA,MAAK,GAAA,CAAI;IACX;IACA,OAAO;AACT;;ACvOA,IAAM,WAAW;AACjB,IAAM,aAAa;AACnB,IAAM,WAAW;AACjB,IAAM,cAAc;AAkBb,SAAS,eAAe,KAAA,EAAwB;IACrD,OAAQ,OAAO,OAAO;QACpB,KAAK;YAIH,OAAO,WAAW,aAAa,MAAM,MAAA;QACvC,KAAK;YACH,IAAI,MAAM,KAAK,GAAG;gBAChB,IAAI,SAAS,CAAA,CAAE,KAAK,EAAA,KAAO,SAAS,KAAK,KAAK,GAAG;oBAC/C,OAAO,WAAW;gBACpB;gBACA,OAAO,WAAW;YACpB;YACA,OAAO,WAAW;QACpB,KAAK;YACH,OAAO;QACT,KAAK;YACH,IAAI,UAAU,MAAM;gBAClB,OAAO;YACT;YAEA,IAAI,MAAM,OAAA,CAAQ,KAAK,GAAG;gBACxB,IAAI,MAAM,IAAI,WAAW;gBACzB,KAAA,MAAW,WAAW,MAAO;oBAC3B,OAAO,eAAe,OAAO;gBAC/B;gBACA,OAAO;YACT;YAEA;gBACE,MAAM,MAAM;gBACZ,IAAI,MAAc,IAAI,WAAW;gBACjC,IAAA,MAAW,KAAK,IAAK;oBACnB,QAAI,mWAAA,EAAO,KAAK,CAAC,GAAG;wBAIlB,MAAM,gBAAgB,GAAA,CAAI,CAAC,CAAA;wBAC3B,IAAI,kBAAkB,KAAA,GAAW;4BAC/B,OAAO,eAAe,CAAC,IAAI,eAAe,aAAa;wBACzD;oBACF;gBACF;gBACA,OAAO;YACT;IACJ;IAEA,MAAM,IAAI,MAAM,wBAAgD,KAAK,EAA7B,OAAO,KAAK,EAAA,aAAiB,CAAE;AACzE;AAEA,SAAS,MAAM,KAAA,EAAwB;IACrC,OAAO,UAAA,CAAW,QAAQ,CAAA;AAC5B;AAEA,IAAM,aAAa,IAAI,WAAW,aAAa,WAAW;AAEnD,SAAS,eAAqB,GAAA,EAAQ,KAAA,EAAkB;IAE7D,OAAO,aAAa,eAAe,GAAG,IAAI,eAAe,KAAK;AAChE;;;AEvEO,SAAS,aAAa,IAAA,EAAc,OAAA,EAAgC;IACzE,IAAI,MAAM;IACV,MAAO,MAAM,KAAM;QACjB,MAAM,MAAM,MAAA,CAAQ,OAAO,OAAQ,CAAA;QACnC,MAAM,IAAI,QAAQ,GAAG;QACrB,IAAI,MAAM,GAAG;YACX,OAAO;QACT;QACA,IAAI,IAAI,GAAG;YACT,MAAM,MAAM;QACd,OAAO;YACL,OAAO;QACT;IACF;IACA,OAAO;AACT;;AC1BO,UAAU;IAAA,IAAA,IAAA,OAAA,UAAA,QAAA,QAAA,UAAA,OAAA,OAAA,GAAA,OAAA,MAAA;QAAoB,MAApB,QAAA,SAAA,CAAA,KAAoB,EAAsB;;IACzD,KAAA,MAAW,QAAQ,MAAO;QACxB,OAAO;IACT;AACF;AAEA,UAAU,WACR,IAAA,EACA,CAAA,EACa;IACb,IAAI,QAAQ;IACZ,KAAA,MAAW,KAAK,KAAM;QACpB,IAAI,EAAE,GAAG,OAAO,GAAG;YACjB,MAAM;QACR;IACF;AACF;AAEA,UAAU,QACR,IAAA,EACA,CAAA,EACa;IACb,IAAI,QAAQ;IACZ,KAAA,MAAW,KAAK,KAAM;QACpB,MAAM,EAAE,GAAG,OAAO;IACpB;AACF;AASO,UAAU,KAAQ,MAAA,EAAkC;QAMzD;IALA,MAAM,KAAK,MAAA,CAAO,OAAO,QAAQ,CAAA,CAAE;IACnC,MAAM,EAAC,KAAA,CAAK,CAAA,GAAI,GAAG,IAAA,CAAK;IACxB,IAAI,UAAU,KAAA,GAAW;QACvB,MAAM;IACR;KACA,aAAA,GAAG,MAAA,GAAS,WAAZ,iCAAA,gBAAA;AACF;AAKA,IAAM,cAAN,MAAM,aAAsC;IAM1C,CAAC,OAAO,QAAQ,CAAA,GAAI;QAClB,OAAO,IAAA,CAAK,IAAA,CAAK,OAAO,QAAQ,CAAA,CAAE;IACpC;IAEA,IAAO,CAAA,EAA+C;QACpD,OAAO,IAAI,aAAY,QAAQ,IAAA,CAAK,IAAA,EAAM,CAAC,CAAC;IAC9C;IAEA,OAAO,CAAA,EAAqD;QAC1D,OAAO,IAAI,aAAY,WAAW,IAAA,CAAK,IAAA,EAAM,CAAC,CAAC;IACjD;IAdA,YAAY,IAAA,CAAmB;kQAD/B;QAEE,IAAA,CAAK,IAAA,GAAO;IACd;AAaF;AAEO,SAAS,aAAgB,IAAA,EAAmC;IACjE,OAAO,IAAI,YAAY,IAAI;AAC7B;;AFtCO,IAAM,aAAa;AACnB,IAAM,eAAe;AAYrB,SAAS,kBACd,KAAA,EACA,OAAA,EACA,aAAA,EACa;IACb,WAAO,uWAAA,EAAW;QAChB;QACC,iBAA+B,KAC5B,UACA,QAAQ,GAAA,CAAI,CAAA,IAAK,EAAE,KAAA,CAAM,GAAG,CAAC,CAAC;KACnC;AACH;AAsEA,eAAsB,SACpB,GAAA,EACAC,KAAAA,EACA,MAAA,EACA,gBAAA,EACuB;IACvB,MAAM,OAAO,MAAM,OAAO,OAAA,CAAQA,KAAI;IAEtC,IAAI,qBAAqB,OAAO,QAAA,EAAU;QACxC,OAAO,SAAS,KAAK,OAAO,QAAA,EAAU,QAAQ,OAAO,QAAQ;IAC/D;IACA,IAAI,eAAe,IAAI,GAAG;QACxB,OAAO;IACT;IACA,MAAM,EAAC,OAAA,CAAO,CAAA,GAAI;IAClB,IAAI,IAAIC,cAAa,KAAK,OAAO;IACjC,IAAI,MAAM,QAAQ,MAAA,EAAQ;QACxB;IACF;IACA,MAAM,QAAQ,OAAA,CAAQ,CAAC,CAAA;IACvB,OAAO,SAAS,KAAK,KAAA,CAAM,CAAC,CAAA,EAAG,QAAQ,gBAAgB;AACzD;AAYO,SAASA,cACd,GAAA,EACA,OAAA,EACQ;IACR,OAAO,aAAqB,QAAQ,MAAA,EAAQ,CAAA,QAC1C,6NAAA,EAAY,KAAK,OAAA,CAAQ,CAAC,CAAA,CAAE,CAAC,CAAC;AAElC;AAEO,SAAS,kBACd,CAAA,EACA,OAAA,EACA,GAAA,EACS;IACT,OAAO,MAAM,QAAQ,MAAA,IAAU,OAAA,CAAQ,CAAC,CAAA,CAAE,CAAC,CAAA,KAAM;AACnD;AAEO,SAAS,eACdC,EAAAA,EACA,aAAA,EACAC,eAAAA,EACyB;IACzB,IAAI,mWAAA,IAAwB,iBAA+B,IAAI;QAC7D,OAAOD;IACT;IAEA,IAAA,wWAAA,EAAYA,EAAC;IACb,IAAA,6WAAA,EAAiBA,EAAC;IAElB,IAAA,mWAAA,EAAOA,GAAE,MAAA,IAAU,CAAC;IACpB,MAAM,CAAC,OAAO,OAAO,CAAA,GAAIA;IACzB,IAAA,yWAAA,EAAa,KAAK;IAClB,IAAA,wWAAA,EAAY,OAAO;IAEnB,MAAM,IAAI,QAAQ,IAAI,yWAAA,GAAe;IAGrC,IAAI,iBAA+B,IAAI;QACrC,KAAA,MAAW,KAAK,QAAS;YACvB,YAAY,GAAG,CAAC;QAClB;QACA,OAAOA;IACT;IAEA,MAAM,aAAa,QAAQ,GAAA,CAAI,CAAA,IAAK,kBAAkB,GAAG,GAAGC,eAAc,CAAC;IAC3E,OAAO;QAAC;QAAO,UAAU;KAAA;AAC3B;AAEA,SAAS,YACP,KAAA,EACA,CAAA,EAG0C;IAC1C,IAAA,wWAAA,EAAY,KAAK;IAEjB,IAAA,mWAAA,EAAO,MAAM,MAAA,IAAU,CAAC;IACxB,IAAA,yWAAA,EAAa,KAAA,CAAM,CAAC,CAAC;IACrB,EAAE,KAAA,CAAM,CAAC,CAAC;IACV,IAAA,yWAAA,EAAa,KAAA,CAAM,CAAC,CAAC;AACvB;AAMA,SAAS,kBACP,KAAA,EACA,CAAA,EAGAA,eAAAA,EACyB;IACzB,IAAA,wWAAA,EAAY,KAAK;IACjB,IAAA,mWAAA,EAAO,MAAM,MAAA,IAAU,CAAC;IACxB,IAAA,yWAAA,EAAa,KAAA,CAAM,CAAC,CAAC;IACrB,EAAE,KAAA,CAAM,CAAC,CAAC;IACV,MAAM,YAAYA,gBAAe,KAAA,CAAM,CAAC,CAAA,EAAG,KAAA,CAAM,CAAC,CAAC;IACnD,OAAO;QAAC,KAAA,CAAM,CAAC,CAAA;QAAG,KAAA,CAAM,CAAC,CAAA;QAAG,SAAS;KAAA;AACvC;AAMA,IAAe,0DAAf,MAA+B;IA0B7B,SAAiB;QACf,OAAO,IAAA,CAAK,OAAA,CAAQ,IAAA,CAAK,OAAA,CAAQ,MAAA,GAAS,CAAC,CAAA,CAAE,CAAC,CAAA;IAChD;IAEA,iBAAiB,IAAA,EAAyB;QACxC,mPAAI,IAAA,EAAK,oBAAmB,CAAA,GAAI;YAC9B,sPAAO,IAAA,EAAK;QACd;QAEA,IAAI,MAAM,KAAK,eAAA;QACf,KAAA,MAAW,SAAS,IAAA,CAAK,OAAA,CAAS;YAChC,OAAO,KAAA,CAAM,CAAC,CAAA;QAChB;QACA,OAAQ,qPAAK,gBAAiB;IAChC;IAEU,YAAY,IAAA,EAAkB;6PACjC,gBAAiB,CAAA;QACtB,KAAK,UAAA,CACH,IAAA;IAEJ;IAvCA,YAAY,OAAA,EAA8BC,KAAAA,EAAY,SAAA,CAAoB;QAP1E;kQACA;uQAES;;;mBAEQ,CAAA;;QAGf,IAAA,CAAK,OAAA,GAAU;QACf,IAAA,CAAK,IAAA,GAAOA;QACZ,IAAA,CAAK,SAAA,GAAY;IACnB;AAoCF;AAEO,SAAS,YACd,IAAA,EACA,aAAA,EACa;IACb,OAAO,kBAAkB,KAAK,KAAA,EAAO,KAAK,OAAA,EAAS,aAAa;AAClE;AAEO,IAAM,gEAAN,cAA2B,SAA0B;IAG1D,IACE,GAAA,EACA,KAAA,EACA,SAAA,EACA,IAAA,EACuB;QACvB,IAAI;QACJ,MAAM,IAAIC,cAAa,KAAK,IAAA,CAAK,OAAO;QACxC,IAAI,CAAC,kBAAkB,GAAG,IAAA,CAAK,OAAA,EAAS,GAAG,GAAG;YAE5C,cAAc;QAChB,OAAO;YACL,cAAc;QAChB;QAEA,OAAO,QAAQ,OAAA,qPACb,WAAK,aAAL,IAAA,EAAa,MAAM,GAAG,aAAa;YAAC;YAAK;YAAO,SAAS;SAAC;IAE9D;IAkBA,IAAI,GAAA,EAAa,IAAA,EAAyC;QACxD,MAAM,IAAIA,cAAa,KAAK,IAAA,CAAK,OAAO;QACxC,IAAI,CAAC,kBAAkB,GAAG,IAAA,CAAK,OAAA,EAAS,GAAG,GAAG;YAE5C,OAAO,QAAQ,OAAA,CAAQ,IAAI;QAC7B;QAGA,OAAO,QAAQ,OAAA,qPAAQ,WAAK,aAAL,IAAA,EAAa,MAAM,GAAG,CAAC,CAAC;IACjD;IAEA,OAAO,KAAK,KAAA,EAAgD;QAC1D,KAAA,MAAW,SAAS,IAAA,CAAK,OAAA,CAAS;YAChC,MAAM,KAAA,CAAM,CAAC,CAAA;QACf;IACF;IAEA,OAAO,YACL,KAAA,EAC8C;QAC9C,KAAA,MAAW,SAAS,IAAA,CAAK,OAAA,CAAS;YAChC,MAAM;QACR;IACF;;sgBA7DS,SAAQ;;AA8DnB;AAEA,SAAS,eACPC,MAAAA,EACA,KAAA,EACA,WAAA;IAAA,IAAA,IAAA,OAAA,UAAA,QACG,AADH,QAAA,UAAA,OAAA,IAAA,OAAA,QAAA,OAAA,GAAA,OAAA,MAAA;cAAA,OAAA,KAAA,SAAA,CAAA,KACG,EACE;;IACL,MAAM,MAAMA,OAAM,KAAA,CAAM,GAAG,KAAK;IAChC,IAAA,IAAS,IAAI,GAAG,IAAI,MAAM,MAAA,EAAQ,IAAK;QACrC,IAAI,IAAA,CAAK,KAAA,CAAM,CAAC,CAAC;IACnB;IACA,IAAA,IAAS,IAAI,QAAQ,aAAa,IAAIA,OAAM,MAAA,EAAQ,IAAK;QACvD,IAAI,IAAA,CAAKA,MAAAA,CAAM,CAAC,CAAC;IACnB;IACA,OAAO;AACT;AAEO,IAAM,wIAAN,MAAM,0BAAyB,SAAe;IAanD,MAAM,IACJ,GAAA,EACA,KAAA,EACA,SAAA,EACA,IAAA,EAC2B;QAC3B,IAAI,IAAID,cAAa,KAAK,IAAA,CAAK,OAAO;QACtC,IAAI,MAAM,IAAA,CAAK,OAAA,CAAQ,MAAA,EAAQ;YAE7B;QACF;QAEA,MAAM,YAAY,IAAA,CAAK,OAAA,CAAQ,CAAC,CAAA,CAAE,CAAC,CAAA;QACnC,MAAM,eAAe,MAAM,KAAK,OAAA,CAAQ,SAAS;QAEjD,MAAM,YAAY,MAAM,aAAa,GAAA,CAAI,KAAK,OAAO,WAAW,IAAI;QAEpE,MAAM,gBAAgB,UAAU,gBAAA,CAAiB,IAAI;QACrD,IAAI,gBAAgB,KAAK,OAAA,IAAW,gBAAgB,KAAK,OAAA,EAAS;YAChE,2PAAO,sBAAK,wBAAL,IAAA,EAAwB,MAAM,GAAG,SAAS;QACnD;QAEA,MAAM,WAAW,8BACf,WACA,KAAK,YAAA;QAEP,2PAAO,iBAAK,mBAAL,IAAA,EAAmB,MAAM,GAAG,QAAQ;IAC7C;IA4FA,MAAM,IACJ,GAAA,EACA,IAAA,EAC0C;QAC1C,MAAM,IAAIA,cAAa,KAAK,IAAA,CAAK,OAAO;QACxC,IAAI,MAAM,IAAA,CAAK,OAAA,CAAQ,MAAA,EAAQ;YAE7B,OAAO,IAAA;QACT;QAEA,MAAM,YAAY,IAAA,CAAK,OAAA,CAAQ,CAAC,CAAA,CAAE,CAAC,CAAA;QACnC,MAAM,eAAe,MAAM,KAAK,OAAA,CAAQ,SAAS;QACjD,MAAM,UAAU,aAAa,IAAA;QAE7B,MAAM,YAAY,MAAM,aAAa,GAAA,CAAI,KAAK,IAAI;QAClD,IAAI,UAAU,IAAA,KAAS,SAAS;YAE9B,OAAO,IAAA;QACT;QAEA,IAAI,UAAU,OAAA,CAAQ,MAAA,KAAW,GAAG;YAElC,MAAM,UAAU,eAAe,IAAA,CAAK,OAAA,EAAS,GAAG,CAAC;YACjD,OAAO,KAAK,mBAAA,CAAoB,SAAS,IAAA,CAAK,KAAK;QACrD;QAEA,IAAI,MAAM,KAAK,IAAA,CAAK,OAAA,CAAQ,MAAA,KAAW,GAAG;YAGxC,OAAO;QACT;QAGA,IAAI,UAAU,gBAAA,CAAiB,IAAI,IAAI,KAAK,OAAA,EAAS;YAEnD,MAAM,QAAQ,8BAA8B,WAAW,KAAK,YAAY;YACxE,2PAAO,iBAAK,mBAAL,IAAA,EAAmB,MAAM,GAAG,KAAK;QAC1C;QAGA,2PAAO,sBAAK,wBAAL,IAAA,EAAwB,MAAM,GAAG,SAAS;IACnD;IAEA,OAAO,KAAK,IAAA,EAA+C;QACzD,KAAA,MAAW,SAAS,IAAA,CAAK,OAAA,CAAS;YAChC,MAAM,YAAY,MAAM,KAAK,OAAA,CAAQ,KAAA,CAAM,CAAC,CAAC;YAC7C,OAAO,UAAU,IAAA,CAAK,IAAI;QAC5B;IACF;IAEA,OAAO,YACL,IAAA,EAC8C;QAC9C,KAAA,MAAW,SAAS,IAAA,CAAK,OAAA,CAAS;YAChC,MAAM,YAAY,MAAM,KAAK,OAAA,CAAQ,KAAA,CAAM,CAAC,CAAC;YAC7C,OAAO,UAAU,WAAA,CAAY,IAAI;QACnC;IACF;IAEA,YACE,KAAA,EACA,MAAA,EACA,IAAA,EACiD;QACjD,MAAM,KAAiD,CAAC,CAAA;QACxD,IAAA,IAAS,IAAI,OAAO,IAAI,UAAU,IAAI,IAAA,CAAK,OAAA,CAAQ,MAAA,EAAQ,IAAK;YAC9D,GAAG,IAAA,CAAK,KAAK,OAAA,CAAQ,IAAA,CAAK,OAAA,CAAQ,CAAC,CAAA,CAAE,CAAC,CAAC,CAAC;QAC1C;QACA,OAAO,QAAQ,GAAA,CAAI,EAAE;IACvB;IAEA,MAAM,qBACJ,KAAA,EACA,MAAA,EACA,IAAA,EAC0C;QAC1C,MAAM,EAAC,KAAA,CAAK,CAAA,GAAI,IAAA;QAEhB,IAAI,WAAW,GAAG;YAChB,OAAO,IAAI,kBAAiB,CAAC,CAAA,EAAG,cAAc,GAAG,QAAQ,GAAG,IAAI;QAClE;QAEA,MAAM,SAAS,MAAM,IAAA,CAAK,WAAA,CAAY,OAAO,QAAQ,QAAQ,IAAI;QAEjE,IAAI,QAAQ,GAAG;YACb,MAAME,WAAyB,CAAC,CAAA;YAChC,KAAA,MAAW,SAAS,OAA8B;gBAChDA,SAAQ,IAAA,CAAK,GAAG,MAAM,OAAO;YAC/B;YACA,OAAO,IAAI,kBAAiBA,UAAS,cAAc,GAAG,QAAQ,GAAG,IAAI;QACvE;QAEA,IAAA,mWAAA,EAAO,UAAU,CAAC;QAClB,MAAM,UAAoC,CAAC,CAAA;QAC3C,KAAA,MAAW,SAAS,OAA0B;YAC5C,QAAQ,IAAA,CAAK,GAAG,MAAM,OAAO;QAC/B;QACA,OAAO,IAAI,aAAa,SAAS,cAAc,GAAG,IAAI;IACxD;IAnOA,YACE,OAAA,EACAH,KAAAA,EACA,KAAA,EACA,SAAA,CACA;QACA,KAAA,CAAM,SAASA,OAAM,SAAS,GA+BhC;;;GAAA,GAMA,uPAAM,qBAwEN,kgBArHS;QASP,IAAA,CAAK,KAAA,GAAQ;IACf;AA4NF;AAoBO,SAAS,YACd,OAAA,EACAA,KAAAA,EACA,KAAA,EACA,SAAA,EACiC;IACjC,IAAI,UAAU,GAAG;QACf,OAAO,IAAI,aACT,SACAA,OACA;IAEJ;IACA,OAAO,IAAI,iBAAiB,SAA0BA,OAAM,OAAO,SAAS;AAC9E;AAEO,SAAS,eACd,IAAA,EACsB;IACtB,OAAO,KAAK,KAAA,KAAU;AACxB;AAEO,SAAS,UACd,MAAA,EAEAI,eAAAA,EACA,GAAA,EACA,GAAA,EACO;IACP,MAAM,aAAoB,CAAC,CAAA;IAC3B,MAAM,QAAkB,CAAC,CAAA;IACzB,IAAI,MAAM;IACV,IAAI,QAAa,CAAC,CAAA;IAClB,KAAA,MAAW,SAAS,OAAQ;QAC1B,MAAM,OAAOA,gBAAe,KAAK;QACjC,IAAI,QAAQ,KAAK;YACf,IAAI,MAAM,MAAA,GAAS,GAAG;gBACpB,WAAW,IAAA,CAAK,KAAK;gBACrB,MAAM,IAAA,CAAK,GAAG;YAChB;YACA,WAAW,IAAA,CAAK;gBAAC,KAAK;aAAC;YACvB,MAAM,IAAA,CAAK,IAAI;YACf,MAAM;YACN,QAAQ,CAAC,CAAA;QACX,OAAA,IAAW,MAAM,QAAQ,KAAK;YAC5B,MAAM,IAAA,CAAK,KAAK;YAChB,WAAW,IAAA,CAAK,KAAK;YACrB,MAAM,IAAA,CAAK,MAAM,IAAI;YACrB,MAAM;YACN,QAAQ,CAAC,CAAA;QACX,OAAO;YACL,OAAO;YACP,MAAM,IAAA,CAAK,KAAK;QAClB;IACF;IAEA,IAAI,MAAM,GAAG;QACX,IAAI,MAAM,MAAA,GAAS,KAAK,MAAM,KAAA,CAAM,MAAM,MAAA,GAAS,CAAC,CAAA,IAAK,KAAK;YAC5D,UAAA,CAAW,WAAW,MAAA,GAAS,CAAC,CAAA,CAAE,IAAA,CAAK,GAAG,KAAK;QACjD,OAAO;YACL,WAAW,IAAA,CAAK,KAAK;QACvB;IACF;IAEA,OAAO;AACT;AAEO,IAAM,gBAAgB,kBAC3B,GACA,CAAC,CAAA,EACa;AAET,IAAM,oBAAoB,IAAI,aAAa,CAAC,CAAA,EAAG,WAAW,KAAK;AAE/D,SAAS,8BACd,IAAA,EACAA,eAAAA,EACwB;IACxB,MAAM,MAAM,KAAK,MAAA,CAAO;IACxB,MAAM,QAAQ,KAAK,IAAA;IACnB,MAAM,OAAOA,gBAAe,KAAK,KAAK;IACtC,OAAO;QAAC;QAAK;QAAO,IAAI;KAAA;AAC1B;;AGvsBA,IAAM,oBAAoB,CAAA;AACnB,IAAM,YAAY;AAClB,IAAM,iBAAiB;AACvB,IAAM,eAAe;AACrB,IAAM,cAAc;AAE3B,IAAM,MAAM;AACZ,IAAM,QAAQ;AAIP,UAAU,eACf,QAAA,EACA,OAAA,EACyB;IACzB,IAAI,gBAAgB;IACpB,IAAI,eAAe;IACnB,IAAI;IAEJ,SAAS,eAAeC,OAAAA,EAAgB,KAAA,EAAqB;QAC3D,IAAIA,OAAAA,CAAO,WAAW,CAAA,KAAM,mBAAmB;YAC7CA,OAAAA,CAAO,WAAW,CAAA,GAAI;QACxB;IACF;IAEA,SAAS,YAAoB;QAC3B,OAAO;YAAC;YAAe;YAAG;YAAG,iBAAiB;SAAA;IAChD;IAEA,MAAO,gBAAgB,SAAS,MAAA,IAAU,eAAe,QAAQ,MAAA,CAAQ;QACvE,IAAI,QAAA,CAAS,aAAa,CAAA,CAAE,GAAG,CAAA,KAAM,OAAA,CAAQ,YAAY,CAAA,CAAE,GAAG,CAAA,EAAG;YAC/D,IACE,UAAA,wCAAA;YAEE,QAAA,CAAS,aAAa,CAAA,CAAE,KAAK,CAAA,EAC7B,OAAA,CAAQ,YAAY,CAAA,CAAE,KAAK,CAAA,GAE7B;gBACA,IAAI,QAAQ;oBACV,eAAe,QAAQ,CAAC;oBACxB,MAAM;oBACN,SAAS,KAAA;gBACX;YACF,OAAO;gBACL,IAAI,CAAC,QAAQ;oBACX,SAAS,UAAU;gBACrB;gBACA,MAAA,CAAO,YAAY,CAAA;gBACnB,MAAA,CAAO,cAAc,CAAA;gBACrB,eAAe,QAAQ,YAAY;YACrC;YACA;YACA;QACF,OAAA,IAAW,QAAA,CAAS,aAAa,CAAA,CAAE,GAAG,CAAA,GAAI,OAAA,CAAQ,YAAY,CAAA,CAAE,GAAG,CAAA,EAAG;YAEpE,IAAI,CAAC,QAAQ;gBACX,SAAS,UAAU;YACrB;YACA,MAAA,CAAO,cAAc,CAAA;YAErB;QACF,OAAO;YAEL,IAAI,CAAC,QAAQ;gBACX,SAAS,UAAU;YACrB;YACA,MAAA,CAAO,YAAY,CAAA;YACnB,eAAe,QAAQ,YAAY;YAEnC;QACF;IACF;IAEA,IAAI,eAAe,QAAQ,MAAA,EAAQ;QACjC,IAAI,CAAC,QAAQ;YACX,SAAS,UAAU;QACrB;QACA,MAAA,CAAO,YAAY,CAAA,IAAK,QAAQ,MAAA,GAAS;QACzC,eAAe,QAAQ,YAAY;IACrC;IAEA,IAAI,gBAAgB,SAAS,MAAA,EAAQ;QACnC,IAAI,CAAC,QAAQ;YACX,SAAS,UAAU;QACrB;QACA,MAAA,CAAO,cAAc,CAAA,IAAK,SAAS,MAAA,GAAS;IAC9C;IAEA,IAAI,QAAQ;QACV,eAAe,QAAQ,CAAC;QACxB,MAAM;IACR;AACF;;ACzDO,IAAM,mBAAmB;AAEzB,IAAM,YAAN,MAAiE;IAwBtE,MAAM,QAAQC,KAAAA,EAAsD;QAClE,IAAIA,UAAS,WAAW;YACtB,OAAO;QACT;QAEA,MAAM,SAAS,IAAA,CAAK,MAAA,CAAO,GAAA,CAAIA,KAAI;QACnC,IAAI,QAAQ;YACV,OAAO;QACT;QAEA,MAAM,QAAQ,MAAM,IAAA,CAAK,QAAA,CAAS,YAAA,CAAaA,KAAI;QACnD,MAAM,OAAO,eACX,MAAM,IAAA,EACN,IAAA,CAAK,cAAA,EACL,IAAA,CAAK,YAAA;QAEP,MAAM,OAAO,YACX,IAAA,CAAK,YAAY,CAAA,EACjBA,OACA,IAAA,CAAK,UAAU,CAAA,EACf;QAEF,IAAA,CAAK,MAAA,CAAO,GAAA,CAAIA,OAAM,IAAI;QAC1B,OAAO;IACT;IAEA,MAAM,IAAI,GAAA,EAAmD;QAC3D,MAAM,OAAO,MAAM,SAAS,KAAK,IAAA,CAAK,QAAA,EAAU,IAAA,EAAM,IAAA,CAAK,QAAQ;QACnE,MAAM,QAAQC,cAAa,KAAK,KAAK,OAAO;QAC5C,IAAI,CAAC,kBAAkB,OAAO,KAAK,OAAA,EAAS,GAAG,GAAG;YAChD,OAAO,KAAA;QACT;QACA,OAAO,KAAK,OAAA,CAAQ,KAAK,CAAA,CAAE,CAAC,CAAA;IAC9B;IAEA,MAAM,IAAI,GAAA,EAA+B;QACvC,MAAM,OAAO,MAAM,SAAS,KAAK,IAAA,CAAK,QAAA,EAAU,IAAA,EAAM,IAAA,CAAK,QAAQ;QACnE,MAAM,QAAQA,cAAa,KAAK,KAAK,OAAO;QAC5C,OAAO,kBAAkB,OAAO,KAAK,OAAA,EAAS,GAAG;IACnD;IAEA,MAAM,UAA4B;QAChC,MAAM,EAAC,QAAA,CAAQ,CAAA,GAAI,IAAA;QACnB,MAAM,OAAO,MAAM,IAAA,CAAK,OAAA,CAAQ,IAAA,CAAK,QAAQ;QAE7C,IAAI,IAAA,CAAK,QAAA,KAAa,UAAU;YAC9B,OAAO,IAAA,CAAK,OAAA,CAAQ;QACtB;QACA,OAAO,KAAK,OAAA,CAAQ,MAAA,KAAW;IACjC;IAAA,uEAAA;IAAA,wEAAA;IAAA,0EAAA;IAAA,4EAAA;IAMA,KAAK,OAAA,EAAgE;QACnE,OAAO,YACL,IAAA,CAAK,QAAA,EACL,IAAM,IAAA,CAAK,QAAA,EACX,IAAA,CAAK,QAAA,EACL,SACA,OAAMD,UAAQ;YACZ,MAAM,SAAS,MAAM,IAAA,CAAK,OAAA,CAAQA,KAAI;YACtC,IAAI,QAAQ;gBACV,OAAO;oBACL,OAAO,KAAA;oBACP,OAAO,SAAA,GAAY,OAAO,OAAA,CAAQ,KAAA,CAAM,IAAI,OAAO,OAAA;iBACrD;YACF;YACA,MAAM,QAAQ,MAAM,IAAA,CAAK,QAAA,CAAS,YAAA,CAAaA,KAAI;YACnD,OAAO,eACL,MAAM,IAAA,EACN,IAAA,CAAK,cAAA,EACL,IAAA,CAAK,YAAA;QAET;IAEJ;IAEA,OAAO,OAAsC;QAC3C,MAAM,OAAO,MAAM,IAAA,CAAK,OAAA,CAAQ,IAAA,CAAK,QAAQ;QAC7C,OAAO,KAAK,IAAA,CAAK,IAAI;IACvB;IAEA,OAAO,UAAyD;QAC9D,MAAM,OAAO,MAAM,IAAA,CAAK,OAAA,CAAQ,IAAA,CAAK,QAAQ;QAC7C,OAAO,KAAK,WAAA,CAAY,IAAI;IAC9B;IAEA,CAAC,OAAO,aAAa,CAAA,GAAmD;QACtE,OAAO,IAAA,CAAK,OAAA,CAAQ;IACtB;IAEA,OAAO,KAAK,IAAA,EAA+D;QACzE,MAAM,CAAC,aAAa,QAAQ,CAAA,GAAI,MAAM,QAAQ,GAAA,CAAI;YAChD,IAAA,CAAK,OAAA,CAAQ,IAAA,CAAK,QAAQ;YAC1B,KAAK,OAAA,CAAQ,KAAK,QAAQ;SAC3B;QACD,OAAO,UAAU,UAAU,aAAa,MAAM,IAAI;IACpD;IAjHA,YACE,OAAA,EACA,aAAA,EACA,OAAa,SAAA,EACb,eAA6C,cAAA,EAC7C,kBAAkB,gBAAA,CAClB;qPAfiB,UACjB,aAAA,GAAA,IAAI,IAAI;sQAES;4QACA;sQACnB;0QACS;6QACA;QASP,IAAA,CAAK,QAAA,GAAW;QAChB,IAAA,CAAK,cAAA,GAAiB;QACtB,IAAA,CAAK,QAAA,GAAW;QAChB,IAAA,CAAK,YAAA,GAAe;QACpB,IAAA,CAAK,eAAA,GAAkB;IACzB;AAsGF;AAEA,gBAAgB,UACd,IAAA,EACA,OAAA,EACA,QAAA,EACA,WAAA,EAC8C;IAC9C,IAAI,KAAK,KAAA,GAAQ,QAAQ,KAAA,EAAO;QAG9B,MAAM,YAAa,MAAO,KAA0B,oBAAA,CAClD,GACA,KAAK,OAAA,CAAQ,MAAA,EACb;QAEF,OAAO,UAAU,WAAW,SAAS,UAAU,WAAW;QAC1D;IACF;IAEA,IAAI,QAAQ,KAAA,GAAQ,KAAK,KAAA,EAAO;QAE9B,MAAM,eAAgB,MACpB,QACA,oBAAA,CACA,GACA,QAAQ,OAAA,CAAQ,MAAA,EAChB;QAEF,OAAO,UAAU,MAAM,cAAc,UAAU,WAAW;QAC1D;IACF;IAEA,IAAI,eAAe,IAAI,KAAK,eAAe,OAAO,GAAG;QACnD,OAAO,YACJ,KAAsB,OAAA,EACtB,QAAyB,OAAA;QAE5B;IACF;IAKA,MAAM,iBAAiB,eACpB,KAA0B,OAAA,EAC1B,QAA6B,OAAA;IAEhC,KAAA,MAAW,UAAU,eAAgB;QACnC,MAAM,CAAC,WAAW,YAAY,CAAA,GAAI,MAAM,QAAQ,GAAA,CAAI;YACjD,KAA0B,oBAAA,CACzB,MAAA,CAAO,SAAS,CAAA,EAChB,MAAA,CAAO,cAAc,CAAA,EACrB;YAED,QAA6B,oBAAA,CAC5B,MAAA,CAAO,WAAW,CAAA,EAClB,MAAA,CAAO,YAAY,CAAA,EACnB;SAEH;QACD,OAAO,UAAU,WAAW,cAAc,UAAU,WAAW;IACjE;AACF;AAEA,UAAU,YACR,WAAA,EACA,cAAA,EACyC;IACzC,MAAM,aAAa,YAAY,MAAA;IAC/B,MAAM,gBAAgB,eAAe,MAAA;IACrC,IAAI,IAAI;IACR,IAAI,IAAI;IACR,MAAO,IAAI,cAAc,IAAI,cAAe;QAC1C,MAAM,UAAU,WAAA,CAAY,CAAC,CAAA,CAAE,CAAC,CAAA;QAChC,MAAM,aAAa,cAAA,CAAe,CAAC,CAAA,CAAE,CAAC,CAAA;QACtC,IAAI,YAAY,YAAY;YAC1B,IAAI,CAAC,UAAU,WAAA,CAAY,CAAC,CAAA,CAAE,CAAC,CAAA,EAAG,cAAA,CAAe,CAAC,CAAA,CAAE,CAAC,CAAC,GAAG;gBACvD,MAAM;oBACJ,IAAI;oBACJ,KAAK;oBACL,UAAU,WAAA,CAAY,CAAC,CAAA,CAAE,CAAC,CAAA;oBAC1B,UAAU,cAAA,CAAe,CAAC,CAAA,CAAE,CAAC,CAAA;gBAC/B;YACF;YACA;YACA;QACF,OAAA,IAAW,UAAU,YAAY;YAC/B,MAAM;gBACJ,IAAI;gBACJ,KAAK;gBACL,UAAU,WAAA,CAAY,CAAC,CAAA,CAAE,CAAC,CAAA;YAC5B;YACA;QACF,OAAO;YACL,MAAM;gBACJ,IAAI;gBACJ,KAAK;gBACL,UAAU,cAAA,CAAe,CAAC,CAAA,CAAE,CAAC,CAAA;YAC/B;YACA;QACF;IACF;IACA,MAAO,IAAI,YAAY,IAAK;QAC1B,MAAM;YACJ,IAAI;YACJ,KAAK,WAAA,CAAY,CAAC,CAAA,CAAE,CAAC,CAAA;YACrB,UAAU,WAAA,CAAY,CAAC,CAAA,CAAE,CAAC,CAAA;QAC5B;IACF;IACA,MAAO,IAAI,eAAe,IAAK;QAC7B,MAAM;YACJ,IAAI;YACJ,KAAK,cAAA,CAAe,CAAC,CAAA,CAAE,CAAC,CAAA;YACxB,UAAU,cAAA,CAAe,CAAC,CAAA,CAAE,CAAC,CAAA;QAC/B;IACF;AACF;AAUA,gBAAgB,YACd,gBAAA,EACA,WAAA,EACAA,KAAAA,EACA,OAAA,EACA,QAAA,EAC+C;IAC/C,IAAIA,UAAS,WAAW;QACtB;IACF;IAEA,MAAM,OAAO,MAAM,SAASA,KAAI;IAChC,MAAM,UAAU,IAAA,CAAK,YAAY,CAAA;IACjC,IAAI,IAAI;IACR,IAAI,SAAS;QACX,IAAIC,cAAa,SAAS,OAAO;IACnC;IACA,IAAI,IAAA,CAAK,UAAU,CAAA,GAAI,GAAG;QACxB,MAAO,IAAI,QAAQ,MAAA,EAAQ,IAAK;YAC9B,OAAO,YACL,kBACA,aACC,OAAA,CAAQ,CAAC,CAAA,CAAkB,CAAC,CAAA,EAC7B,SACA;YAEF,UAAU;QACZ;IACF,OAAO;QACL,MAAO,IAAI,QAAQ,MAAA,EAAQ,IAAK;YAC9B,MAAM,WAAW,YAAY;YAE7B,IAAI,qBAAqB,UAAU;gBACjC,OAAO,YACL,UACA,aACA,UACA,OAAA,CAAQ,CAAC,CAAA,CAAE,CAAC,CAAA,EACZ;gBAEF;YACF;YACA,MAAM,OAAA,CAAQ,CAAC,CAAA;QACjB;IACF;AACF;AAEA,eAAsB,iBACpB,GAAA,EACA,EAAA,EACuB;IACvB,MAAMC,QAAgC,CAAC,CAAA;IACvC,MAAM,OACJ,OAAO,QACH,CAAA,QAAA,CAAU;YACR,IAAI;YACJ,KAAK,KAAA,CAAM,CAAC,CAAA;YACZ,UAAU,KAAA,CAAM,CAAC,CAAA;QACnB,CAAA,IACA,CAAA,QAAA,CAAU;YACR,IAAI;YACJ,KAAK,KAAA,CAAM,CAAC,CAAA;YACZ,UAAU,KAAA,CAAM,CAAC,CAAA;QACnB,CAAA;IAEN,WAAA,MAAiB,SAAS,IAAI,OAAA,CAAQ,EAAG;QACvCA,MAAK,IAAA,CAAK,KAAK,KAAK,CAAC;IACvB;IACA,OAAOA;AACT;;ACzWO,SAAS,cAAc,CAAA,EAAW,CAAA,EAAmB;IAC1D,IAAI,MAAM,GAAG;QACX,OAAO;IACT;IACA,IAAI,IAAI,GAAG;QACT,OAAO,CAAA;IACT;IACA,OAAO;AACT;;AC6BO,SAAS,eAAe,CAAA,EAAW,CAAA,EAAmB;IAC3D,IAAI,MAAM,GAAG;QACX,OAAO;IACT;IACA,IAAI,MAAM,MAAM;QACd,OAAO,CAAA;IACT;IACA,IAAI,MAAM,MAAM;QACd,OAAO;IACT;IAEA,MAAM,MAAM,gBAAgB,CAAC;IAC7B,MAAM,MAAM,gBAAgB,CAAC;IAG7B,IAAI,OAAO,QAAQ,YAAY,OAAO,QAAQ,UAAU;QACtD,OAAO,cAAc,OAAO,GAAG,GAAG,OAAO,GAAG,CAAC;IAC/C;IAEA,OAAO,MAAM;AACf;AAIA,SAAS,gBAAgB,MAAA,EAA0C;IACjE,IAAI,OAAO,WAAW,YAAY,OAAO,WAAW,UAAU;QAC5D,OAAO;IACT;IACA,OAAO,OAAO,KAAA;AAChB;AAEO,SAAS,aAAaC,EAAAA,EAAiC;IAC5D,IAAIA,OAAM,QAAQ,OAAOA,OAAM,YAAY,OAAOA,OAAM,UAAU;QAChE;IACF;IAEA,iBAAiBA,EAAC;IAClB,IAAI,OAAOA,GAAE,KAAA,KAAU,YAAY,OAAOA,GAAE,KAAA,KAAU,UAAU;QAC9D;IACF;IAEA,MAAM,IAAI,MAAM,gBAAgB;AAClC;;ACzEO,IAAM,YAAY;AAClB,IAAM,eAAe;;ACkBrB,IAAM,oBAAoB;AAE1B,SAAS,kBACd,MAAA,EACiC;IACjC,OAAO,gBAAgB,OAAO,IAAI;AACpC;AAEO,SAAS,cACd,MAAA,EACiC;IACjC,OAAO,kBAAkB,MAAM;AACjC;AAEO,SAAS,iBACd,MAAA,EACoC;IACpC,OAAO,mBAAmB,OAAO,IAAI;AACvC;AAEO,IAAM,SAAN,MAA6B;IAOlC,IAAI,OAAU;QACZ,OAAO,IAAA,CAAK,KAAA,CAAM,IAAA,CAAK,IAAA;IACzB;IAEA,IAAI,YAAkB;QAEpB,OAAO,IAAA,CAAK,KAAA,CAAM,IAAA,CAAK,SAAA;IACzB;IAEA,cAAc,QAAA,EAAoB,OAAA,EAAwC;QACxE,OAAO,cAAc,UAAU,SAAS,IAAA,CAAK,IAAI;IACnD;IAEA,MAAM,kBACJ,QAAA,EACA,OAAA,EACiB;QACjB,OAAQ,MAAM,IAAA,CAAK,aAAA,CAAc,UAAU,OAAO,IAAK;IACzD;IAEA,IAAI,UAAkC;QAEpC,OAAO,IAAA,CAAK,KAAA,CAAM,IAAA,CAAK,OAAA;IACzB;IA3BA,YAAY,KAAA,CAA6B;mQAFhC;QAGP,IAAA,CAAK,KAAA,GAAQ;IACf;AA0BF;AAEA,eAAsB,cACpB,QAAA,EACA,OAAA,EACA,IAAA,EACiB;IACjB,OAAQ,KAAK,IAAA,EAAM;QACjB,KAAc;;YACZ,8CAAY,eAAA,CAAgB,QAAQ,CAAA,0DAA7B,iCAAkC;QAE3C,KAAc;YAAW;gBACvB,IAAI,KAAK,QAAA,KAAa,UAAU;oBAC9B,OAAO,KAAK,UAAA;gBACd;gBACA,MAAM,EAAC,SAAA,CAAS,CAAA,GAAI;gBACpB,MAAM,cAAc,MAAM,eAAe,WAAW,OAAO;gBAC3D,OAAO,cAAc,UAAU,SAAS,YAAY,IAAI;YAC1D;QAEA;YACE,IAAA,wWAAA,EAAY,IAAI;IACpB;AACF;AAYA,eAAsB,eACpB,cAAA,EACA,OAAA,EACkC;IAClC,MAAM,UAAU,MAAM,YAAY,gBAAgB,OAAO;IAEzD,OAAO,QAAQ,MAAA,CAAO,CAAA,IAAK,cAAc,CAAC,CAAC;AAC7C;AAEA,eAAsB,mBACpB,cAAA,EACA,OAAA,EACkC;IAClC,MAAM,UAAU,MAAM,YAAY,gBAAgB,OAAO;IAEzD,OAAO,QAAQ,MAAA,CAAO,CAAA,IAAK,kBAAkB,CAAC,CAAC;AACjD;AAEA,eAAsB,0BACpB,MAAA,EACA,gBAAA,EACA,OAAA,EACkC;IAClC,MAAM,UAAmC,CAAC,CAAA;IAC1C,MAAM,4BAA4B,IAAI,IAAI,OAAO,OAAA,CAAQ,gBAAgB,CAAC;IAC1E,MAAO,CAAC,iBAAiB,MAAM,KAAK,0BAA0B,IAAA,GAAO,EAAG;QACtE,IAAI,kBAAkB,MAAM,GAAG;YAC7B,MAAM,EAAC,IAAA,CAAI,CAAA,GAAI;YACf,MAAM,uBAAuB,0BAA0B,GAAA,CAAI,KAAK,QAAQ;YACxE,IAAI,yBAAyB,KAAA,GAAW;gBACtC,IAAI,KAAK,UAAA,IAAc,sBAAsB;oBAC3C,0BAA0B,MAAA,CAAO,KAAK,QAAQ;gBAChD,OAAO;oBACL,QAAQ,IAAA,CAAK,MAA+B;gBAC9C;YACF;QACF;QACA,MAAM,EAAC,SAAA,CAAS,CAAA,GAAI,OAAO,IAAA;QAC3B,IAAI,cAAc,MAAM;YACtB,MAAM,IAAI,MAAM,UAA2B,OAAjB,OAAO,KAAA,CAAM,IAAI,EAAA,cAAe;QAC5D;QACA,SAAS,MAAM,eAAe,WAAW,OAAO;IAClD;IACA,OAAO;AACT;AAEA,eAAsB,qBACpB,IAAA,EACA,OAAA,EACmC;IACnC,MAAMC,QAAO,MAAM,QAAQ,OAAA,CAAQ,IAAI;IACvC,IAAA,mWAAA,EAAOA,OAAM,gBAAoB,CAAE,MAAN,IAAI;IACjC,OAAO,qBAAqBA,OAAM,OAAO;AAC3C;AAEA,eAAsB,yBACpBA,KAAAA,EACA,OAAA,EACe;IACf,OAAA,CAAQ,MAAM,qBAAqBA,OAAM,OAAO,CAAA,EAAG,KAAA,CAAM,IAAA;AAC3D;AAEA,eAAsB,qBACpBA,KAAAA,EACA,OAAA,EACmC;IACnC,MAAM,SAAS,MAAM,eAAeA,OAAM,OAAO;IACjD,OAAO,uBAAuB,QAAQ,OAAO;AAC/C;AAEA,eAAsB,uBACpB,MAAA,EACA,OAAA,EACmC;IACnC,MAAO,CAAC,iBAAiB,MAAM,EAAG;QAChC,MAAM,EAAC,IAAA,CAAI,CAAA,GAAI;QACf,IAAI,gBAAgB,IAAI,GAAG;YACzB,SAAS,MAAM,eAAe,KAAK,gBAAA,EAAkB,OAAO;QAC9D,OAAO;YACL,MAAM,EAAC,SAAA,CAAS,CAAA,GAAI;YACpB,IAAI,cAAc,MAAM;gBACtB,MAAM,IAAI,MAAM,UAA2B,OAAjB,OAAO,KAAA,CAAM,IAAI,EAAA,cAAe;YAC5D;YACA,SAAS,MAAM,eAAe,WAAW,OAAO;QAClD;IACF;IACA,OAAO;AACT;AAEO,SAAS,kBACd,CAAA,EACA,QAAA,EACkE;IAClE,MAAM,IAAI,EAAE,IAAA;;IACZ,MAAM,sCAAO,EAAE,eAAA,CAAgB,QAAQ,CAAA,qFAAK;IAC5C,OAAO;QAAC;QAAM,EAAE,UAAU;KAAA;AAC5B;AAEO,SAAS,2BACd,CAAA,EACA,CAAA,EACQ;IACR,OAAO,eAAe,EAAE,IAAA,CAAK,UAAA,EAAY,EAAE,IAAA,CAAK,UAAU;AAC5D;AAOA,eAAsB,YACpB,cAAA,EACA,OAAA,EACyB;IACzB,IAAI,SAAS,MAAM,eAAe,gBAAgB,OAAO;IACzD,MAAM,UAAU,CAAC,CAAA;IACjB,MAAO,CAAC,iBAAiB,MAAM,EAAG;QAChC,MAAM,EAAC,IAAA,CAAI,CAAA,GAAI;QACf,MAAM,EAAC,SAAA,CAAS,CAAA,GAAI;QACpB,IAAI,cAAc,MAAM;YACtB,MAAM,IAAI,MAAM,UAA2B,OAAjB,OAAgC,AAAzB,KAAA,CAAM,IAAI,EAAA;QAC7C;QACA,QAAQ,IAAA,CAAK,MAAM;QACnB,SAAS,MAAM,eAAe,WAAW,OAAO;IAClD;IACA,QAAQ,IAAA,CAAK,MAAM;IACnB,OAAO;AACT;AAEA,eAAsB,eACpBA,KAAAA,EACA,OAAA,EACuB;IACvB,MAAM,QAAQ,MAAM,QAAQ,YAAA,CAAaA,KAAI;IAC7C,OAAO,UAAU,KAAK;AACxB;AAEA,eAAsB,eACpB,IAAA,EACA,OAAA,EACuB;IACvB,MAAMA,QAAO,MAAM,gBAAgB,MAAM,OAAO;IAChD,OAAO,eAAeA,OAAM,OAAO;AACrC;AAgBO,SAAS,oBACdC,EAAAA,EAC4B;IAE5B,IAAA,yWAAA,EAAaA,GAAE,QAAQ;IACvB,IAAA,yWAAA,EAAaA,GAAE,UAAU;IACzB,IAAA,yWAAA,EAAaA,GAAE,WAAW;IAC1B,IAAI,CAACA,GAAE,WAAA,EAAa;QAClB,MAAM,IAAI,MAAM,sBAAsB;IACxC;IACA,gBAAgBA,GAAE,eAAe;IACjC,IAAIA,GAAE,YAAA,KAAiB,MAAM;QAC3B,WAAWA,GAAE,YAAY;IAC3B;IACA,IAAA,yWAAA,EAAaA,GAAE,SAAS;AAC1B;AAEO,SAAS,gBAAgB,IAAA,EAAmC;IACjE,OAAO,KAAK,IAAA,KAAkB;AAChC;AAiBO,SAAS,uBACdC,EAAAA,EAC+B;IAE/B,IAAIA,GAAE,SAAA,KAAc,MAAM;QACxB,WAAWA,GAAE,SAAS;IACxB;IACA,gBAAgBA,GAAE,UAAU;IAC5B,sBAAsBA,GAAE,eAAe;AACzC;AAEA,SAAS,sBACPA,EAAAA,EACuC;IACvC,IAAA,yWAAA,EAAaA,EAAC;IACd,KAAA,MAAW,KAAK,OAAO,MAAA,CAAOA,EAAC,EAAG;QAChC,IAAA,yWAAA,EAAa,CAAC;IAChB;AACF;AAIO,SAAS,yBACd,CAAA,EACuC;IACvC,uBAAuB,EAAE,IAAI;AAC/B;AAEA,SAAS,mBAAmB,IAAA,EAAsC;IAChE,OAAO,KAAK,IAAA,KAAkB;AAChC;AAEA,SAAS,WAAWA,EAAAA,EAA+B;IACjD,IAAA,yWAAA,EAAaA,EAAC;IACd,IAAA,6WAAA,EAAiBA,EAAC;IAClB,IAAIA,GAAE,SAAA,KAAc,MAAM;QACxB,IAAA,yWAAA,EAAaA,GAAE,SAAS;IAC1B;IAEA,IAAA,yWAAA,EAAaA,GAAE,IAAI;IACnB,OAAQA,GAAE,IAAA,EAAM;QACd,KAAc;YACZ,oBAAoBA,EAAC;YACrB;QACF,KAAc;YACZ,uBAAuBA,EAAC;YACxB;QACF;YACE,MAAM,IAAI,MAAM,sBAA4B,CAAE,MAARA,GAAE,IAAI;IAChD;AACF;AAeO,SAAS,oCACd,CAAA,EACA,CAAA,EACS;QAGN;IAFH,OACE,EAAE,WAAA,KAAgB,EAAE,WAAA,IAAA,oBACjB,UAAA,yDAAc,KAAA,MAAA,oBAAc,UAAA,yCAAF,gBAAgB,KAAA,KAC7C,EAAE,SAAA,KAAc,EAAE,SAAA;AAEtB;AAEA,SAAS,2BACPA,EAAAA,EACmC;IACnC,IAAA,yWAAA,EAAaA,EAAC;IACd,IAAA,6WAAA,EAAiBA,EAAC;IAClB,IAAA,yWAAA,EAAaA,GAAE,IAAI;IACnB,IAAA,yWAAA,EAAaA,GAAE,SAAS;IACxB,IAAA,yWAAA,EAAaA,GAAE,WAAW;IAC1B,IAAIA,GAAE,UAAA,KAAe,KAAA,GAAW;QAC9B,IAAA,0WAAA,EAAcA,GAAE,UAAU;IAC5B;AACF;AAEO,SAAS,uBACd,IAAA,EACA,eAAA,EACgC;;IAChC,OAAO;QACL;QACA,sDAA2B,MAAA,cAAhB,+DAA0B;QACrC,aAAa,gBAAgB,WAAA;QAC7B,aAAY,8CAAgB,UAAA,qFAAc;IAC5C;AACF;AAOA,SAAS,kBAAkBA,EAAAA,EAAsC;IAC/D,IAAA,yWAAA,EAAaA,EAAC;IACd,IAAA,6WAAA,EAAiBA,EAAC;IAClB,2BAA2BA,GAAE,UAAU;IACvC,IAAA,yWAAA,EAAaA,GAAE,SAAS;AAC1B;AAEA,SAAS,mBAAmBA,EAAAA,EAAwC;IAClE,IAAA,wWAAA,EAAYA,EAAC;IACb,IAAA,6WAAA,EAAiBA,EAAC;IAClB,KAAA,MAAW,MAAMA,GAAG;QAClB,kBAAkB,EAAE;IACtB;AACF;AAEO,SAAS,aACdC,YAAAA,EACA,SAAA,EACA,gBAAA,EACA,UAAA,EACA,WAAA,EACA,eAAA,EACA,YAAA,EACA,SAAA,EACA,OAAA,EACA,SAAA,EACA,QAAA,EACuB;IACvB,MAAM,OAAsB;QAC1B,MAAe;QACf;QACA;QACA;QACA;QACA;QACA;QACA;QACA;IACF;IACA,OAAO,qBACLA,cACA,eAAe,MAAM,WAAW,OAAO;AAE3C;AAEO,SAAS,gBACdA,YAAAA,EACA,SAAA,EACA,eAAA,EACA,UAAA,EACA,SAAA,EACA,OAAA,EAC0B;IAC1B,OAAO,qBACLA,cACA,0BACE,WACA,iBACA,YACA,WACA;AAGN;AAEO,SAAS,0BACd,SAAA,EACA,eAAA,EACA,UAAA,EACA,SAAA,EACA,OAAA,EAC8B;IAC9B,MAAM,OAAyB;QAC7B,MAAe;QACf;QACA;QACA;IACF;IACA,OAAO,eAAe,MAAM,WAAW,OAAO;AAChD;AAEO,SAAS,UAAU,KAAA,EAA4B;IACpD,cAAc,KAAK;IACnB,OAAO,IAAI,OAAO,KAAK;AACzB;AAEA,SAAS,qBACPA,YAAAA,EACA,IAAA,EACW;IACX,OAAO,IAAI,OAAOA,aAAY,MAAM,QAAQ,IAAI,CAAC,CAAC;AACpD;AAEO,SAAS,QAAQ,IAAA,EAA8B;IACpD,MAAM,OAAkB,aAAA,GAAA,IAAI,IAAI;IAChC,KAAK,GAAA,CAAI,KAAK,SAAS;IACvB,MAAM,EAAC,IAAA,CAAI,CAAA,GAAI;IACf,OAAQ,KAAK,IAAA,EAAM;QACjB,KAAc;YACZ,KAAK,SAAA,IAAa,KAAK,GAAA,CAAI,KAAK,SAAS;YAEzC;QACF,KAAc;YAEZ;QACF;YACE,IAAA,wWAAA,EAAY,IAAI;IACpB;IAEA,KAAA,MAAW,SAAS,KAAK,OAAA,CAAS;QAChC,KAAK,GAAA,CAAI,MAAM,SAAS;IAC1B;IAEA,OAAO,OAAO,IAAI;AACpB;AAQO,SAAS,eACd,IAAA,EACA,SAAA,EACA,OAAA,EACe;IACf,OAAO,2WAAA,EAAW;QAChB;QACA;QACA;IACF,CAAC;AACH;AAEO,SAAS,iBAAiBD,EAAAA,EAA2C;IAC1E,IAAI,mWAAA,EAAuB;QACzB;IACF;IAEA,IAAA,yWAAA,EAAaA,EAAC;IACd,IAAA,6WAAA,EAAiBA,EAAC;IAClB,WAAWA,GAAE,IAAI;IACjB,IAAA,yWAAA,EAAaA,GAAE,SAAS;IACxB,mBAAmBA,GAAE,OAAO;AAC9B;AAEA,SAAS,cAAc,KAAA,EAAwD;IAC7E,MAAM,EAAC,IAAA,CAAI,CAAA,GAAI;IACf,iBAAiB,IAAI;IAErB,MAAM,OAAO,aAAA,GAAA,IAAI,IAAI;IACrB,KAAA,MAAW,SAAS,KAAK,OAAA,CAAS;QAChC,MAAM,EAAC,IAAA,CAAI,CAAA,GAAI,MAAM,UAAA;QACrB,IAAI,KAAK,GAAA,CAAI,IAAI,GAAG;YAClB,MAAM,IAAI,MAAM,mBAAuB,CAAE,MAAN,IAAI;QACzC;QACA,KAAK,GAAA,CAAI,IAAI;IACf;AACF;;ACxjBO,IAAM,MAAM;AACZ,IAAM,SAAS;;ACQf,IAAM,YAAN,MAAmC;IAIxC,YAAY,IAAA,EAAmB,GAAA,CAAY;kQAHlC;4PACA;QAGP,IAAA,CAAK,IAAA,GAAO;QACZ,IAAA,CAAK,GAAA,GAAM;IACb;AACF;AAEO,IAAM,aAAN,cAAyB,UAAsB;IAAA,oFAAA;IAAA,iCAAA;IAGpD,QAAuB;QACrB,OAAO,IAAA,CAAK,GAAA,CAAI,KAAA,CAAM;IACxB;IAEA,QAAuB;QACrB,OAAO,IAAA,CAAK,GAAA,CAAI,KAAA,CAAM;IACxB;AACF;AAGA,eAAsB,WACpB,EAAA,EACA,KAAA,EACA,EAAA,EACA,GAAA,EACA,GAAA,EACA,WAAA,EACA,UAAA,EACe;IACf,IAAI;QACF,KAAA,MAAW,SAAS,aAAa,KAAK,KAAK,aAAa,UAAU,EAAG;YACnE,OAAQ,IAAI;gBACV,KAAoB;oBAClB,MAAM,MAAM,GAAA,CAAI,OAAO,GAAG;oBAC1B;gBACF,KAAoB;oBAClB,MAAM,MAAM,GAAA,CAAI,KAAK;oBACrB;YACJ;QACF;IACF,EAAA,OAAS,GAAG;YAIV;SAAA,WAAA,GAAG,IAAA,cAAH,+BAAA,cAAA,IAAU,sBAAsB,KAAK,KAAK,CAAC;IAC7C;AACF;AAGO,SAAS,aACd,OAAA,EACA,KAAA,EACA,WAAA,EACA,UAAA,EACU;IACV,MAAM,SAAS,oBAAoB,OAAO,WAAW;IACrD,IAAI,WAAW,KAAA,GAAW;QACxB,IAAI,YAAY;YACd,OAAO,CAAC,CAAA;QACV;QACA,MAAM,IAAI,MAAM,qBAAgC,CAAE,MAAb,WAAW;IAClD;IAEA,MAAM,SAAS,MAAM,OAAA,CAAQ,MAAM,IAAI,SAAS;QAAC,MAAM;KAAA;IAEvD,MAAM,YAAsB,CAAC,CAAA;IAC7B,KAAA,MAAWE,UAAS,OAAQ;QAC1B,IAAI,OAAOA,WAAU,UAAU;YAC7B,UAAU,IAAA,CAAK,eAAe;gBAACA;gBAAO,OAAO;aAAC,CAAC;QACjD,OAAO;YACL,MAAM,IAAI,MAAM,yBAAyB;QAC3C;IACF;IAEA,OAAO;AACT;AAEO,IAAM,gBAAgB;AACtB,IAAM,gBAAgB;AAkBtB,SAAS,eAAe,QAAA,EAA4B;IACzD,MAAM,YAAY,QAAA,CAAS,CAAC,CAAA;IAC5B,MAAM,UAAU,QAAA,CAAS,CAAC,CAAA;IAE1B,IAAI,UAAU,QAAA,CAAS,IAAQ,GAAG;QAChC,MAAM,IAAI,MAAM,wCAAwC;IAC1D;IACA,OAAO,gBAAgB,YAAY,gBAAgB;AACrD;AA2BO,SAAS,mBACd,SAAA,EACA,OAAA,EACQ;IACR,MAAM,IAAI,eAAe;QAAC;QAAW,WAAW,EAAE;KAAC;IACnD,IAAI,YAAY,KAAA,GAAW;QACzB,OAAO,EAAE,KAAA,CAAM,GAAG,EAAE,MAAA,GAAS,CAAC;IAChC;IACA,OAAO;AACT;AAGO,SAAS,eAAe,eAAA,EAAmC;IAChE,IAAI,eAAA,CAAgB,CAAC,CAAA,KAAM,eAAe;QACxC,MAAM,IAAI,MAAM,iBAAiB;IACnC;IAEA,MAAM,aAAa,cAAc,MAAA;IACjC,MAAM,eAAe,cAAc,MAAA;IACnC,MAAM,kBAAkB,gBAAgB,OAAA,CAAQ,eAAe,UAAU;IACzE,IAAI,oBAAoB,CAAA,GAAI;QAC1B,MAAM,IAAI,MAAM,oBAAoB;IACtC;IAEA,MAAM,YAAY,gBAAgB,KAAA,CAAM,YAAY,eAAe;IACnE,MAAM,UAAU,gBAAgB,KAAA,CAAM,kBAAkB,YAAY;IACpE,OAAO;QAAC;QAAW,OAAO;KAAA;AAC5B;AAEO,SAAS,oBACd,KAAA,EACA,OAAA,EAC6B;IAC7B,SAAS,WAAW,CAAA,EAA+B;QACjD,IAAI,EAAE,UAAA,CAAW,GAAG,KAAM,EAAE,UAAA,CAAW,GAAG,KAAK,EAAE,MAAA,KAAW,GAAI;YAC9D,OAAO,KAAA;QACT;QACA,OAAO,SAAS,GAAG,EAAE;IACvB;IAEA,IAAI,YAAY,IAAI;QAClB,OAAO;IACT;IACA,IAAI,CAAC,QAAQ,UAAA,CAAW,GAAG,GAAG;QAC5B,MAAM,IAAI,MAAM,yBAAgC,CAAE,MAAT,OAAO;IAClD;IAEA,MAAM,SAAS,QACZ,KAAA,CAAM,GAAG,EACT,KAAA,CAAM,CAAC,EACP,GAAA,CAAI,CAAA,IAAK,EAAE,OAAA,CAAQ,OAAO,GAAG,EAAE,OAAA,CAAQ,OAAO,GAAG,CAAC;IAErD,IAAI,SAAS;IACb,KAAA,MAAW,SAAS,OAAQ;QAC1B,IAAI;QACJ,IAAI,MAAM,OAAA,CAAQ,MAAM,GAAG;YACzB,MAAM,IAAI,WAAW,KAAK;YAC1B,IAAI,MAAM,KAAA,GAAW;gBACnB,OAAO,KAAA;YACT;YACA,YAAY,MAAA,CAAO,CAAC,CAAA;QACtB,OAAA,IAAW,WAAW,MAAM;YAC1B,OAAO,KAAA;QACT,OAAA,IAAW,OAAO,WAAW,UAAU;YACrC,SAAS;YACT,YAAY,MAAA,CAAO,KAAK,CAAA;QAC1B;QACA,IAAI,cAAc,KAAA,GAAW;YAC3B,OAAO,KAAA;QACT;QACA,SAAS;IACX;IACA,OAAO;AACT;;ACzMO,IAAM,gDAAN,MAAW;IAehB,IAAI,GAAA,EAA+B;QACjC,OAAO,IAAA,CAAK,GAAA,CAAI,GAAA,CAAI,GAAG;IACzB;IAEA,IAAI,GAAA,EAAmD;QACrD,OAAO,IAAA,CAAK,GAAA,CAAI,GAAA,CAAI,GAAG;IACzB;IAEA,UAA4B;QAC1B,OAAO,IAAA,CAAK,GAAA,CAAI,OAAA,CAAQ;IAC1B;IAEA,eAAe,SAAA,EAA8B;QAC3C,MAAM,MAAM,IAAA,CAAK,OAAA,CAAQ,GAAA,CAAI,SAAS;QACtC,IAAI,QAAQ,KAAA,GAAW;YACrB,MAAM,IAAI,MAAM,uBAAgC,CAAE,MAAX,SAAS;QAClD;QACA,OAAO,IAAI,GAAA;IACb;IAEA,IAAI,SAAkB;QACpB,sPAAO,IAAA,EAAK,UAAS,MAAA;IACvB;IAEA,QAAc;QACZ,+OAAA,IAAA,EAAK,UAAS,OAAA,CAAQ;IACxB;IApCA,YACE,OAAA,EACA,GAAA,EACA,OAAA,CACA;;;wBARO;;iQACT;qQACS;6PAOF,UAAW;QAChB,IAAA,CAAK,GAAA,GAAM;QACX,IAAA,CAAK,OAAA,GAAU;IACjB;AA6BF;AAEO,SAAS,oBACd,OAAA,EACA,aAAA,EACe;IACf,OAAO,aAAa,mBAAmB,SAAS,aAAa;AAC/D;AAEA,eAAsB,aACpB,IAAA,EACA,OAAA,EACA,aAAA,EACe;IACf,MAAM,SAAS,MAAM,eAAe,MAAM,OAAO;IACjD,OAAO,eAAe,QAAQ,SAAS,aAAa;AACtD;AAEA,eAAsB,aACpBC,KAAAA,EACA,OAAA,EACA,aAAA,EACe;IACf,MAAM,SAAS,MAAM,eAAeA,OAAM,OAAO;IACjD,OAAO,eAAe,QAAQ,SAAS,aAAa;AACtD;AAEA,SAAS,eACP,MAAA,EACA,OAAA,EACA,aAAA,EACM;IACN,MAAM,UAAU,mBAAmB,QAAQ,SAAS,aAAa;IACjE,MAAM,MAAM,IAAI,UAAU,SAAS,eAAe,OAAO,SAAS;IAClE,OAAO,IAAI,KAAK,SAAS,KAAK,OAAO;AACvC;AAEO,SAAS,mBACd,MAAA,EACA,OAAA,EACA,aAAA,EACwB;IACxB,MAAM,IAAI,aAAA,GAAA,IAAI,IAAI;IAClB,KAAA,MAAW,SAAS,OAAO,OAAA,CAAS;QAClC,EAAE,GAAA,CACA,MAAM,UAAA,CAAW,IAAA,EACjB,IAAI,UACF,OACA,IAAI,UAAU,SAAS,eAAe,MAAM,SAAS;IAG3D;IACA,OAAO;AACT;;AChHA,eAAsB,qBACpB,EAAA,EACc;IACd,MAAM,MAAW,CAAC,CAAA;IAClB,WAAA,MAAiBC,MAAK,GAAI;QACxB,IAAI,IAAA,CAAKA,EAAC;IACZ;IACA,OAAO;AACT;;ACJO,SAAS,KACd,MAAA,EACA,MAAA,EACuB;IAEvB,OAAO,qBAAqB,OAAO,IAAA,CAAK,MAAM,CAAC;AACjD;;ACeO,IAAM,oJAAN,cAAyB,UAAU;IA8CxC,WAAW,IAAA,EAA6C;QACtD,IAAA,mWAAA,EAAO,KAAK,SAAS;QACrB,+OAAA,IAAA,EAAK,WAAU,MAAA,CAAO,KAAK,IAAI;QAC/B,KAAK,IAAA,GAAO,cAAc;QAC1B,gPAAA,IAAA,kBAAK,oBAAL,IAAA,EAAoB,IAAI;IAC1B;IAEA,oBACE,OAAA,EACA,KAAA,EACkB;QAClB,MAAM,IAAI,IAAI,iBAAiB,SAAS,cAAc,GAAG,OAAO,IAAI;QACpE,gPAAA,IAAA,kBAAK,oBAAL,IAAA,EAAoB,CAAC;QACrB,OAAO;IACT;IAEA,gBAAgB,OAAA,EAAiD;QAC/D,MAAM,IAAI,IAAI,aAAa,SAAS,cAAc,GAAG,IAAI;QACzD,gPAAA,IAAA,kBAAK,oBAAL,IAAA,EAAoB,CAAC;QACrB,OAAO;IACT;IAQA,YACE,OAAA,EACA,KAAA,EACiC;QACjC,MAAM,IAAI,YAAY,SAAS,cAAc,GAAG,OAAO,IAAI;QAC3D,gPAAA,IAAA,kBAAK,oBAAL,IAAA,EAAoB,CAAC;QACrB,OAAO;IACT;IAEA,IAAI,GAAA,EAAa,KAAA,EAAuC;QACtD,sPAAO,IAAA,EAAK,OAAM,QAAA,CAAS,YAAY;YACrC,MAAM,cAAc,MAAM,IAAA,CAAK,OAAA,CAAQ,IAAA,CAAK,QAAQ;YACpD,MAAM,YAAY,IAAA,CAAK,YAAA,CAAa,KAAK,KAAK;YAC9C,MAAM,WAAW,MAAM,YAAY,GAAA,CAAI,KAAK,OAAO,WAAW,IAAI;YAGlE,IAAI,SAAS,gBAAA,CAAiB,IAAI,IAAI,IAAA,CAAK,OAAA,EAAS;gBAClD,MAAM,aAAa,IAAA,CAAK,eAAA;gBACxB,MAAM,aAAa,UACjB,SAAS,OAAA,EACT,CAAAC,SAASA,MAAAA,CAAM,CAAC,CAAA,EAChB,IAAA,CAAK,OAAA,GAAU,YACf,IAAA,CAAK,OAAA,GAAU;gBAEjB,MAAM,EAAC,KAAA,CAAK,CAAA,GAAI;gBAChB,MAAM,UAAyB,WAAW,GAAA,CAAI,CAAAC,aAAW;oBACvD,MAAM,OAAO,IAAA,CAAK,WAAA,CAAYA,UAAS,KAAK;oBAC5C,OAAO,8BAA8B,MAAM,IAAA,CAAK,YAAY;gBAC9D,CAAC;gBACD,MAAM,UAAU,IAAA,CAAK,mBAAA,CAAoB,SAAS,QAAQ,CAAC;gBAC3D,IAAA,CAAK,QAAA,GAAW,QAAQ,IAAA;gBACxB;YACF;YAEA,IAAA,CAAK,QAAA,GAAW,SAAS,IAAA;QAC3B,CAAC;IACH;IAEA,IAAI,GAAA,EAA+B;QACjC,sPAAO,IAAA,EAAK,OAAM,QAAA,CAAS,YAAY;YACrC,MAAM,cAAc,MAAM,IAAA,CAAK,OAAA,CAAQ,IAAA,CAAK,QAAQ;YACpD,MAAM,cAAc,MAAM,YAAY,GAAA,CAAI,KAAK,IAAI;YAInD,MAAM,QAAQ,IAAA,CAAK,QAAA,KAAa,YAAY,IAAA;YAC5C,IAAI,OAAO;gBAET,IAAI,YAAY,KAAA,GAAQ,KAAK,YAAY,OAAA,CAAQ,MAAA,KAAW,GAAG;oBAC7D,IAAA,CAAK,QAAA,GAAY,YAAiC,OAAA,CAAQ,CAAC,CAAA,CAAE,CAAC,CAAA;gBAChE,OAAO;oBACL,IAAA,CAAK,QAAA,GAAW,YAAY,IAAA;gBAC9B;YACF;YAEA,OAAO;QACT,CAAC;IACH;IAEA,QAAuB;QACrB,sPAAO,IAAA,EAAK,OAAM,QAAA,CAAS,MAAM;YAC/B,+OAAA,IAAA,EAAK,WAAU,KAAA,CAAM;YACrB,IAAA,CAAK,QAAA,GAAW;QAClB,CAAC;IACH;IAEA,QAAuB;QACrB,sPAAO,IAAA,EAAK,OAAM,QAAA,CAAS,YAAY;YACrC,MAAM,WAAW,IAAA,CAAK,QAAA;YAEtB,IAAI,IAAA,CAAK,QAAA,KAAa,WAAW;gBAE/B,MAAM,QAAQ,SAAS,WAAA,CAAY,eAAe,CAAC,CAAC;gBACpD,MAAM,SAAS,QAAA,CAAS,KAAiC;gBACzD,OAAO,MAAM,IAAA;YACf;YAEA,MAAM,YAAqB,CAAC,CAAA;YAC5B,MAAM,UAAU,gBACd,IAAA,CAAK,QAAA,EACL,WACA,SAAS,WAAA,iPACT,IAAA,EAAK,YACL,IAAA,CAAK,cAAA;YAEP,MAAM,QAAQ,GAAA,CAAI,UAAU,GAAA,CAAI,CAAA,QAAS,SAAS,QAAA,CAAS,KAAK,CAAC,CAAC;YAClE,+OAAA,IAAA,EAAK,WAAU,KAAA,CAAM;YACrB,IAAA,CAAK,QAAA,GAAW;YAChB,OAAO;QACT,CAAC;IACH;IA3IA,YACE,QAAA,EACA,aAAA,EACA,OAAa,SAAA,EACb,UAAU,IAAI,IAAA,EACd,UAAU,KAAK,IAAA,EACf,eAA6C,cAAA,EAC7C,eAAA,CACA;QACA,KAAA,CAAM,UAAU,eAAe,MAAM,cAAc,eAAe,igBAjB3D;;mBAAQ,IAAI,2NAAA,CAAK;kQACjB;;mBAAwD,aAAA,GAAA,IAAI,IAAI;yQAIhE,4PACA;QAaP,IAAA,CAAK,OAAA,GAAU;QACf,IAAA,CAAK,OAAA,GAAU;IACjB;AA+HF;AAEA,SAAS,gBACPC,KAAAA,EACA,SAAA,EACAC,YAAAA,EACA,QAAA,EACA,aAAA,EACM;IACN,MAAM,OAAO,SAAS,GAAA,CAAID,KAAI;IAC9B,IAAI,SAAS,KAAA,GAAW;QAEtB,OAAOA;IACT;IAEA,IAAI,eAAe,IAAI,GAAG;QACxB,MAAME,SAAQD,aAAY,YAAY,MAAM,aAAa,GAAG,CAAC,CAAC;QAC9D,UAAU,IAAA,CAAKC,MAAK;QACpB,OAAOA,OAAM,IAAA;IACf;IAIA,MAAM,OAAe,CAAC,CAAA;IACtB,MAAM,EAAC,OAAA,CAAO,CAAA,GAAI;IAClB,IAAA,IAAS,IAAI,GAAG,IAAI,QAAQ,MAAA,EAAQ,IAAK;QACvC,MAAM,QAAQ,OAAA,CAAQ,CAAC,CAAA;QACvB,MAAM,YAAY,KAAA,CAAM,CAAC,CAAA;QACzB,MAAM,eAAe,gBACnB,WACA,WACAD,cACA,UACA;QAEF,IAAI,iBAAiB,WAAW;YAG9B,OAAA,CAAQ,CAAC,CAAA,GAAI;gBAAC,KAAA,CAAM,CAAC,CAAA;gBAAG;gBAAc,KAAA,CAAM,CAAC,CAAC;aAAA;QAChD;QACA,KAAK,IAAA,CAAK,YAAY;IACxB;IACA,MAAM,QAAQA,aAAY,YAAY,MAAM,aAAa,GAAG,OAAO,IAAI,CAAC;IACxE,UAAU,IAAA,CAAK,KAAK;IACpB,OAAO,MAAM,IAAA;AACf;;AC3OO,SAAS,KAAQ,OAAA,EAA2B;IACjD,IAAI;IACJ,OAAO,MAAM;QACX,IAAI,UAAU,KAAA,GAAW;YACvB,QAAQ,QAAQ;QAClB;QACA,OAAO;IACT;AACF;;ACiBO,IAAM,WAAN,cAAuB,IAA0B;IAC7C,IAAI,GAAA,EAAa,KAAA,EAA2B;QACnD,IAAI,MAAM,MAAA,KAAW,GAAG;YACtB,OAAO,IAAA;QACT;QACA,OAAO,KAAA,CAAM,IAAI,KAAK,KAAK;IAC7B;AACF;AAMA,eAAsBE,MACpB,OAAA,EACA,OAAA,EACA,IAAA,EACA,UAAA,EACA,aAAA,EACmB;IACnB,MAAM,CAAC,WAAW,SAAS,CAAA,GAAI,MAAM,QAAQ,GAAA,CAAI;QAC/C,eAAe,SAAS,IAAI;QAC5B,eAAe,SAAS,IAAI;KAC7B;IAED,OAAO,YAAY,WAAW,WAAW,MAAM,YAAY,aAAa;AAC1E;AAOA,eAAsB,YACpB,SAAA,EACA,SAAA,EACA,IAAA,EACA,UAAA,EACA,aAAA,EACmB;IACnB,MAAM,WAAW,IAAI,SAAS;IAC9B,IAAI,CAAC,WAAW,kBAAA,CAAmB,GAAG;QACpC,OAAO;IACT;IAEA,MAAM,SAAS,IAAI,UAAU,MAAM,eAAe,UAAU,SAAS;IACrE,MAAM,SAAS,IAAI,UAAU,MAAM,eAAe,UAAU,SAAS;IACrE,MAAM,YAAY,MAAM,KAAU,QAAQ,MAAM;IAChD,SAAS,GAAA,CAAI,IAAI,SAAS;IAE1B,MAAM,mBACJ,WACA,WACA,MACA,UACA,YACA;IAGF,OAAO;AACT;AAEA,eAAsB,mBACpB,UAAA,EACA,UAAA,EACA,IAAA,EACA,QAAA,EACA,UAAA,EACA,aAAA,EACA;IACA,MAAM,aAAa,mBAAmB,YAAY,MAAM,aAAa;IACrE,MAAM,aAAa,mBAAmB,YAAY,MAAM,aAAa;IAErE,KAAA,MAAW,CAAC,cAAc,QAAQ,CAAA,IAAK,WAAY;QACjD,IAAI,CAAC,WAAW,0BAAA,CAA2B,YAAY,GAAG;YACxD;QACF;QAEA,MAAM,WAAW,WAAW,GAAA,CAAI,YAAY;QAC5C,IAAI,aAAa,KAAA,GAAW;YAC1B,IAAA,mWAAA,EAAO,aAAa,QAAQ;YAC5B,MAAM,QAAQ,MAAM,KAAU,SAAS,GAAA,EAAK,SAAS,GAAG;YACxD,WAAW,MAAA,CAAO,YAAY;YAC9B,SAAS,GAAA,CAAI,cAAc,KAAK;QAClC,OAAO;YAEL,MAAM,QAAQ,MAAM,iBAAiB,SAAS,GAAA,EAAK,KAAK;YACxD,SAAS,GAAA,CAAI,cAAc,KAAK;QAClC;IACF;IAEA,KAAA,MAAW,CAAC,cAAc,QAAQ,CAAA,IAAK,WAAY;QACjD,IAAI,CAAC,WAAW,0BAAA,CAA2B,YAAY,GAAG;YACxD;QACF;QAEA,MAAM,QAAQ,MAAM,iBAAiB,SAAS,GAAA,EAAK,KAAK;QACxD,SAAS,GAAA,CAAI,cAAc,KAAK;IAClC;AACF;;AC1FO,IAAM,SACF,yCACA,2EAMA,yCACA,sGATJ,cAAoB,KAAK;IAkC9B;;;GAAA,GAMA,MAAM,IACJ,EAAA,EACA,GAAA,EACA,KAAA,EACe;QACf,MAAM,SAAS,KAAK,IAAM,IAAA,CAAK,GAAA,CAAI,GAAA,CAAI,GAAG,CAAC;QAC3C,MAAM,cAAc,IAAI,IAAA,CAAK,OAAA,EAAS,KAAK,QAAQ,KAAK;QAExD,MAAM,IAAA,CAAK,GAAA,CAAI,GAAA,CAAI,KAAK,KAAK;IAC/B;IAEA,gBAAiC;QAC/B,OAAO,6PAAc,IAAA,EAAK,2PAAW,IAAA,EAAK,2PAAW,IAAA,EAAK,KAAK;IACjE;IAEA,MAAM,IAAI,EAAA,EAAgB,GAAA,EAA+B;QAEvD,MAAM,SAAS,KAAK,IAAM,IAAA,CAAK,GAAA,CAAI,GAAA,CAAI,GAAG,CAAC;QAC3C,IAAI,WAAW,KAAA,GAAW;YACxB,MAAM,cAAc,IAAI,IAAA,CAAK,OAAA,EAAS,KAAK,QAAQ,KAAA,CAAS;QAC9D;QACA,OAAO,IAAA,CAAK,GAAA,CAAI,GAAA,CAAI,GAAG;IACzB;IAEA,MAAM,QAAuB;QAC3B,MAAM,IAAA,CAAK,GAAA,CAAI,KAAA,CAAM;QACrB,MAAM,KAAK,CAAC,CAAA;QACZ,KAAA,MAAW,OAAO,IAAA,CAAK,OAAA,CAAQ,MAAA,CAAO,EAAG;YACvC,GAAG,IAAA,CAAK,IAAI,KAAA,CAAM,CAAC;QACrB;QACA,MAAM,QAAQ,GAAA,CAAI,EAAE;IACtB;IAEA,MAAM,YAAyC;QAC7C,MAAM,YAAY,MAAM,IAAA,CAAK,GAAA,CAAI,KAAA,CAAM;QACvC,MAAM,eAA8B,CAAC,CAAA;QAErC,KAAA,MAAW,SAAS,IAAA,CAAK,OAAA,CAAQ,MAAA,CAAO,EAAG;YACzC,MAAMC,aAAY,MAAM,MAAM,KAAA,CAAM;YACpC,MAAM,cAA2B;gBAC/B,YAAY,MAAM,IAAA,CAAK,UAAA;gBACvB,WAAAA;YACF;YACA,aAAa,IAAA,CAAK,WAAW;QAC/B;QAEA,IAAI;QACJ,MAAM,sPAAO,IAAA,EAAK;QAClB,OAAQ,KAAK,IAAA,EAAM;YACjB,KAAc;gBAAW;oBACvB,IAAA,mWAAA,iPAAO,IAAA,EAAK,mBAAgC,IAAI;oBAChD,MAAM,EACJ,SAAA,EACA,UAAA,EACA,WAAA,EACA,eAAA,EACA,YAAA,EACA,SAAA,EACF,GAAI;oBACJ,SAAS,4PACP,IAAA,EAAK,WAAU,WAAA,EACf,WACA,MAAM,yBAAyB,0PAAW,IAAA,EAAK,SAAS,IACxD,YACA,aACA,iBACA,cACA,WACA,cACA,0PACA,IAAA,EAAK;oBAEP;gBACF;YAEA,KAAc;gBAAc;oBAC1B,IAAA,mWAAA,iPAAO,IAAA,EAAK,kBAA+B,IAAI;oBAC/C,MAAM,EAAC,SAAA,EAAW,eAAA,EAAiB,UAAA,CAAU,CAAA,GAAI;oBACjD,SAAS,+PACP,IAAA,EAAK,WAAU,WAAA,EACf,WACA,iBACA,YACA,WACA;oBAEF;gBACF;QACF;QACA,qPAAM,IAAA,EAAK,WAAU,QAAA,CAAS,OAAO,KAAK;QAC1C,OAAO;IACT;IAAA,8CAAA;IAGA,MAAM,OAAO,QAAA,EAAiC;QAC5C,MAAM,SAAS,MAAM,IAAA,CAAK,SAAA,CAAU;QACpC,MAAM,aAAa,OAAO,KAAA,CAAM,IAAA;QAChC,qPAAM,IAAA,EAAK,WAAU,OAAA,CAAQ,UAAU,UAAU;QACjD,qPAAM,IAAA,EAAK,WAAU,MAAA,CAAO;QAC5B,OAAO;IACT;IAEA,MAAM,gBACJ,QAAA,EACA,UAAA,EAC2B;QAC3B,MAAM,SAAS,IAAA,CAAK,SAAA,CAAU;QAC9B,MAAM,UAAU,0PAAM,kBAAK,oBAAL,IAAA,EAAoB,UAAU;QACpD,MAAM,aAAA,CAAc,MAAM,MAAA,EAAQ,KAAA,CAAM,IAAA;QACxC,qPAAM,IAAA,EAAK,WAAU,OAAA,CAAQ,UAAU,UAAU;QACjD,qPAAM,IAAA,EAAK,WAAU,MAAA,CAAO;QAC5B,OAAO;YAAC;YAAY,OAAO;SAAA;IAC7B;IAyDA,QAAc;QACZ,+OAAA,IAAA,EAAK,WAAU,OAAA,CAAQ;IACzB;IAxMA,YACE,QAAA,EACA,GAAA,EACA,KAAA,EACA,IAAA,EACA,OAAA,EACA,QAAA,EACA,aAAA,CACA;QAEA,KAAA,CAAM,UAAU,KAAK,OAAO,GAqI9B,uPAAM;;;;;;kQAvJG;;;;;;;;;;6PAmBF,WAAY;6PACZ,QAAS;6PACT,OAAQ;6PACR,WAAY;6PACZ,gBAAiB;QAGtB,IAAI,UAAU,KAAA,GAAW;YACvB,IAAA,mWAAA,EAAO,KAAK,SAAA,KAAc,SAAS;QACrC,OAAO;YACL,IAAA,mWAAA,EAAO,KAAK,SAAA,KAAc,MAAM,KAAA,CAAM,IAAI;QAC5C;IACF;AAkLF;AAEA,eAAsB,cACpB,SAAA,EACA,WAAA,EACA,eAAA,EACA,YAAA,EACA,QAAA,EACA,SAAA,EACA,QAAA,EACA,aAAA,EACgB;IAChB,MAAM,QAAQ,MAAM,eAAe,WAAW,QAAQ;IACtD,MAAM,aAAa,IAAI,WAAW,UAAU,eAAe,MAAM,SAAS;IAC1E,MAAM,aAAa,MAAM,MAAM,iBAAA,CAAkB,UAAU,QAAQ;IACnE,MAAM,UAAU,oBAAoB,OAAO,UAAU,aAAa;IAClE,IAAA,mWAAA,EAAO,iBAA+B,IAAI;IAC1C,OAAO,IAAI,MACT,UACA,YACA,OAEA;QACE,MAAe;QACf;QACA,kBAAkB,MAAM,yBAAyB,WAAW,QAAQ;QACpE;QACA;QACA;QACA;QACA;QACA;IACF,GACA,SACA,UACA;AAEJ;AAEA,eAAsB,qBACpB,SAAA,EACA,eAAA,EACA,UAAA,EACA,QAAA,EACA,QAAA,EACA,aAAA,EACgB;IAChB,MAAM,QAAQ,MAAM,eAAe,WAAW,QAAQ;IACtD,MAAM,aAAa,IAAI,WAAW,UAAU,eAAe,MAAM,SAAS;IAC1E,OAAO,IAAI,MACT,UACA,YACA,OACA;QAAC;QAAW,MAAe;QAAc;QAAiB;IAAU,GACpE,oBAAoB,OAAO,UAAU,aAAa,GAClD,UACA;AAEJ;AAEA,eAAsB,cACpB,EAAA,EACA,OAAA,EACA,GAAA,EACA,YAAA,EACA,MAAA,EACe;IACf,MAAM,KAAsB,CAAC,CAAA;IAC7B,KAAA,MAAW,OAAO,QAAQ,MAAA,CAAO,EAAG;QAClC,MAAM,EAAC,SAAA,CAAS,CAAA,GAAI,IAAI,IAAA,CAAK,UAAA;QAC7B,IAAI,CAAC,aAAa,IAAI,UAAA,CAAW,SAAS,GAAG;YAC3C,MAAM,SAAS,MAAM,aAAa;YAClC,IAAI,WAAW,KAAA,GAAW;oBASpB;gBARJ,GAAG,IAAA,CACD,WACE,IACA,IAAI,GAAA,EACW,QACf,KACA,QACA,IAAI,IAAA,CAAK,UAAA,CAAW,WAAA,yCAChB,IAAA,CAAK,UAAA,CAAW,UAAA,6FAAc;YAGxC;YACA,IAAI,WAAW,KAAA,GAAW;;gBACxB,GAAG,IAAA,CACD,WACE,IACA,IAAI,GAAA,EACW,KACf,KACA,QACA,IAAI,IAAA,CAAK,UAAA,CAAW,WAAA,GACpB,uCAAI,IAAA,CAAK,UAAA,CAAW,UAAA,+FAAc;YAGxC;QACF;IACF;IACA,MAAM,QAAQ,GAAA,CAAI,EAAE;AACtB;AAEO,SAAS,oBACd,MAAA,EACA,QAAA,EACA,aAAA,EACyB;IACzB,MAAM,IAAI,aAAA,GAAA,IAAI,IAAI;IAClB,KAAA,MAAW,SAAS,OAAO,OAAA,CAAS;QAClC,EAAE,GAAA,CACA,MAAM,UAAA,CAAW,IAAA,EACjB,IAAI,WACF,OACA,IAAI,WAAW,UAAU,eAAe,MAAM,SAAS;IAG7D;IACA,OAAO;AACT;AAEA,eAAsB,iBACpB,EAAA,EACA,QAAA,EACA,QAAA,EACA,MAAA,EACA,WAAA,EACA,UAAA,EACA,aAAA,EACqB;IACrB,MAAM,WAAW,IAAI,WAAW,UAAU,aAAa;IACvD,WAAA,MAAiB,SAAS,SAAS,IAAA,CAAK,MAAM,EAAG;QAC/C,MAAM,MAAM,KAAA,CAAM,CAAC,CAAA;QACnB,IAAI,CAAC,IAAI,UAAA,CAAW,MAAM,GAAG;YAC3B;QACF;QACA,MAAM,WACJ,IACA,UACe,KACf,KACA,KAAA,CAAM,CAAC,CAAA,EACP,aACA;IAEJ;IACA,OAAO;AACT;;ACjYO,IAAM,sBAAyD,eAAA,MAAA,CAAO;AAOtE,IAAM,iBAA+C,eAAA,MAAA,CAAO;;ACT5D,SAAS,eAAuB;IACrC,MAAM,SAAS;IACf,MAAM,OAAO,aAAa;IAC1B,MAAM,MAAM,aAAa;IACzB,MAAM,WAAY,QAAQ,GAAA,GAAO;IACjC,OAAO,SAAS,QAAA,CAAS,EAAE,EAAE,KAAA,CAAM,CAAC,MAAM,EAAE,QAAA,CAAS,QAAQ,GAAG;AAClE;;ACkCA,IAAM,iBAAwB,eAAe;IAC3C,sBAA6B,eAAA,MAAA,CAAO;IAEpC,UAAU;IAAA;;;GAAA,GAMV,iBAAiB,WAAW,QAAA,CAAS;IAAA;;;GAAA,GAMrC,eAAe;AACjB,CAAC;AAID,IAAM,iBAAwB,eAAe;IAC3C,sBAA6B,eAAA,MAAA,CAAO;IAAA;;;;;;;;;;;GAAA,GAcpC,eAAsB,cAAc,UAAU;IAAA;;;GAAA,GAM9C,aAAa,WAAW,QAAA,CAAS;IAAA;;;GAAA,GAMjC,eAAe;AACjB,CAAC;AAMD,SAAS,WAAW,MAAA,EAAoC;IACtD,OAAQ,OAAoB,aAAA,KAAkB,KAAA;AAChD;AAEO,IAAM,oBAAoB;AAEjC,IAAM,eAAsB,eAAA,KAAA,CAAM,gBAAgB,cAAc;AAEhE,SAAS,aAAa,KAAA,EAAyC;IACtDC,QAAO,OAAO,YAAY;AACnC;AAEO,SAAS,eAAe,KAAA,EAA2C;IACjEA,QAAO,OAAO,cAAc;AACrC;AAEA,SAAS,qBAAqB,SAAA,EAA+B;IAC3D,IAAA,yWAAA,EAAa,SAAS;IACtB,MAAM,UAAU,aAAA,GAAA,IAAI,IAAI;IACxB,IAAA,MAAW,OAAO,UAAW;QAC3B,QAAI,mWAAA,EAAO,WAAW,GAAG,GAAG;YAC1B,MAAM,QAAQ,SAAA,CAAU,GAAG,CAAA;YAC3B,IAAI,UAAU,KAAA,GAAW;gBACvB,aAAa,KAAK;gBAClB,QAAQ,GAAA,CAAI,KAAK,KAAK;YACxB;QACF;IACF;IACA,OAAO;AACT;AAEA,SAAS,qBACP,OAAA,EACA,QAAA,EACiB;IACjB,KAAA,MAAW,UAAU,QAAQ,MAAA,CAAO,EAAG;QACrC,IAAI,WAAW,MAAM,GAAG;YACtB,OAAO,aAAA,CAAc,OAAA,CAAQ,SAAS,eAAe;YACrD,IAAI,OAAO,WAAA,EAAa;gBACtB,SAAS,eAAA,CAAgB,OAAO,WAAW;YAC7C;QACF,OAAO;YACL,SAAS,eAAA,CAAgB,OAAO,QAAQ;YACxC,IAAI,OAAO,eAAA,EAAiB;gBAC1B,SAAS,eAAA,CAAgB,OAAO,eAAe;YACjD;QACF;IACF;IACA,WAAO,uWAAA,EAAW,OAAO,WAAA,CAAY,OAAO,CAAC;AAC/C;AAEA,eAAsB,WAAW,OAAA,EAAmC;IAClE,MAAMC,QAAO,MAAM,QAAQ,OAAA,CAAQ,iBAAiB;IACpD,OAAO,iBAAiBA,OAAM,OAAO;AACvC;AAEA,eAAe,iBACbA,KAAAA,EACA,OAAA,EACoB;IACpB,IAAI,CAACA,OAAM;QACT,OAAO,aAAA,GAAA,IAAI,IAAI;IACjB;IACA,MAAM,QAAQ,MAAM,QAAQ,QAAA,CAASA,KAAI;IACzC,OAAO,mEAAqB,MAAO,IAAI;AACzC;AAKO,IAAM,2BAAN,cAAuC,MAAM;IAGlD,YAAY,EAAA,CAAc;QACxB,KAAA,CAAM,+BAAiC,CAAE,MAAJ,EAAE,iPAHzC,QAAO,qRACE;QAGP,IAAA,CAAK,EAAA,GAAK;IACZ;AACF;AAKA,eAAsB,qBACpB,EAAA,EACA,OAAA,EACe;IACf,IAAI,CAAE,MAAM,eAAe,IAAI,OAAO,GAAI;QACxC,MAAM,IAAI,yBAAyB,EAAE;IACvC;AACF;AAEA,eAAsB,eACpB,EAAA,EACA,OAAA,EACkB;IAClB,OAAO,CAAC,CAAE,MAAM,UAAU,IAAI,OAAO;AACvC;AAEA,eAAsB,UACpB,EAAA,EACA,OAAA,EAC6B;IAC7B,MAAM,UAAU,MAAM,WAAW,OAAO;IACxC,OAAO,QAAQ,GAAA,CAAI,EAAE;AACvB;AAEA,eAAsB,cACpB,EAAA,EACA,OAAA,EACiB;IACjB,MAAM,SAAS,MAAM,UAAU,IAAI,OAAO;IAC1C,IAAI,CAAC,QAAQ;QACX,MAAM,IAAI,yBAAyB,EAAE;IACvC;IACA,OAAO;AACT;AASO,SAAS,aACd,WAAA,EACA,EAAA,EACA,MAAA,EACA,YAAA,EACA,OAAA,EACA,aAAA,EACA,wBAAA,EAC6B;IAC7B,OAAO,UAAU,QAAQ,OAAM,aAAY;QACzC,eAAe,kCACb,SAAA,EACA,UAAA,EACAC,UAAAA,EACAC,aAAAA,EAC6B;YAC7B,MAAM,kBAAkB,0BACtB,WACA,CAAC,GACD,YACAD,YACAC;YAEF,MAAM,QAAQ,SAAS,WAAA,CACrB,iBACA,QAAQ,eAAe;YAGzB,MAAM,mBAAmB,aAAa;YAEtC,MAAM,YAAsB;gBAC1B,sBAAsB,KAAK,GAAA,CAAI;gBAC/B,eAAe;oBAAC,MAAM,IAAI;iBAAA;gBAC1B,aAAa;gBACb,eAAe;YACjB;YAEA,MAAM,aAAa,IAAI,IAAI,OAAO,EAAE,GAAA,CAAI,aAAa,SAAS;YAE9D,MAAM,cAA2B;gBAC/B,UAAU,MAAM,IAAA;gBAChB;gBACA;gBACA,aAAa,CAAC;gBACd,2BAA2B,CAAC;gBAC5B,UAAU;YACZ;YAEA,MAAM,QAAQ,GAAA,CAAI;gBAChB,SAAS,QAAA,CAAS,KAAK;gBACvB,WAAW,YAAY,QAAQ;gBAC/B,eAAe,kBAAkB,aAAa,QAAQ;aACvD;YAED,OAAO;gBAAC;gBAAW,MAAM,IAAA;gBAAM;gBAAY,IAAI;aAAA;QACjD;QAEA,MAAM,UAAU,MAAM,WAAW,QAAQ;QAEzC,MAAM,MAAM,MAAM,mBAAmB,UAAU,cAAc,OAAO;QACpE,IAAI,IAAI,IAAA,KAAS,gCAAgC;YAG/C,MAAM,EAAC,aAAA,EAAe,QAAA,CAAQ,CAAA,GAAI;YAElC,MAAM,YAAsB;gBAC1B;gBACA,eAAe;oBAAC,QAAQ;iBAAA;gBACxB,sBAAsB,KAAK,GAAA,CAAI;gBAC/B,aAAa;YACf;YACA,MAAM,aAAa,IAAI,IAAI,OAAO,EAAE,GAAA,CAAI,aAAa,SAAS;YAC9D,MAAM,WAAW,YAAY,QAAQ;YAErC,OAAO;gBAAC;gBAAW;gBAAU;gBAAY,KAAK;aAAA;QAChD;QAEA,IACE,CAAC,4BACD,IAAI,IAAA,KAAS,+BACb;YAEA,MAAM,kBAAkB,SAAS,WAAA,CAAY,eAAe,CAAC,CAAC;YAC9D,MAAM,SAAS,QAAA,CAAS,eAAe;YAGvC,MAAMA,gBAA8B,CAAC,CAAA;YAIrC,KAAA,MAAW,CAAC,MAAM,eAAe,CAAA,IAAK,OAAO,OAAA,CAAQ,OAAO,EAAG;gBAC7D,MAAM,uBAAuB,uBAC3B,MACA;gBAEFA,cAAa,IAAA,CAAK;oBAChB,YAAY;oBACZ,WAAW,gBAAgB,IAAA;gBAC7B,CAAC;YACH;YAEA,OAAO,kCACL,MACA,MACA,gBAAgB,IAAA,EAChBA;QAEJ;QAIA,IAAA,mWAAA,EAAO,IAAI,IAAA,KAAS,8BAA8B;QAElD,MAAM,EAAC,QAAA,CAAQ,CAAA,GAAI;QAGnB,MAAM,eAA8B,CAAC,CAAA;QACrC,MAAM,EAAC,SAAA,EAAW,SAAS,UAAA,CAAU,CAAA,GAAI;QACzC,MAAM,MAAM,IAAI,UAAU,UAAU,eAAe,SAAS;QAE5D,KAAA,MAAW,CAAC,MAAM,eAAe,CAAA,IAAK,OAAO,OAAA,CAAQ,OAAO,EAAG;YAC7D,MAAM,EAAC,SAAS,EAAA,EAAI,WAAA,EAAa,aAAa,KAAA,CAAK,CAAA,GAAI;YACvD,MAAM,uBAA6C;gBACjD;gBACA,WAAW;gBACX;gBACA;YACF;YAEA,MAAM,WAAW,qBAAqB,YAAY,oBAAoB;YACtE,IAAI,UAAU;gBACZ,aAAa,IAAA,CAAK;oBAChB,YAAY;oBACZ,WAAW,SAAS,SAAA;gBACtB,CAAC;YACH,OAAO;gBACL,MAAM,aAAa,MAAM,iBACvB,IACA,UACA,KACA,QACA,aACA,YACA;gBAEF,aAAa,IAAA,CAAK;oBAChB,YAAY;oBACZ,WAAW,MAAM,WAAW,KAAA,CAAM;gBACpC,CAAC;YACH;QACF;QAEA,OAAO,kCACL,SAAS,IAAA,CAAK,SAAA,EACd,SAAS,IAAA,CAAK,UAAA,EACd,SAAS,SAAA,EACT;IAEJ,CAAC;AACH;AAEA,SAAS,qBACP,UAAA,EACA,oBAAA,EACA;IACA,OAAO,WAAW,IAAA,CAAK,CAAA,QACrB,oCAAoC,MAAM,UAAA,EAAY,oBAAoB;AAE9E;AAEO,IAAM,gCAAgC;AACtC,IAAM,iCAAiC;AACvC,IAAM,iCAAiC;AAgB9C,eAAsB,mBACpB,OAAA,EACA,YAAA,EACA,OAAA,EACmC;IACnC,IAAI;IACJ,IAAI;IACJ,MAAM,kBAAkB,IAAI,IAAI,YAAY;IAE5C,MAAM,eAAe,MAAM,gBAAgB,OAAO;IAClD,KAAA,MAAW,CAAC,eAAe,WAAW,CAAA,IAAK,aAAc;QACvD,IACE,CAAC,YAAY,QAAA,IACb,kBAAkB,iBAAiB,YAAY,YAAY,KAC3D,sBAAsB,SAAS,YAAY,OAAO,GAClD;YAEA,OAAO;gBACL,MAAM;gBACN;gBACA,UAAU,YAAY,QAAA;YACxB;QACF;QAEA,MAAM,4BAA4B,MAAM,qBACtC,YAAY,QAAA,EACZ;QAEF,yBAAyB,yBAAyB;QAElD,MAAM,EAAC,UAAA,CAAU,CAAA,GAAI,0BAA0B,IAAA;QAC/C,IACE,iBAAiB,KAAA,KACjB,eAAe,YAAY,YAAY,IAAI,GAC3C;YACA,eAAe;YACf,eAAe;QACjB;IACF;IAEA,IAAI,cAAc;QAChB,OAAO;YACL,MAAM;YACN,UAAU;QACZ;IACF;IAEA,OAAO;QAAC,MAAM;IAA6B;AAC7C;AAEA,SAAS,kBAAkB,OAAA,EAA0B;IACnD,MAAM,OAAkB,aAAA,GAAA,IAAI,IAAI;IAChC,KAAA,MAAW,UAAU,QAAQ,MAAA,CAAO,EAAG;QACrC,IAAI,WAAW,MAAM,GAAG;YACtB,KAAA,MAAWF,SAAQ,OAAO,aAAA,CAAe;gBACvC,KAAK,GAAA,CAAIA,KAAI;YACf;YACA,IAAI,OAAO,WAAA,EAAa;gBACtB,KAAK,GAAA,CAAI,OAAO,WAAW;YAC7B;QACF,OAAO;YACL,KAAK,GAAA,CAAI,OAAO,QAAQ;YACxB,IAAI,OAAO,eAAA,EAAiB;gBAC1B,KAAK,GAAA,CAAI,OAAO,eAAe;YACjC;QACF;IACF;IACA,OAAO,OAAO,IAAI;AACpB;AAEA,eAAsB,wBACpB,QAAA,EACA,IAAA,EACkC;IAClC,MAAM,gBAAgB,MAAM,0BAA0B,UAAU,IAAI;IACpE,IAAI,CAAC,eAAe;QAClB,OAAO,KAAA;IACT;IACA,OAAO,eAAe,eAAe,IAAI;AAC3C;AAEA,eAAsB,0BACpB,QAAA,EACA,IAAA,EACoC;IACpC,MAAM,SAAS,MAAM,UAAU,UAAU,IAAI;IAC7C,uDAAO,OAAQ,aAAA;AACjB;AAMA,eAAsB,UACpB,QAAA,EACA,MAAA,EACA,QAAA,EACe;IACf,MAAM,UAAU,MAAM,WAAW,QAAQ;IACzC,MAAM,aAAa,IAAI,IAAI,OAAO,EAAE,GAAA,CAAI,UAAU,MAAM;IACxD,OAAO,WAAW,YAAY,QAAQ;AACxC;AAMA,eAAsB,WACpB,OAAA,EACA,QAAA,EACe;IACf,MAAM,YAAY,qBAAqB,SAAS,QAAQ;IACxD,MAAM,QAAQ,SAAS,WAAA,CAAY,WAAW,kBAAkB,OAAO,CAAC;IACxE,MAAM,SAAS,QAAA,CAAS,KAAK;IAC7B,MAAM,SAAS,OAAA,CAAQ,mBAAmB,MAAM,IAAI;IACpD,OAAO,MAAM,IAAA;AACf;;AChhBO,SAAS,UACd,KAAA,EACA,MAAA,EACqB;IACrB,OAAO,WAAW,OAAO,CAAC,GAAGG,KAAM;YAAC;YAAG,OAAOA,EAAe,CAAC;SAAC;AAGjE;AAEO,SAAS,WACd,KAAA,EACA,MAAA,EACmB;IAGnB,MAAM,SAA4B,CAAC;IAInC,KAAA,MAAW,SAAS,OAAO,OAAA,CAAQ,KAAK,EAAG;QACzC,MAAM,SAAS,OAAO,KAAA,CAAM,CAAC,CAAA,EAAG,KAAA,CAAM,CAAC,CAAC;QACxC,MAAA,CAAO,MAAA,CAAO,CAAC,CAAC,CAAA,GAAI,MAAA,CAAO,CAAC,CAAA;IAC9B;IACA,OAAO;AACT;AAEO,SAAS,cACd,KAAA,EACA,MAAA,EACmB;IAGnB,MAAM,SAA4B,CAAC;IACnC,KAAA,MAAW,UAAU,OAAO,OAAO,OAAA,CAAQ,KAAK,CAAC,EAAG;QAClD,MAAA,CAAO,MAAA,CAAO,CAAC,CAAC,CAAA,GAAI,MAAA,CAAO,CAAC,CAAA;IAC9B;IACA,OAAO;AACT;;ACrCO,SAAS,KAAQC,EAAAA,EAAyB,GAAA,EAAiB;IAEhE,IAAIA,MAAK,MAAM;QACb,MAAM,IAAI,uCAAM,MAAO,cAAe,OAADA,EAAC,EAAA,OAAQ;IAChD;IACA,OAAOA;AACT;;ACyBO,SAAS,cAAc,CAAA,EAAU,CAAA,EAAkB;IACxD,IAAI,mBAAmB,CAAC;IACxB,IAAI,mBAAmB,CAAC;IAExB,IAAI,MAAM,GAAG;QACX,OAAO;IACT;IACA,IAAI,MAAM,MAAM;QACd,OAAO,CAAA;IACT;IACA,IAAI,MAAM,MAAM;QACd,OAAO;IACT;IACA,IAAI,OAAO,MAAM,WAAW;QAC1B,IAAA,0WAAA,EAAc,CAAC;QACf,OAAO,IAAI,IAAI,CAAA;IACjB;IACA,IAAI,OAAO,MAAM,UAAU;QACzB,IAAA,yWAAA,EAAa,CAAC;QACd,OAAO,IAAI;IACb;IACA,IAAI,OAAO,MAAM,UAAU;QACzB,IAAA,yWAAA,EAAa,CAAC;QASd,OAAOE,iOAAAA,EAAY,GAAG,CAAC;IACzB;IACA,MAAM,IAAI,MAAM,qBAAsB,CAAE,MAAH,CAAC;AACxC;AASO,SAAS,mBAAmBC,EAAAA,EAA2B;IAC5D,sCAAOA,KAAK;AACd;AAIO,SAAS,eACd,KAAA,EACA,OAAA,EACY;IACZ,OAAO,CAAC,GAAG,MAAM;QAEf,KAAA,MAAW,OAAO,MAAO;YACvB,MAAM,QAAQ,GAAA,CAAI,CAAC,CAAA;YACnB,MAAM,OAAO,cAAc,CAAA,CAAE,KAAK,CAAA,EAAG,CAAA,CAAE,KAAK,CAAC;YAC7C,IAAI,SAAS,GAAG;gBACd,MAAM,SAAS,GAAA,CAAI,CAAC,CAAA,KAAM,QAAQ,OAAO,CAAC;gBAC1C,OAAO,UAAU,CAAC,SAAS;YAC7B;QACF;QACA,OAAO;IACT;AACF;AAQO,SAAS,YAAY,CAAA,EAAU,CAAA,EAAmB;IAEvD,IAAI,KAAK,QAAQ,KAAK,MAAM;QAC1B,OAAO;IACT;IACA,OAAO,MAAM;AACf;AAEO,SAAS,aAAa,IAAA,EAAY;IACvC,KAAA,MAAW,UAAU,OAAO,MAAA,CAAO,KAAK,aAAa,EAAG;QACtD,KAAA,MAAWC,SAAQ,OAAO,EAAG;YAC3B,aAAaA,KAAI;QACnB;IACF;AACF;;ACzGO,IAAM,iBAAiB,OAAO,IAAI;AAClC,IAAM,WAAW,OAAO,IAAI;AAwD5B,SAAS,YACd,WAAA,EACA,MAAA,EACA,MAAA,EACA,YAAA,EACA,MAAA;kBACA,iEAAU,OACJ;IACN,IAAI,OAAO,QAAA,EAAU;QACnB,OAAQ,OAAO,IAAA,EAAM;YACnB,KAAK;YACL,KAAK;gBACH,KAAA,MAAW,CAACC,eAAc,QAAQ,CAAA,IAAK,OAAO,OAAA,CAC5C,OAAO,IAAA,CAAK,aAAA,EACX;oBACD,MAAM,cAAc,KAAK,OAAO,aAAA,CAAcA,aAAY,CAAC;oBAC3D,KAAA,MAAW,QAAQ,SAAS,EAAG;wBAC7B,YACE,aACA;4BAAC,MAAM,OAAO,IAAA;4BAAM;wBAAI,GACxB,aACAA,eACA,QACA;oBAEJ;gBACF;gBACA;YACF,KAAK;gBAKH;YACF,KAAK;gBAAS;oBACZ,MAAM,cAAc,KAClB,OAAO,aAAA,CAAc,OAAO,KAAA,CAAM,gBAAgB,CAAA;oBAEpD,YACE,aACA,OAAO,KAAA,CAAM,MAAA,EACb,aACA,cACA,QACA;oBAEF;gBACF;YACA;gBACE,IAAA,wWAAA,EAAY,MAAM;QACtB;IACF;IAEA,MAAM,EAAC,QAAA,EAAU,eAAe,YAAA,CAAY,CAAA,GAAI;IAChD,OAAQ,OAAO,IAAA,EAAM;QACnB,KAAK;YAAO;gBACV,IAAI;gBAEJ,IAAI,UAAU;oBACZ,MAAM,WAAW,WAAA,CAAY,YAAY,CAAA;oBACzC,IAAI,aAAa,KAAA,GAAW;wBAC1B,IAAA,mWAAA,EACE,OAAO,WAAA,CAAY,UAAU,OAAO,IAAA,CAAK,GAAG,MAAM,GAClD,0BAAsC,OAAZ,YAAY,EAAA;wBAGxC,QAAA,CAAS,cAAc,CAAA;oBACzB,OAAO;wBACL,WAAW,iBAAiB,OAAO,IAAA,CAAK,GAAA,EAAK,QAAQ,SAAS,CAAC;wBAE9D,WAAA,CAAgC,YAAY,CAAA,GAAI;oBACnD;gBACF,OAAO;oBACL,WAAW,IACT,OAAO,IAAA,CAAK,GAAA,EACZ,kBAAkB,aAAa,YAAY,GAC3C,QACA;gBAEJ;gBAEA,IAAI,UAAU;oBACZ,KAAA,MAAW,CAACA,eAAc,QAAQ,CAAA,IAAK,OAAO,OAAA,CAC5C,OAAO,IAAA,CAAK,aAAA,EACX;wBAED,MAAM,cAAc,KAAK,OAAO,aAAA,CAAcA,aAAY,CAAC;wBAC3D,MAAM,cAAc,YAAA,CAAaA,aAAY,CAAA;wBAC7C,IAAI,gBAAgB,KAAA,GAAW;4BAC7B;wBACF;wBAEA,MAAM,UAAU,YAAY,QAAA,GACxB,KAAA,IACC,CAAC,CAAA;wBACN,QAAA,CAASA,aAAY,CAAA,GAAI;wBAEzB,KAAA,MAAW,QAAQ,SAAS,EAAG;4BAC7B,YACE,UACA;gCAAC,MAAM;gCAAO;4BAAI,GAClB,aACAA,eACA,aACA;wBAEJ;oBACF;gBACF;gBACA;YACF;QACA,KAAK;YAAU;gBACb,IAAI,UAAU;oBACZ,MAAM,WAAW,WAAA,CAAY,YAAY,CAAA;oBACzC,IAAA,mWAAA,EAAO,aAAa,KAAA,GAAW,qBAAqB;oBACpD,MAAM,KAAK,QAAA,CAAS,cAAc,CAAA;oBAClC,IAAI,OAAO,GAAG;wBACX,WAAA,CAAgC,YAAY,CAAA,GAAI,KAAA;oBACnD;oBACA,QAAA,CAAS,cAAc,CAAA;gBACzB,OAAO;oBACL,wBACE,kBAAkB,aAAa,YAAY,GAC3C,OAAO,IAAA,CAAK,GAAA,EACZ,OAAO,WAAA;gBAEX;gBAEA,aAAa,OAAO,IAAI;gBACxB;YACF;QACA,KAAK;YAAS;gBACZ,IAAI;gBACJ,IAAI,UAAU;oBACZ,WAAW,iBAAiB,aAAa,YAAY;gBACvD,OAAO;oBACL,MAAM,OAAO,kBAAkB,aAAa,YAAY;oBACxD,MAAM,EAAC,GAAA,EAAK,KAAA,CAAK,CAAA,GAAIC,cACnB,MACA,OAAO,IAAA,CAAK,GAAA,EACZ,OAAO,WAAA;oBAET,IAAA,mWAAA,EAAO,OAAO,qBAAqB;oBACnC,WAAW,IAAA,CAAK,GAAG,CAAA;gBACrB;gBAEA,MAAM,cAAc,KAClB,OAAO,aAAA,CAAc,OAAO,KAAA,CAAM,gBAAgB,CAAA;gBAEpD,MAAM,cAAc,OAAO,aAAA,CAAc,OAAO,KAAA,CAAM,gBAAgB,CAAA;gBACtE,IAAI,gBAAgB,KAAA,GAAW;oBAC7B,YACE,UACA,OAAO,KAAA,CAAM,MAAA,EACb,aACA,OAAO,KAAA,CAAM,gBAAA,EACb,aACA;gBAEJ;gBACA;YACF;QACA,KAAK;YAAQ;gBACX,IAAI,UAAU;oBACZ,MAAM,WAAW,WAAA,CAAY,YAAY,CAAA;oBACzC,gBAAgB,QAAQ;oBACxB,UAAU,UAAU,QAAQ,QAAQ,OAAO;gBAC7C,OAAO;oBACL,MAAM,OAAO,kBAAkB,aAAa,YAAY;oBAExD,IAAI,OAAO,WAAA,CAAY,OAAO,OAAA,CAAQ,GAAA,EAAK,OAAO,IAAA,CAAK,GAAG,MAAM,GAAG;wBACjE,MAAM,EAAC,KAAK,MAAA,EAAQ,OAAO,QAAA,CAAQ,CAAA,GAAIA,cACrC,MACA,OAAO,OAAA,CAAQ,GAAA,EACf,OAAO,WAAA;wBAET,IAAA,mWAAA,EAAO,UAAU,yBAAyB;wBAC1C,MAAM,WAAW,IAAA,CAAK,MAAM,CAAA;wBAC5B,MAAM,EAAC,GAAA,EAAK,KAAA,CAAK,CAAA,GAAIA,cACnB,MACA,OAAO,IAAA,CAAK,GAAA,EACZ,OAAO,WAAA;wBAQT,IACE,QAAA,CAAS,cAAc,CAAA,KAAM,KAAA,CAC5B,QAAQ,UAAU,MAAM,MAAM,MAAA,GAC/B;4BACA,UAAU,UAAU,QAAQ,QAAQ,OAAO;wBAC7C,OAAO;4BAUL,QAAA,CAAS,cAAc,CAAA;4BACvB,IAAI,cAAc;4BAClB,IAAI,QAAA,CAAS,cAAc,CAAA,KAAM,GAAG;gCAClC,KAAK,MAAA,CAAO,QAAQ,CAAC;gCACrB,cAAc,SAAS,MAAM,MAAM,IAAI;4BACzC;4BAEA,IAAI;4BACJ,IAAI,OAAO;gCACT,cAAc,IAAA,CAAK,WAAW,CAAA;4BAChC,OAAO;gCACL,KAAK,MAAA,CAAO,aAAa,GAAG,QAAQ;gCACpC,cAAc;gCACd,IAAI,QAAA,CAAS,cAAc,CAAA,GAAI,GAAG;oCAChC,MAAM,eAAe;wCAAC,GAAG,QAAA;oCAAQ;oCACjC,IAAA,CAAK,MAAM,CAAA,GAAI;gCACjB;4BACF;4BACA,WAAA,CAAY,cAAc,CAAA;4BAC1B,UAAU,aAAa,QAAQ,QAAQ,OAAO;wBAChD;oBACF,OAAO;wBAEL,MAAM,EAAC,GAAA,EAAK,KAAA,CAAK,CAAA,GAAIA,cACnB,MACA,OAAO,OAAA,CAAQ,GAAA,EACf,OAAO,WAAA;wBAET,IAAA,mWAAA,EAAO,OAAO,qBAAqB;wBACnC,UAAU,IAAA,CAAK,GAAG,CAAA,EAAG,QAAQ,QAAQ,OAAO;oBAC9C;gBACF;gBAEA;YACF;QACA;YACE,IAAA,wWAAA,EAAY,MAAM;IACtB;AACF;AAEA,SAAS,UACP,QAAA,EACA,MAAA,EACA,MAAA,EACA,OAAA,EACA;IACA,OAAO,MAAA,CAAO,UAAU,OAAO,IAAA,CAAK,GAAG;IACvC,IAAI,SAAS;QACX,QAAA,CAAS,QAAQ,CAAA,GAAI,OAAO,OAAO,IAAA,CAAK,GAAA,EAAK,MAAM;IACrD;AACF;AAEA,SAAS,IACP,GAAA,EACA,IAAA,EACA,MAAA,EACA,OAAA,EACuB;IACvB,MAAM,EAAC,GAAA,EAAK,KAAA,CAAK,CAAA,GAAIA,cAAa,MAAM,KAAK,OAAO,WAAW;IAE/D,IAAI,OAAO;QACT,IAAA,CAAK,GAAG,CAAA,CAAE,cAAc,CAAA;QACxB,OAAO,KAAA;IACT;IACA,MAAM,WAAW,iBAAiB,KAAK,QAAQ,SAAS,CAAC;IACzD,KAAK,MAAA,CAAO,KAAK,GAAG,QAAQ;IAC5B,OAAO;AACT;AAEA,SAAS,wBACP,IAAA,EACA,GAAA,EACA,WAAA,EACW;IACX,MAAM,EAAC,GAAA,EAAK,KAAA,CAAK,CAAA,GAAIA,cAAa,MAAM,KAAK,WAAW;IACxD,IAAA,mWAAA,EAAO,OAAO,qBAAqB;IACnC,MAAM,WAAW,IAAA,CAAK,GAAG,CAAA;IACzB,MAAM,KAAK,QAAA,CAAS,cAAc,CAAA;IAClC,IAAI,OAAO,GAAG;QACZ,KAAK,MAAA,CAAO,KAAK,CAAC;IACpB;IACA,QAAA,CAAS,cAAc,CAAA;IAEvB,OAAO;AACT;AAGA,SAASA,cACP,IAAA,EACA,MAAA,EACA,UAAA,EACA;IACA,IAAI,MAAM;IACV,IAAI,OAAO,KAAK,MAAA,GAAS;IACzB,MAAO,OAAO,KAAM;QAClB,MAAM,MAAO,MAAM,SAAU;QAC7B,MAAM,aAAa,WAAW,IAAA,CAAK,GAAG,CAAA,EAAU,MAAa;QAC7D,IAAI,aAAa,GAAG;YAClB,MAAM,MAAM;QACd,OAAA,IAAW,aAAa,GAAG;YACzB,OAAO,MAAM;QACf,OAAO;YACL,OAAO;gBAAC,KAAK;gBAAK,OAAO;YAAI;QAC/B;IACF;IACA,OAAO;QAAC,KAAK;QAAK,OAAO;IAAK;AAChC;AAEA,SAAS,kBACP,WAAA,EACA,YAAA,EACe;IACf,MAAM,OAAO,WAAA,CAAY,YAAY,CAAA;IACrC,IAAA,wWAAA,EAAY,IAAI;IAChB,OAAO;AACT;AAEA,SAAS,gBAAgBC,EAAAA,EAAoC;IAC3D,IAAA,yWAAA,EAAcA,EAAAA,CAAyB,cAAc,CAAC;AACxD;AAEA,SAAS,iBAAiB,WAAA,EAAoB,YAAA,EAAiC;IAC7E,MAAM,IAAI,WAAA,CAAY,YAAY,CAAA;IAClC,IAAA,yWAAA,EAAc,CAAA,CAAyB,cAAc,CAAC;IACtD,OAAO;AACT;AAEA,SAAS,iBACP,GAAA,EACA,MAAA,EACA,OAAA,EACA,EAAA,EACW;IACX,IAAI,SAAS;QACX,OAAO;YAAC,GAAG,GAAA;YAAK,CAAC,cAAc,CAAA,EAAG;YAAI,CAAC,QAAQ,CAAA,EAAG,OAAO,KAAK,MAAM;QAAC;IACvE;IACA,OAAO;QAAC,GAAG,GAAA;QAAK,CAAC,cAAc,CAAA,EAAG;IAAE;AACtC;AACA,SAAS,OAAO,GAAA,EAAU,MAAA,EAAsB;IAE9C,IAAI,OAAO,UAAA,CAAW,MAAA,KAAW,GAAG;QAClC,OAAO,KAAK,SAAA,CAAU,GAAA,CAAI,OAAO,UAAA,CAAW,CAAC,CAAC,CAAC;IACjD;IACA,OAAO,KAAK,SAAA,CAAU,OAAO,UAAA,CAAW,GAAA,CAAI,CAAA,IAAK,GAAA,CAAI,CAAC,CAAC,CAAC;AAC1D;;AC/YO,IAAM,iBAAiB,MAAQ,KAAK;AAGpC,IAAM,yBAAyB;AAE/B,IAAM,UAAe;AACrB,IAAM,aAAa,MAAQ,KAAK;AAEvC,IAAM,aAAa;IACjB,GAAG;IACH,GAAG,KAAK;IACR,GAAG,KAAK,KAAK;IACb,GAAG,KAAK,KAAK,KAAK;IAClB,GAAG,MAAM,KAAK,KAAK,KAAK;AAC1B;AAEO,SAAS,SAAS,GAAA,EAAkB;IACzC,IAAI,OAAO,QAAQ,UAAU;QAC3B,OAAO,OAAO,KAAA,CAAM,GAAG,IAAI,IAAI,CAAC,OAAO,QAAA,CAAS,GAAG,KAAK,MAAM,IAAI,CAAA,IAAK;IACzE;IACA,IAAI,QAAQ,QAAQ;QAClB,OAAO;IACT;IACA,IAAI,QAAQ,WAAW;QACrB,OAAO,CAAA;IACT;IACA,MAAM,QAAQ,UAAA,CAAW,GAAA,CAAI,IAAI,MAAA,GAAS,CAAC,CAAa,CAAA;IACxD,OAAO,OAAO,IAAI,KAAA,CAAM,GAAG,CAAA,CAAE,CAAC,IAAI;AACpC;AAEO,SAAS,WAAW,CAAA,EAAQ,CAAA,EAAgB;IACjD,MAAM,KAAK,SAAS,CAAC;IACrB,MAAM,KAAK,SAAS,CAAC;IACrB,IAAI,OAAO,CAAA,KAAM,OAAO,CAAA,GAAI;QAC1B,OAAO;IACT;IACA,IAAI,OAAO,CAAA,KAAM,OAAO,CAAA,GAAI;QAC1B,OAAO,CAAA;IACT;IACA,OAAO,KAAK;AACd;AAEO,SAAS,aAAa,GAAA,EAAe;IAC1C,IAAI,OAAO,QAAQ,UAAU;QAC3B,OAAO;IACT;IAEA,IAAI,MAAM,GAAG;QACX,OAAO;IACT;IAEA,IAAI,QAAQ,GAAG;QACb,OAAO;IACT;IAEA,IAAI,WAAW,IAAI,QAAA,CAAS;IAC5B,MAAM,iBAAiB,SAAS,MAAA;IAChC,KAAA,MAAW,QAAQ;QAAC;QAAK;QAAK;QAAK;QAAK,GAAG;KAAA,CAAY;QACrD,MAAM,QAAQ,UAAA,CAAW,IAAI,CAAA;QAC7B,MAAM,QAAQ,MAAM;QACpB,MAAM,YAAY,UAAG,KAAK,EAAO,OAAJ,IAAI;QACjC,IAAI,UAAU,MAAA,GAAS,SAAS,MAAA,EAAQ;YACtC,WAAW;QACb;IACF;IAEA,OAAQ,SAAS,MAAA,GAAS,iBAAiB,WAAW;AACxD;AAEO,SAAS,SAAS,GAAA,EAAU,EAAA,EAAuC;IACxE,MAAM,YAAY,SAAS,GAAG;IAC9B,IAAI,cAAc,CAAA,KAAM,YAAY,KAAK,KAAK,KAAM;YAElD;QAAA,eAAA,0BAAA,WAAA,GAAI,IAAA,cAAJ,+BAAA,cAAA,IAAW,QAAyC,OAAjC,AAAwC,GAArC,EAAA,+BAAqC,CAAE;QAC7D,OAAO,SAAS,OAAO;IACzB;IACA,OAAO;AACT;;AC1FA,IAAM,OAA4B,CAAC,CAAA;AAE5B,IAAM,aACV,eAAA,OAAA,CAAQ,EACR,KAAA,CAAM,CAAAC,OAAK;IACV,IAAI,mWAAA,EAAqB;QACvB,OAAc,+NAAA,EAAA,CAAGA,EAAsB;IACzC;IACA,MAAM,KAAK,YAAYA,IAAG,IAAI,IACnB,+NAAA,EAAA,CAAGA,EAAC,IACJ,+NAAA,GAAA,CAAI;QACT,SAAS;QACT,MAAM,KAAK,KAAA,CAAM;IACnB,CAAC;IACL,KAAK,MAAA,GAAS;IACd,OAAO;AACT,CAAC;AAEI,IAAM,mBACV,eAAA,OAAA,CAAQ,EACR,KAAA,CAAM,CAAAA,OAAK;IACV,IAAI,mWAAA,EAAqB;QACvB,OAAc,+NAAA,EAAA,CAAGA,EAAuB;IAC1C;IACA,MAAM,KAAK,aAAaA,IAAG,IAAI,IACpB,+NAAA,EAAA,CAAGA,EAAC,IACJ,+NAAA,GAAA,CAAI;QACT,SAAS;QACT,MAAM,KAAK,KAAA,CAAM;IACnB,CAAC;IACL,KAAK,MAAA,GAAS;IACd,OAAO;AACT,CAAC;;AChCI,IAAM,gBAAkB,eAAA,KAAA,CAAM;IAAG,eAAA,MAAA,CAAO,CAAC;CAAC,EAAE,MAAA,CAAS,eAAA,KAAA,CAAQ,eAAA,MAAA,CAAO,CAAC,CAAC;;;AEAtE,SAAS,QAAW,GAAA,EAA6B;IAEtD,IAAI,IAAI,IAAI,SAAA,CAAU,CAAA,IAAK,MAAM,KAAA,CAAS;IAC1C,IAAI,IAAI,GAAG;QACT,OAAO;IACT;IACA,MAAME,WAAe,IAAI,KAAA,CAAM,GAAG,CAAC;IACnC,IAAK,KAAK,IAAI,IAAI,MAAA,EAAQ,IAAK;QAC7B,MAAM,IAAI,GAAA,CAAI,CAAC,CAAA;QACf,IAAI,MAAM,KAAA,GAAW;YACnBA,SAAQ,IAAA,CAAK,CAAC;QAChB;IACF;IACA,OAAOA;AACT;AAEO,SAAS,SAAY,IAAA,EAAoB,IAAA,EAA6B;IAC3E,OAAO,KAAK,MAAA,KAAW,KAAK,MAAA,IAAU,KAAK,KAAA,CAAM,CAAC,GAAG,IAAM,MAAM,IAAA,CAAK,CAAC,CAAC;AAC1E;;ACrBO,IAAM,cAAgB,eAAA,KAAA,CAAM,YAAc,eAAA,SAAA,CAAU,CAAC;AAErD,IAAM,YAAc,eAAe,WAAW;;AFW9C,IAAM,iBAAmB,eAAA,MAAA,CAAO;AAChC,IAAM,gBAAgB,OAAO;AAEpC,IAAM,wBAA0B,SAC5B,eAAA,KAAA,CAAM;IAAC;IAAkB,aAAa,OAAO,MAAM,CAAC;CAAC;AAGlD,IAAM,iBAAmB,cAAc,qBAAqB;AAG5D,IAAM,kBAAoB,eAAA,KAAA,CAC7B,eAAA,MAAA,CAAO,GACP,eAAA,MAAA,CAAO,GACP,eAAA,OAAA,CAAQ,GACR,eAAA,IAAA,CAAK;AAGF,IAAM,oBAAsB,aAAa,KAAK,MAAM,MAAM,QAAQ;AAElE,IAAM,iBAAmB,aAAa,KAAK,KAAK,MAAM,IAAI;AAE1D,IAAM,gBAAkB,aAC7B,QACA,YACA,SACA;AAGK,IAAM,cAAgB,aAAa,MAAM,QAAQ;AAEjD,IAAM,uBAAyB,eAAA,KAAA,CACpC,mBACA,gBACA,eACA;AAGF,IAAM,yBAAqD,eAAe;IACxE,MAAQ,eAAA,OAAA,CAAQ,SAAS;IACzB,OAAS,eAAA,KAAA,CACL,eAAA,MAAA,CAAO,GACP,eAAA,MAAA,CAAO,GACP,eAAA,OAAA,CAAQ,GACR,eAAA,IAAA,CAAK,GACL,cAAgB,eAAA,KAAA,CAAQ,eAAA,MAAA,CAAO,GAAK,eAAA,MAAA,CAAO,GAAK,eAAA,OAAA,CAAQ,CAAC,CAAC;AAEhE,CAAC;AACD,IAAM,wBAAmD,eAAe;IACtE,MAAQ,eAAA,OAAA,CAAQ,QAAQ;IACxB,MAAQ,eAAA,MAAA,CAAO;AACjB,CAAC;AAmBD,IAAM,2BAA6B,eAAe;IAChD,MAAQ,eAAA,OAAA,CAAQ,QAAQ;IAAA,6CAAA;IAAA,mDAAA;IAAA,oDAAA;IAAA,kDAAA;IAAA,0CAAA;IAMxB,QAAU,aAAa,YAAY,gBAAgB;IACnD,OAAS,eAAA,KAAA,CAAQ,eAAA,MAAA,CAAO,GAAK,eAAA,KAAA,CAAQ,eAAA,MAAA,CAAO,CAAC,CAAC;AAChD,CAAC;AAED,IAAM,uBAAyB,eAAA,KAAA,CAC7B,wBACA,uBACA;AAKK,IAAM,wBAAmD,eAAe;IAC7E,MAAQ,eAAA,OAAA,CAAQ,QAAQ;IACxB,IAAI;IACJ,MAAM;IACN,OAAS,eAAA,KAAA,CAAM,0BAA0B,sBAAsB;AACjE,CAAC;AAIM,IAAM,4CACT,aAAa,UAAU,YAAY;AAEhC,IAAM,oCACT,eAAe;IACf,MAAQ,eAAA,OAAA,CAAQ,oBAAoB;IACpC,SAAW,eAAA,IAAA,CAAK,IAAM,wBAAwB;IAC9C,IAAI;AACN,CAAC;AAEI,IAAM,kBAAuC,eAAA,KAAA,CAClD,uBACE,eAAA,IAAA,CAAK,IAAM,iBAAiB,GAC5B,eAAA,IAAA,CAAK,IAAM,iBAAiB,GAC9B;AAGF,IAAM,oBAA2C,eAAe;IAC9D,MAAQ,eAAA,OAAA,CAAQ,KAAK;IACrB,YAAc,cAAc,eAAe;AAC7C,CAAC;AAED,IAAM,oBAA2C,eAAe;IAC9D,MAAQ,eAAA,OAAA,CAAQ,IAAI;IACpB,YAAc,cAAc,eAAe;AAC7C,CAAC;AAID,SAAS,gBAAgB,KAAA,EAAuC;IAC9D,IAAA,mWAAA,EAAO,MAAM,OAAA,CAAQ,KAAK,KAAK,MAAM,MAAA,IAAU,CAAC;IAChD,OAAO;AACT;AAEO,IAAM,oBAA2C,SACpD,eAAA,KAAA,CAAM;IAAG,eAAA,MAAA,CAAO,CAAC;CAAC,EAAE,MAAA,CAAS,eAAA,KAAA,CAAQ,eAAA,MAAA,CAAO,CAAC,CAAC;AAGlD,IAAM,oBAAsB,eAAe;IACzC,aAAa;IACb,YAAY;AACd,CAAC;AAQM,IAAM,uCAAyC,eAAe;IACnE,aAAa;IACb,QAAU,eAAA,OAAA,CAAQ,EAAE,QAAA,CAAS;IAC7B,QAAU,aAAa,eAAe,UAAU,MAAM,EAAE,QAAA,CAAS;AACnE,CAAC;AAEM,IAAM,2BACX,qCAAqC,MAAA,CAAO;IAC1C,UAAY,eAAA,IAAA,CAAK,IAAM,SAAS;AAClC,CAAC;AAEI,IAAM,YAA2B,eAAe;IACrD,QAAU,eAAA,MAAA,CAAO,EAAE,QAAA,CAAS;IAC5B,OAAS,eAAA,MAAA,CAAO;IAChB,OAAS,eAAA,MAAA,CAAO,EAAE,QAAA,CAAS;IAC3B,OAAO,gBAAgB,QAAA,CAAS;IAChC,SAAW,cAAc,wBAAwB,EAAE,QAAA,CAAS;IAC5D,OAAS,eAAA,MAAA,CAAO,EAAE,QAAA,CAAS;IAC3B,SAAS,eAAe,QAAA,CAAS;IACjC,OACG,eAAA,MAAA,CAAO;QACN,KAAK;QACL,WAAa,eAAA,OAAA,CAAQ;IACvB,CAAC,EACA,QAAA,CAAS;AACd,CAAC;AAgJD,SAAS,aAAa,GAAA,EAAU,SAAA,EAAwC;QA2C3D;IAzCX,MAAM,EAAC,SAAA,EAAW,UAAA,CAAU,CAAA,GAAI;IAChC,MAAM,UAAU,CAAC,IAAc,WAAW,IAAI,KAAA,EAAO,CAAC;IACtD,MAAM,MAAM,CAAC,OAAe,MAAmB;QAC7C,MAAM,YAAY,EAAE,GAAA,CAAI,CAAA,MAAO,WAAW,OAAO,GAAG,CAAC;QACrD,OAAO,gBAAgB,SAAS;IAClC;IAEA,MAAM,QAAQ,IAAI,KAAA,GAAQ,UAAU,KAAA,CAAM,IAAI,KAAK,IAAI,KAAA;IACvD,MAAM,cAAc;QAClB,QAAQ,IAAI,MAAA;QACZ,OAAO,UAAU,IAAI,KAAK;QAC1B,OAAO,IAAI,KAAA;QACX,OAAO,QAAQ,eAAe,OAAO,IAAI,KAAA,EAAO,SAAS,IAAI,KAAA;QAC7D,SAAS,IAAI,OAAA,GACT,UAAU,OAAA,CACR,IAAI,OAAA,CAAQ,GAAA,CACV,CAAA,IAAA,CACG;gBACC,aAAa;oBACX,aAAa,IAAI,IAAI,KAAA,EAAO,EAAE,WAAA,CAAY,WAAW;oBACrD,YAAY,IAAI,EAAE,QAAA,CAAS,KAAA,EAAO,EAAE,WAAA,CAAY,UAAU;gBAC5D;gBACA,QAAQ,EAAE,MAAA;gBACV,UAAU,aAAa,EAAE,QAAA,EAAU,SAAS;gBAC5C,QAAQ,EAAE,MAAA;YACZ,CAAA,MAGN,KAAA;QACJ,OAAO,IAAI,KAAA,GACP;YACE,GAAG,IAAI,KAAA;YACP,KAAK,OAAO,WAAA,CACV,OAAO,OAAA,CAAQ,IAAI,KAAA,CAAM,GAAG,EAAE,GAAA,CAAI;oBAAC,CAAC,KAAK,GAAG,CAAA;uBAAM;oBAChD,QAAQ,GAAG;oBACX;iBACD;;QAEL,IACA,KAAA;QACJ,OAAO,IAAI,KAAA;QACX,OAAA,sBAAa,OAAA,8DAAS,GAAA,CAAI;gBAAC,CAAC,KAAK,GAAG,CAAA;mBAAM;gBAAC,QAAQ,GAAG;gBAAG,GAAG;aAAU;;IACxE;IAEA,OAAO;AACT;AAEA,SAAS,eACP,KAAA,EACA,KAAA,EACA,SAAA,EACW;IAEX,MAAM,EAAC,UAAA,CAAU,CAAA,GAAI;IACrB,MAAM,YAAY,CAAC,IACjB,EAAE,IAAA,KAAS,WAAW,IAAI;YAAC,GAAG,CAAA;YAAG,MAAM,WAAW,OAAO,EAAE,IAAI;QAAC;IAClE,MAAM,MAAM,CAACC,QAAe,MAAmB;QAC7C,MAAM,YAAY,EAAE,GAAA,CAAI,CAAA,MAAO,WAAWA,QAAO,GAAG,CAAC;QACrD,OAAO,gBAAgB,SAAS;IAClC;IAEA,IAAI,MAAM,IAAA,KAAS,UAAU;QAC3B,OAAO;YAAC,GAAG,KAAA;YAAO,MAAM,UAAU,MAAM,IAAI;QAAC;IAC/C,OAAA,IAAW,MAAM,IAAA,KAAS,sBAAsB;QAC9C,MAAM,EAAC,WAAA,EAAa,QAAA,CAAQ,CAAA,GAAI,MAAM,OAAA;QACtC,OAAO;YACL,GAAG,KAAA;YACH,SAAS;gBACP,GAAG,MAAM,OAAA;gBACT,aAAa;oBACX,aAAa,IAAI,OAAO,YAAY,WAAW;oBAC/C,YAAY,IAAI,SAAS,KAAA,EAAO,YAAY,UAAU;gBACxD;gBACA,UAAU,aAAa,UAAU,SAAS;YAC5C;QACF;IACF;IAEA,OAAO;QACL,MAAM,MAAM,IAAA;QACZ,YAAY,UAAU,UAAA,CACpB,MAAM,UAAA,CAAW,GAAA,CAAI,CAAA,IAAK,eAAe,GAAG,OAAO,SAAS,CAAC;IAEjE;AACF;AAEA,IAAM,iBAAiB,aAAA,GAAA,IAAI,QAA4B;AAEvD,IAAM,sBAAoC;IACxC,WAAW,CAAA,IAAK;IAChB,YAAY,CAAC,GAAG,IAAM;IACtB,SAAS;IACT,OAAO;IACP,YAAY,CAAA,IAAK,EAAE,IAAA,CAAK,YAAY;AACtC;AAEO,SAAS,aAAa,GAAA,EAAyB;IACpD,IAAI,aAAa,eAAe,GAAA,CAAI,GAAG;IACvC,IAAI,CAAC,YAAY;QACf,aAAa,aAAa,KAAK,mBAAmB;QAClD,eAAe,GAAA,CAAI,KAAK,UAAU;IACpC;IACA,OAAO;AACT;AAEO,SAAS,OAAO,GAAA,EAAU,MAAA,EAAoB;IACnD,OAAO,aAAa,KAAK;QACvB,WAAW,CAAA,QAAS,OAAO,SAAA,CAAU,KAAK;QAC1C,YAAY,CAAC,OAAO,MAAQ,OAAO,UAAA,CAAW,OAAO,GAAG;QACxD,SAAS,CAAA,IAAK;QACd,OAAO,CAAA,IAAK;QACZ,YAAY,CAAA,IAAK;IACnB,CAAC;AACH;AAEO,SAAS,aACd,IAAA,EACA,KAAA,EACA,MAAA,EACA;IACA,OAAO,eAAe,MAAM,OAAO;QACjC,WAAW,CAAAA,SAAS,OAAO,SAAA,CAAUA,MAAK;QAC1C,YAAY,CAACA,QAAO,MAAQ,OAAO,UAAA,CAAWA,QAAO,GAAG;QACxD,SAAS,CAAA,IAAK;QACd,OAAO,CAAA,IAAK;QACZ,YAAY,CAAA,IAAK;IACnB,CAAC;AACH;AAEA,SAAS,cACP,OAAA,EAC+B;IAC/B,OAAO,QAAQ,IAAA,CAAK,UAAU;AAChC;AAEA,SAAS,aAAa,CAAA,EAAc,CAAA,EAAsB;IACxD,IAAI,EAAE,IAAA,KAAS,UAAU;QACvB,IAAI,EAAE,IAAA,KAAS,UAAU;YACvB,OAAO,CAAA;QACT;QAEA,OACE,qBAAqB,EAAE,IAAA,EAAM,EAAE,IAAI,KACnC,qBAAqB,EAAE,EAAA,EAAI,EAAE,EAAE,KAC/B,qBAAqB,EAAE,KAAA,EAAO,EAAE,KAAK;IAEzC;IAEA,IAAI,EAAE,IAAA,KAAS,UAAU;QACvB,OAAO;IACT;IAEA,IAAI,EAAE,IAAA,KAAS,sBAAsB;QACnC,IAAI,EAAE,IAAA,KAAS,sBAAsB;YACnC,OAAO,CAAA;QACT;QACA,OAAO,WAAW,EAAE,OAAA,EAAS,EAAE,OAAO,KAAK,qBAAqB,EAAE,EAAA,EAAI,EAAE,EAAE;IAC5E;IACA,IAAI,EAAE,IAAA,KAAS,sBAAsB;QACnC,OAAO,CAAA;IACT;IAEA,MAAM,MAAM,qBAAqB,EAAE,IAAA,EAAM,EAAE,IAAI;IAC/C,IAAI,QAAQ,GAAG;QACb,OAAO;IACT;IACA,IAAA,IACM,IAAI,GAAG,IAAI,GACf,IAAI,EAAE,UAAA,CAAW,MAAA,IAAU,IAAI,EAAE,UAAA,CAAW,MAAA,EAC5C,KAAK,IACL;QACA,MAAMC,OAAM,aAAa,EAAE,UAAA,CAAW,CAAC,CAAA,EAAG,EAAE,UAAA,CAAW,CAAC,CAAC;QACzD,IAAIA,SAAQ,GAAG;YACb,OAAOA;QACT;IACF;IAEA,OAAO,EAAE,UAAA,CAAW,MAAA,GAAS,EAAE,UAAA,CAAW,MAAA;AAC5C;AAEA,SAAS,qBAAqB,CAAA,EAAkB,CAAA,EAA0B;IACxE,IAAI,EAAE,IAAA,KAAS,EAAE,IAAA,EAAM;QACrB,WAAOC,6NAAAA,EAAY,EAAE,IAAA,EAAM,EAAE,IAAI;IACnC;IACA,OAAQ,EAAE,IAAA,EAAM;QACd,KAAK;YACH,IAAA,mWAAA,EAAO,EAAE,IAAA,KAAS,SAAS;YAC3B,WAAOA,6NAAAA,EAAY,OAAO,EAAE,KAAK,GAAG,OAAO,EAAE,KAAK,CAAC;QACrD,KAAK;YACH,IAAA,mWAAA,EAAO,EAAE,IAAA,KAAS,QAAQ;YAC1B,WAAOA,6NAAAA,EAAY,EAAE,IAAA,EAAM,EAAE,IAAI;QACnC,KAAK;YACH,MAAM,IAAI,MACR;IAEN;AACF;AAEA,SAAS,WAAW,CAAA,EAAuB,CAAA,EAA+B;IACxE,WAAOA,6NAAAA,EAAY,KAAK,EAAE,QAAA,CAAS,KAAK,GAAG,KAAK,EAAE,QAAA,CAAS,KAAK,CAAC;AACnE;AAaA,SAAS,UAAU,IAAA,EAAwC;IACzD,IAAI,KAAK,IAAA,KAAS,YAAY,KAAK,IAAA,KAAS,sBAAsB;QAChE,OAAO;IACT;IACA,MAAM,aAAa,QACjB,KAAK,UAAA,CAAW,OAAA,CAAQ,CAAA,IACtB,EAAE,IAAA,KAAS,KAAK,IAAA,GAAO,EAAE,UAAA,CAAW,GAAA,CAAI,CAAAC,KAAK,UAAUA,EAAC,CAAC,IAAI,UAAU,CAAC;IAI5E,OAAQ,WAAW,MAAA,EAAQ;QACzB,KAAK;YACH,OAAO,KAAA;QACT,KAAK;YACH,OAAO,UAAA,CAAW,CAAC,CAAA;QACrB;YACE,OAAO;gBACL,MAAM,KAAK,IAAA;gBACX;YACF;IACJ;AACF;AAEA,SAAS,qBAAqB,CAAA,EAAkB,CAAA,EAA0B;IACxE,IAAI,MAAM,QAAQ,MAAM,MAAM;QAC5B,OAAOD,iOAAAA,EAAY,GAAG,CAAC;IACzB;IACA,IAAI,MAAM,MAAM;QACd,OAAO,CAAA;IACT;IACA,IAAI,MAAM,MAAM;QACd,OAAO;IACT;IACA,OAAO;AACT;;AG/jBA,IAAM,sBAAwB,eAAA,MAAA,CAAO;IACnC,gCAAgC;IAChC,uBAAuB;AACzB,CAAC;AAID,IAAM,wBAA0B,eAAA,MAAA,CAAO;IACrC,UAAY,eAAA,MAAA,CAAO;IACnB,SAAW,eAAA,MAAA,CAAO;IAAA,mDAAA;IAAA,oCAAA;IAGlB,KAAK,UAAU,QAAA,CAAS;IAAA,8BAAA;IAExB,MAAQ,eAAA,MAAA,CAAO,EAAE,QAAA,CAAS;IAAA,8BAAA;IAE1B,MAAQ,cAAc,UAAU,EAAE,QAAA,CAAS;IAC3C,KAAO,eAAA,OAAA,CAAQ;IACf,SAAW,eAAA,OAAA,CAAQ;IACnB,KAAO,eAAA,MAAA,CAAO;IACd,eAAiB,eAAA,MAAA,CAAO,EAAE,QAAA,CAAS;IACnC,UAAY,eAAA,MAAA,CAAO;IACnB,SAAS,oBAAoB,QAAA,CAAS,EAAE,QAAA,CAAS;AACnD,CAAC;AAID,IAAM,wBAA0B,eAAA,MAAA,CAAO;IACrC,IAAM,eAAA,MAAA,CAAO;AACf,CAAC;AAEM,IAAM,2BAA2B,sBAAsB,MAAA,CAAO;IACnE,IAAM,eAAA,OAAA,CAAQ,SAAS;IACvB,OAAS,eAAA,KAAA,CAAM,qBAAqB;AACtC,CAAC;AAIM,IAAM,2BAA2B,sBAAsB,MAAA,CAAO;IACnE,IAAM,eAAA,OAAA,CAAQ,SAAS;IACvB,OAAO;AACT,CAAC;AAIM,IAAM,2BAA2B,sBAAsB,MAAA,CAAO;IACnE,IAAM,eAAA,OAAA,CAAQ,SAAS;IACvB,OAAS,eAAA,MAAA,CAAO;AAClB,CAAC;AAEM,IAAM,wBAA0B,eAAA,KAAA,CACrC,0BACA,0BACA;AAGK,IAAM,2BAA6B,eAAA,KAAA,CAAM;IAC5C,eAAA,OAAA,CAAQ,SAAS;IACnB;CACD;;AChEM,SAAS,yBAAyBE,MAAAA,EAAmB;IAC1D,IAAIA,WAAU,MAAM;QAClB,MAAM,IAAI,UAAU,sBAAsB;IAC5C;IAGA,IAAA,IAAS,IAAI,GAAG,IAAIA,OAAM,MAAA,EAAQ,IAAK;QACrCA,MAAAA,CAAM,CAAC,CAAA,GAAI,KAAK,KAAA,CAAM,KAAK,MAAA,CAAO,IAAI,GAAG;IAC3C;IAEA,OAAOA;AACT;;ACHO,SAAS;eAAO,iEAAO,IAAY;IAExC,MAAM,cAAc,yBAAyB,IAAI,WAAW,IAAI,CAAC;IAEjE,OAAO,YAAY,MAAA,CAAO,CAAC,IAAI,SAAS;QAMtC,QAAQ;QACR,IAAI,OAAO,IAAI;YAEb,MAAM,KAAK,QAAA,CAAS,EAAE;QACxB,OAAA,IAAW,OAAO,IAAI;YAEpB,MAAA,CAAO,OAAO,EAAA,EAAI,QAAA,CAAS,EAAE,EAAE,WAAA,CAAY;QAC7C,OAAA,IAAW,OAAO,IAAI;YACpB,MAAM;QACR,OAAO;YACL,MAAM;QACR;QACA,OAAO;IACT,GAAG,EAAE;AACP;;AC7BO,IAAM,MAAM,CAAC,IAAc,KAAK,GAAG,CAAC;AACpC,IAAM,OAAO,CAAC,IAAc,KAAK,GAAG,CAAC;AAM5C,SAAS,KAAK,GAAA,EAAa,KAAA,EAAuB;IAChD,IAAIC,QAAO,EAAA;IACX,IAAA,IAAS,IAAI,GAAG,IAAI,OAAO,IAAK;QAC9BA,QAAAA,CAAQA,SAAQ,GAAA,IAAO,OAAO,mOAAA,EAAS,KAAK,CAAC,CAAC;IAChD;IACA,OAAOA;AACT;;ACdO,IAAM,mBAAqB,SAC9B,eAAA,KAAA,CAAM;IAAG,eAAA,MAAA,CAAO,CAAC;CAAC,EAAE,MAAA,CAAS,eAAA,KAAA,CAAQ,eAAA,MAAA,CAAO,CAAC,CAAC;AAK3C,IAAM,wBAA0B,eAAA,KAAA,CACnC,eAAA,MAAA,CAAO,GACP,eAAA,MAAA,CAAO,GACP,eAAA,OAAA,CAAQ;AAKL,IAAM,8BAAgC,eAC3C;;ACVK,IAAM,6BAA6B;AACnC,IAAM,yBAAyB;AAC/B,IAAM,sBAAsB;AAC5B,IAAM,uBAAuB;AAE7B,SAAS,oBAAoB,QAAA,EAAkBC,KAAAA,EAAsB;IAC1E,OAAO,6BAA6B,WAAW,MAAMA;AACvD;AAEO,SAAS,8BAA8B,QAAA,EAA0B;IACtE,OAAO,6BAA6B,WAAW;AACjD;AAEO,SAAS,gBAAgBA,KAAAA,EAAsB;IACpD,OAAO,yBAAyBA;AAClC;AAEO,SAAS,sBAAsB,GAAA,EAAyB;IAC7D,OAAO,uBAAuB,IAAI,QAAA,GAAW,MAAM,IAAI,EAAA;AACzD;AAEO,SAAS,mBACd,SAAA,EACA,UAAA,EACA,KAAA,EACQ;IACR,IAAI,WAAW,MAAA,KAAW,GAAG;QAC3B,OACE,sBACA,YACA,MACE,MAAM,KAAA,CAAM,UAAA,CAAW,CAAC,CAAC,CAAA,EAAG,qBAAqB;IAEvD;IAEA,MAAM,SAAS,WAAW,GAAA,CAAI,CAAA,IAAO,MAAM,KAAA,CAAM,CAAC,CAAA,EAAG,qBAAqB,CAAC;IAC3E,MAAM,MAAM,KAAK,SAAA,CAAU,MAAM;IAEjC,MAAM,YAAY,KAAK,GAAG;IAC1B,OAAO,sBAAsB,YAAY,MAAM;AACjD;AAEO,SAAS,kBAAkB,GAAA,EAAqB;IACrD,MAAM,QAAQ,IAAI,OAAA,CAAQ,KAAK,oBAAoB,MAAM;IACzD,OAAO,IAAI,KAAA,CAAM,oBAAoB,MAAA,EAAQ,KAAK;AACpD;;AChDO,IAAM,WAAN,MAAe;IASpB,IAAI,CAAA,EAAmB;QACrB,IAAI,EAAE,MAAA,GAAS,GAAG;YAChB,MAAM,IAAI,MAAM,0CAA0C;QAC5D;QACA,IAAI,IAAA,CAAK,MAAA,KAAW,GAAG;YACrB,IAAA,CAAK,MAAA,IAAU,EAAE,MAAA;YACjB,IAAA,CAAK,IAAA,IAAS,EAAE,MAAA,GAAA,CAAU,EAAE,IAAA,GAAO,IAAA,CAAK,IAAA,IAAS,IAAA,CAAK,MAAA;QACxD,OAAO;YACL,IAAA,CAAK,MAAA,GAAS,EAAE,MAAA;YAChB,IAAA,CAAK,IAAA,GAAO,EAAE,IAAA;QAChB;IACF;IAhBA,YAAY,IAAA,EAAc,MAAA,CAAgB;kQAH1C;oQACA;QAGE,IAAA,CAAK,IAAA,GAAO;QACZ,IAAA,CAAK,MAAA,GAAS;IAChB;AAcF;AAKO,SAAS,iBAAiB,SAAA,EAA+B;IAC9D,UAAU,IAAA,CAAK,CAAC,GAAG,IAAM,EAAE,IAAA,GAAO,EAAE,IAAI;AAC1C;;ACjBO,IAAM,slBAAN,MAAM,SAAQ;IAkBnB;;;GAAA,GAMA,OAAO,SAAS,IAAA,EAAsC;QACpD,MAAM,SAAS,IAAI,SAAQ,IAAA,CAAK,CAAC,CAAC;QAClC,IAAI,KAAK,MAAA,GAAS,MAAM,GAAG;YACzB,MAAM,IAAI,MAAM,yBAAyB;QAC3C;QACA,IAAA,IAAS,IAAI,GAAG,IAAI,KAAK,MAAA,EAAQ,KAAK,EAAG;YACvC,OAAO,GAAA,CAAI,IAAA,CAAK,CAAC,CAAA,EAAG,IAAA,CAAK,IAAI,CAAC,CAAC;QACjC;QACA,OAAO;IACT;IAEA,QAAc;6PACP,YAAa,CAAC,CAAA;6PACd,cAAe,CAAC,CAAA;6PAChB,aAAc,CAAC,CAAA;6PACf,kBAAmB;6PACnB,oBAAqB;6PACrB,MAAO,OAAO,SAAA;6PACd,MAAO,CAAC,OAAO,SAAA;IACtB;IAEA,IAAI,IAAA,EAAkC;qBAApB,iEAAiB;QACjC,IAAA,CAAK,WAAA,CAAY,IAAI,SAAS,MAAM,MAAM,CAAC;IAC7C;IAAA,wDAAA,GAGA,gBAAgB,YAAA,EAA4B;QAC1C,KAAA,MAAW,KAAK,aAAc;YAC5B,IAAA,CAAK,WAAA,CAAY,CAAC;QACpB;IACF;IAAA;;;GAAA,GAMA,YAAY,CAAA,EAAmB;QAC7B,IACE,OAAO,KAAA,CAAM,EAAE,IAAI,KACnB,EAAE,MAAA,IAAU,KACZ,OAAO,KAAA,CAAM,EAAE,MAAM,KACrB,CAAC,OAAO,QAAA,CAAS,EAAE,MAAM,GACzB;YACA;QACF;QAEA,+OAAA,IAAA,EAAK,cAAa,IAAA,CAAK,IAAI,SAAS,EAAE,IAAA,EAAM,EAAE,MAAM,CAAC;ggBACrD,IAAA,EAAK,sBAAsB,EAAE,MAAA;QAE7B,mPACE,IAAA,EAAK,YAAW,MAAA,kPAAS,IAAA,EAAK,iQAC9B,IAAA,EAAK,cAAa,MAAA,kPAAS,IAAA,EAAK,kBAChC;YACA,gPAAA,IAAA,YAAK,SAAS,KAAd,IAAA;QACF;IACF;IAAA;;;;IAAA,GAOA,MAAM,EAAA,EAAa;QACjB,gPAAA,cAAG,SAAS,KAAZ;QACA,IAAA,CAAK,eAAA,gPAAgB,IAAG,UAAU;IACpC;IAuCA;;;;;;GAAA,GASA,YAA+C;iBAArC,iEAAmB,CAAC,CAAA;QAC5B,gPAAA,IAAA,YAAK,SAAS,KAAd,IAAA;QACA,OAAO,GAAG,MAAA,gPAAO,IAAA,EAAK,UAAU;IAClC;IAEA,QAAgB;QACd,gPAAA,IAAA,YAAK,SAAS,KAAd,IAAA;QAIA,sPAAO,IAAA,EAAK;IACd;IAAA;;;GAAA,GAMA,SAAsB;QACpB,gPAAA,IAAA,YAAK,SAAS,KAAd,IAAA;QACA,MAAM,OAAoB;YAAC,IAAA,CAAK,WAAW;SAAA;QAC3C,KAAA,MAAW,2PAAY,IAAA,EAAK,YAAY;YACtC,KAAK,IAAA,CAAK,SAAS,IAAA,EAAM,SAAS,MAAM;QAC1C;QACA,OAAO;IACT;IAyBA,iDAAA;IAAA,+DAAA;IAAA,8CAAA;IAKA,SAAS,CAAA,EAAmB;QAC1B,gPAAA,IAAA,YAAK,SAAS,KAAd,IAAA;QACA,gPAAA,IAAA,qBAAK,kBAAkB,KAAvB,IAAA;QACA,IAAI,IAAI,KAAK,IAAI,oPAAK,IAAA,EAAK,YAAW,MAAA,KAAW,GAAG;YAClD,OAAO;QACT;QACA,IAAI,mPAAA,EAAK,YAAW,MAAA,KAAW,GAAG;YAChC,sPAAO,IAAA,EAAK,WAAA,CAAW,CAAC,CAAA,CAAE,IAAA;QAC5B;QACA,MAAM,QAAQ,mPAAI,IAAA,EAAK;QACvB,IAAI,wPAAS,IAAA,EAAK,WAAA,CAAW,CAAC,CAAA,CAAE,MAAA,GAAS,GAAG;YAC1C,sPACE,IAAA,EAAK,QACH,IAAI,uPAAS,IAAA,EAAK,WAAA,CAAW,CAAC,CAAA,CAAE,MAAA,GAAA,gPAC/B,IAAA,EAAK,WAAA,CAAW,CAAC,CAAA,CAAE,IAAA,kPAAO,IAAA,EAAK,KAAA;QAEtC;QAEA,MAAM,QAAQ,4PACZ,IAAA,EAAK,aAAY,MAAA,EACjB,CAAC,IAAc,gPAAC,IAAA,EAAK,YAAA,CAAY,CAAC,CAAA,GAAI;QAGxC,IAAI,QAAQ,qPAAM,IAAA,EAAK,aAAY,MAAA,EAAQ;YACzC,MAAMC,MAAK,QAAQ,mPAAA,EAAK,YAAA,CAAY,QAAQ,CAAC,CAAA;YAC7C,MAAMC,qPAAK,IAAA,EAAK,YAAA,CAAY,KAAK,CAAA,GAAI;YACrC,OAAO,+PACL,IAAA,EAAK,WAAA,CAAW,QAAQ,CAAC,CAAA,CAAE,IAAA,EAC3BA,oPACA,IAAA,EAAK,WAAA,CAAW,KAAK,CAAA,CAAE,IAAA,EACvBD;QAEJ;QAEA,MAAM,KACJ,uPAAQ,IAAA,EAAK,mQAAmB,IAAA,EAAK,WAAA,CAAW,QAAQ,CAAC,CAAA,CAAE,MAAA,GAAS;QACtE,MAAM,oPAAK,IAAA,EAAK,WAAA,CAAW,QAAQ,CAAC,CAAA,CAAE,MAAA,GAAS,IAAI;QACnD,OAAO,+PACL,IAAA,EAAK,WAAA,gPAAW,IAAA,EAAK,YAAW,MAAA,GAAS,CAAC,CAAA,CAAE,IAAA,EAC5C,mPACA,IAAA,EAAK,OACL;IAEJ;IAAA;;GAAA,GAKA,IAAI,CAAA,EAAmB;QACrB,gPAAA,IAAA,YAAK,SAAS,KAAd,IAAA;QACA,gPAAA,IAAA,qBAAK,kBAAkB,KAAvB,IAAA;QACA,sPAAQ,IAAA,EAAK,YAAW,MAAA,EAAQ;YAC9B,KAAK;gBACH,OAAO;YACT,KAAK;gBAAG;oBACN,MAAM,uPAAQ,IAAA,EAAK,uPAAO,IAAA,EAAK;oBAC/B,IAAI,oPAAK,IAAA,EAAK,OAAM;wBAClB,OAAO;oBACT;oBACA,IAAI,oPAAK,IAAA,EAAK,OAAM;wBAClB,OAAO;oBACT;oBACA,IAAI,mPAAI,IAAA,EAAK,SAAQ,OAAO;wBAE1B,OAAO;oBACT;oBACA,OAAA,CAAQ,mPAAI,IAAA,EAAK,KAAA,IAAQ;gBAC3B;QACF;QAEA,IAAI,oPAAK,IAAA,EAAK,OAAM;YAClB,OAAO;QACT;QACA,IAAI,oPAAK,IAAA,EAAK,OAAM;YAClB,OAAO;QACT;QACA,MAAM,oPAAK,IAAA,EAAK,WAAA,CAAW,CAAC,CAAA,CAAE,IAAA;QAE9B,IAAI,KAAK,IAAI;YACX,IAAI,oPAAK,IAAA,EAAK,QAAO,GAAG;gBACtB,OAAA,CACK,mPAAI,IAAA,EAAK,KAAA,IAAA,CAAS,oPAAK,IAAA,EAAK,KAAA,mPAAS,IAAA,EAAK,WAAA,CAAW,CAAC,CAAA,CAAE,MAAA,kPAC3D,IAAA,EAAK,oBACL;YAEJ;YACA,OAAO;QACT;QAEA,MAAM,oPAAK,IAAA,EAAK,WAAA,gPAAW,IAAA,EAAK,YAAW,MAAA,GAAS,CAAC,CAAA,CAAE,IAAA;QACvD,IAAI,KAAK,IAAI;YACX,mPAAI,IAAA,EAAK,QAAO,KAAK,GAAG;gBACtB,OACE,IAAA,gPACG,IAAA,EAAK,QAAO,CAAA,IAAA,CAAM,mPAAA,EAAK,QAAO,EAAA,mPAC/B,IAAA,EAAK,WAAA,gPAAW,IAAA,EAAK,YAAW,MAAA,GAAS,CAAC,CAAA,CAAE,MAAA,kPAC5C,IAAA,EAAK,oBACL;YAEN;YACA,OAAO;QACT;QAEA,MAAM,QAAQ,4PACZ,IAAA,EAAK,YAAW,MAAA,EAAA,8DAAA;QAAA,yBAAA;QAAA,+CAAA;QAIhB,CAAA,IAAK,mPAAI,IAAA,EAAK,WAAA,CAAW,CAAC,CAAA,CAAE,IAAA,IAAQ;QAGtC,MAAM,KAAK,mPAAI,IAAA,EAAK,WAAA,CAAW,QAAQ,CAAC,CAAA,CAAE,IAAA;QAC1C,MAAM,oPAAK,IAAA,EAAK,WAAA,CAAW,KAAK,CAAA,CAAE,IAAA,GAAO;QACzC,OACE,+PACE,IAAA,EAAK,YAAA,CAAY,QAAQ,CAAC,CAAA,EAC1B,mPACA,IAAA,EAAK,YAAA,CAAY,KAAK,CAAA,EACtB,qPACE,IAAA,EAAK;IAEb;IA3SA,YAAY,cAAsB,GAAA,CAAM;+PA8ExC,WAAW;;;;yQA1FF;;;;;;;wBAGT;;;;wBACA;;;;wBACA;;;;wBACA;;;;mBACA;;;;wBACA;;8PACA;;;;;;;;QAIE,IAAA,CAAK,WAAA,GAAc;6PACd,eAAgB,cAAc,GAAG,IAAA,CAAK,WAAW;6PACjD,iBAAkB,gBAAgB,GAAG,IAAA,CAAK,WAAW;QAC1D,IAAA,CAAK,KAAA,CAAM;IACb;AAsTF;AA0BA,SAAS,gBACP,EAAA,EACA,EAAA,EACA,EAAA,EACA,EAAA,EACQ;IACR,IAAI,MAAM,IAAI;QACZ,OAAO,sBAAsB,IAAI,IAAI,IAAI,EAAE;IAC7C;IACA,OAAO,sBAAsB,IAAI,IAAI,IAAI,EAAE;AAC7C;AAEA,SAAS,sBACP,EAAA,EACA,EAAA,EACA,EAAA,EACA,EAAA,EACQ;IACR,MAAM,IAAA,CAAK,KAAK,KAAK,KAAK,EAAA,IAAA,CAAO,KAAK,EAAA;IACtC,OAAO,KAAK,GAAA,CAAI,IAAI,KAAK,GAAA,CAAI,GAAG,EAAE,CAAC;AACrC;AAEA,SAAS,cAAc,IAAA,EAAc,WAAA,EAA6B;IAChE,IAAI,SAAS,GAAG;QACd,OAAO,KAAK,IAAA,CAAK,WAAW,IAAI;IAClC;IACA,OAAO;AACT;AAEA,SAAS,gBAAgB,IAAA,EAAc,WAAA,EAA6B;IAClE,IAAI,SAAS,GAAG;QACd,OAAO,KAAK,IAAA,CAAK,WAAW,IAAI;IAClC;IACA,OAAO;AACT;;ACzSO,SAAS,SAAS,CAAA,EAA6C;IACpE,OAAO,EAAE,MAAA,KAAW;AACtB;AAEO,SAAS,SACd,CAAA,EACwC;IACxC,OAAO,EAAE,MAAA,KAAW;AACtB;;AC5EO,IAAM,iBAAiB,OAAO,UAAU;;;AEnC/C,IAAM,YAAY,aAAA,GAAA,IAAI,QAAqB;AAEpC,SAAS,UAAU,GAAA,EAAkB;IAC1C,MAAM,aAAa,aAAa,GAAG;IACnC,MAAM,SAAS,UAAU,GAAA,CAAI,UAAU;IACvC,IAAI,QAAQ;QACV,OAAO;IACT;IACA,MAAME,QAAO,IAAI,KAAK,SAAA,CAAU,UAAU,CAAC,EAAE,QAAA,CAAS,EAAE;IACxD,UAAU,GAAA,CAAI,YAAYA,KAAI;IAC9B,OAAOA;AACT;AAEO,SAAS,kBACd,IAAA,EACA,IAAA,EACQ;IACR,MAAM,aAAa,KAAK,SAAA,CAAU,IAAI;IACtC,OAAO,IAAI,UAAG,IAAI,EAAA,KAAc,CAAE,MAAZ,UAAU,GAAI,QAAA,CAAS,EAAE;AACjD;;ACoBO,IAAM,oBAAkC;IAC7C,MAAK,OAAA,EAAuB;QAC1B,MAAM,IAAI,MAAM,gBAAgB;IAClC;IAEA,QAAO,KAAA,EAAa,QAAA,EAAmB;QACrC,MAAM,IAAI,MAAM,gBAAgB;IAClC;AACF;AAEO,IAAM,4FAAN,MAAiD;IAStD,gBAAgB,MAAA,EAAsB;6PAC/B,SAAU;IACjB;IAEA,UAAgB;QACd,+OAAA,IAAA,EAAK,QAAO,OAAA,CAAQ;IACtB;IAEA,YAA0B;QACxB,sPAAO,IAAA,EAAK,QAAO,SAAA,CAAU;IAC/B;IAEA,KAAK,MAAA,EAAgB;QACnB,+OAAA,IAAA,EAAK,SAAQ,IAAA,CAAK,MAAM;IAC1B;IAEA,CAAC,MAAM,GAAA,EAAiC;QACtC,KAAA,MAAW,uPAAQ,IAAA,EAAK,QAAO,KAAA,CAAM,GAAG,EAAG;YACzC,mPAAI,IAAA,EAAK,SAAQ,MAAA,CAAO,MAAM,KAAK,GAAG;gBACpC,MAAM;YACR;QACF;IACF;IAEA,CAAC,QAAQ,GAAA,EAAiC;QACxC,KAAA,MAAW,QAAQ,mPAAA,EAAK,QAAO,OAAA,CAAQ,GAAG,EAAG;YAC3C,mPAAI,IAAA,EAAK,SAAQ,MAAA,CAAO,MAAM,IAAI,GAAG;gBACnC,MAAM;YACR,OAAO;gBACL,aAAa,IAAI;YACnB;QACF;IACF;IArCA,YAAY,KAAA,CAAc;;;;;8PAF1B;;mBAAwB;;6PAGjB,QAAS;QACd,MAAM,SAAA,CAAU,IAAI;IACtB;AAmCF;AAEO,IAAM,kIAAN,MAA+C;IAYpD,CAAC,MAAM,GAAA,EAAiC;QACtC,KAAA,MAAW,uPAAQ,IAAA,EAAK,QAAO,KAAA,CAAM,GAAG,EAAG;YACzC,MAAM;QACR;IACF;IAEA,CAAC,QAAQ,GAAA,EAAiC;QACxC,KAAA,MAAW,uPAAQ,IAAA,EAAK,QAAO,OAAA,CAAQ,GAAG,EAAG;YAC3C,MAAM;QACR;IACF;IAEA,OAAO,KAAA,EAAa,QAAA,EAAmB;QACrC,OAAO;IACT;IAEA,UAAU,MAAA,EAAgB;6PACnB,UAAU;IACjB;IAEA,UAAgB;QACd,+OAAA,IAAA,EAAK,SAAO,OAAA,CAAQ;IACtB;IAEA,YAA0B;QACxB,sPAAO,IAAA,EAAK,SAAO,SAAA,CAAU;IAC/B;IAEA,KAAK,MAAA,EAAgB;QACnB,+OAAA,IAAA,EAAK,UAAQ,IAAA,CAAK,MAAM;IAC1B;IApCA,YAAY,KAAA,EAAoB,KAAA,CAAoB;;;wBAL3C;;;;wBACA;;8PAET;;mBAAkB;;6PAGX,QAAS;6PACT,SAAS;QACd,MAAM,eAAA,CAAgB,IAAI;IAC5B;AAiCF;AAEO,SAAS,oBACd,KAAA,EACA,QAAA,EACA,QAAA,EACO;IACP,MAAM,cAAc,IAAI,YAAY,KAAK;IACzC,SAAS,OAAA,CAAQ,OAAO,WAAW;IACnC,MAAM,SAAS,SAAS,WAAW;IACnC,SAAS,OAAA,CAAQ,aAAa,MAAM;IACpC,MAAM,YAAY,IAAI,UAAU,aAAa,MAAM;IACnD,SAAS,OAAA,CAAQ,QAAQ,SAAS;IAClC,OAAO;AACT;;ACxEO,IAAM,cAAsB;IACjC,MAAK,OAAA,EAAuB;QAC1B,MAAM,IAAI,MAAM,gBAAgB;IAClC;AACF;;AC5EO,UAAU,KAAQ,MAAA,EAAmB,KAAA,EAA0B;IACpE,IAAI,QAAQ,GAAG;QACb;IACF;IACA,IAAI,QAAQ;IACZ,KAAA,MAAWC,MAAK,OAAQ;QACtB,MAAMA;QACN,IAAI,EAAE,UAAU,OAAO;YACrB;QACF;IACF;AACF;AAEO,SAAS,MAAS,MAAA,EAAkC;QAGzD;IAFA,MAAM,KAAK,MAAA,CAAO,OAAO,QAAQ,CAAA,CAAE;IACnC,MAAM,EAAC,KAAA,CAAK,CAAA,GAAI,GAAG,IAAA,CAAK;KACxB,aAAA,GAAG,MAAA,GAAS,WAAZ,iCAAA,gBAAA;IACA,OAAO;AACT;;ACcO,IAAM,UACF,uCACA,iDACA,4EAEA,8CACA,4CAET,wCAUA,ifAlBK,MAAuC;IA6C5C,gBAAgB,MAAA,EAA4B;6PACrC,UAAU;IACjB;IAEA,OAAO,IAAA,EAAY,OAAA,EAA2B;QAC5C,MAAM,6PAAS,WAAK,aAAL,IAAA,EAAa,IAAI,oPAAK,IAAA,EAAK,UAAQ,MAAA,CAAO,MAAM,OAAO;QACtE,IAAI,SAAS;YACX,gPAAA,IAAA,YAAK,cAAL,IAAA,EAAc,IAAI;QACpB;QACA,OAAO;IACT;IAEA,UAAgB;QACd,+OAAA,IAAA,EAAK,SAAO,OAAA,CAAQ;IACtB;IAEA,YAA0B;QACxB,sPAAO,IAAA,EAAK,SAAO,SAAA,CAAU;IAC/B;IAEA,KAAK,MAAA,EAAgB;QACnB,IAAA,mWAAA,EAAO,gPAAC,IAAA,EAAK,UAAS,wBAAwB;6PACzC,SAAU;QACf,IAAI;YACF,OAAQ,OAAO,IAAA,EAAM;gBAAA,qDAAA;gBAAA,iEAAA;gBAGnB,KAAK;gBACL,KAAK;oBAAQ;wBACX,gPAAA,IAAA,mBAAK,qBAAL,IAAA,EAAqB,MAAM;wBAC3B;oBACF;gBACA,KAAK;oBAAU;wBACb,MAAM,2PAAO,EAAK,wBAAL,IAAA,EAAc,OAAO,IAAI;wBAItC,IAAI,SAAS,KAAA,GAAW;4BACtB;wBACF;wBACA,gPAAA,IAAA,EAAK,sCAAL,IAAA,EAAqB,QAAQ,IAAI;wBACjC,gPAAA,IAAA,YAAK,cAAL,IAAA,EAAc,OAAO,IAAI;wBACzB;oBACF;gBACA,KAAK;oBAKH,IACE,OAAO,KAAA,CAAM,gBAAA,oPAAqB,IAAA,EAAK,sBACvC,OAAO,KAAA,CAAM,MAAA,CAAO,IAAA,KAAS,UAC7B,OAAO,KAAA,CAAM,MAAA,CAAO,IAAA,KAAS,SAC7B;wBACA,gPAAA,IAAA,mBAAK,qBAAL,IAAA,EAAqB,MAAM;wBAC3B;oBACF;oBACA,OAAQ,OAAO,KAAA,CAAM,MAAA,CAAO,IAAA,EAAM;wBAChC,KAAK;4BAAO;gCACV,IAAI,uPAAO,IAAA,YAAK,kBAAL,EAAc,OAAO,IAAI;gCACpC,IAAI,SAAS,KAAA,GAAW;oCACtB;oCACA,gPAAA,IAAA,YAAK,cAAL,IAAA,EAAc,OAAO,IAAA,EAAM,IAAI;gCACjC,OAAO;oCACL,2PAAO,cAAK,gBAAL,IAAA,EAAgB,OAAO,IAAI;gCACpC;gCACA,IAAI,SAAS,GAAG;oCACd,mPAAI,IAAA,EAAK,OAAM;wCAKb,+OAAA,IAAA,EAAK,UAAQ,IAAA,CAAK;4CAChB,MAAM;4CACN,MAAM;gDACJ,KAAK,OAAO,IAAA,CAAK,GAAA;gDACjB,eAAe;oDACb,GAAG,OAAO,IAAA,CAAK,aAAA;oDACf,gPAAC,IAAA,EAAK,iBAAiB,EAAA,EAAG,IAAM,CAAC,CAAA;gDACnC;4CACF;wCACF,CAAC;oCACH,OAAO;wCACL,+OAAA,IAAA,EAAK,UAAQ,IAAA,CAAK;4CAChB,MAAM;4CACN,MAAM,OAAO,IAAA;wCACf,CAAC;oCACH;gCACF,OAAO;oCACL,gPAAA,IAAA,mBAAK,qBAAL,IAAA,EAAqB,QAAQ,IAAI;gCACnC;gCACA;4BACF;wBACA,KAAK;4BAAU;gCACb,IAAI,2PAAO,YAAK,cAAL,IAAA,EAAc,OAAO,IAAI;gCACpC,IAAI,SAAS,KAAA,GAAW;oCACtB,IAAA,mWAAA,EAAO,OAAO,CAAC;oCACf;oCACA,gPAAA,IAAA,YAAK,cAAL,IAAA,EAAc,OAAO,IAAA,EAAM,IAAI;gCACjC,OAAO;oCACL,2PAAO,cAAK,gBAAL,IAAA,EAAgB,OAAO,IAAI;gCACpC;gCACA,IAAI,SAAS,GAAG;oCACd,mPAAI,IAAA,EAAK,OAAM;wCACb,+OAAA,IAAA,EAAK,UAAQ,IAAA,CAAK;4CAChB,MAAM;4CACN,MAAM,OAAO,IAAA;wCACf,CAAC;oCACH,OAAO;wCAIL,+OAAA,IAAA,EAAK,UAAQ,IAAA,CAAK;4CAChB,MAAM;4CACN,MAAM;gDACJ,KAAK,OAAO,IAAA,CAAK,GAAA;gDACjB,eAAe;oDACb,GAAG,OAAO,IAAA,CAAK,aAAA;oDACf,gPAAC,IAAA,EAAK,iBAAiB,EAAA,EAAG,IAAM;4DAC9B,OAAO,KAAA,CAAM,MAAA,CAAO,IAAA;yDACtB;gDACF;4CACF;wCACF,CAAC;oCACH;gCACF,OAAO;oCACL,gPAAA,IAAA,mBAAK,qBAAL,IAAA,EAAqB,QAAQ,IAAI;gCACnC;gCACA;4BACF;oBACF;oBACA;gBACF;oBACE,IAAA,wWAAA,EAAY,MAAM;YACtB;QACF,SAAE;iQACK,SAAU;QACjB;IACF;IAnKA,YACE,KAAA,EACA,OAAA,EACA,gBAAA,EACA,aAAA,EACA,IAAA,CACA;;;;;;+PAkMF;;+PAgCA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;mBApPwB;;;;mBAUd;;6PASH,SAAS;6PACT,mBAAoB;QACzB,+OAAA,IAAA,EAAK,SAAO,eAAA,CAAgB,IAAI;6PAC3B,UAAW;QAChB,IAAA,mWAAA,iPACE,IAAA,EAAK,SAAO,SAAA,CAAU,EAAE,aAAA,CAAc,gBAAgB,CAAA,EACtD,wBAAwC,OAAhB,gBAAgB;6PAErC,MAAO,SAAS;6PAChB,gBAAiB;6PAGjB,cAAe,SAClB,eACA,mPAAA,EAAK,SAAO,SAAA,CAAU,EAAE,UAAA;IAE5B;AAsOF;;AC/RO,IAAM,iLAAN,MAAsC;IAe3C,gBAAgB,MAAA,EAA4B;6PACrC,UAAU;IACjB;IAEA,UAAgB;QACd,KAAA,MAAW,wPAAS,IAAA,EAAK,SAAS;YAChC,MAAM,OAAA,CAAQ;QAChB;IACF;IAEA,YAAY;QACV,sPAAO,IAAA,EAAK;IACd;IAEA,OAAO,IAAA,EAAY,OAAA,EAA2B;QAC5C,sPAAO,IAAA,EAAK,UAAQ,MAAA,CAAO,MAAM,OAAO;IAC1C;IAEA,KAAK,MAAA,EAAgB;QACnB,+OAAA,IAAA,EAAK,oBAAmB,IAAA,CAAK,MAAM;IACrC;IAEA,+BAA+B,gBAAA,EAAkC;QAC/D,mPAAI,IAAA,EAAK,SAAQ,MAAA,KAAW,GAAG;YAC7B,IAAA,mWAAA,iPACE,IAAA,EAAK,oBAAmB,MAAA,KAAW,GACnC;YAEF;QACF;QAEA,mPAAI,IAAA,EAAK,oBAAmB,MAAA,KAAW,GAAG;YAGxC;QACF;QAGA,MAAM,mBAAmB,aAAA,GAAA,IAAI,IAA4B;QACzD,KAAA,MAAW,yPAAU,IAAA,EAAK,oBAAoB;YAC5C,IAAI,qBAAqB,WAAW,OAAO,IAAA,KAAS,SAAS;gBAC3D,IAAA,mWAAA,EACE,iBAAiB,GAAA,CAAI,OAAO,IAAI,MAAM,OACtC,IACE,qCAAgD,OAAX,OAAO,IAAI,EAAA;YAEtD;YACA,iBAAiB,GAAA,CAAI,OAAO,IAAA,EAAM,MAAM;QAC1C;6PAEK,oBAAqB,CAAC,CAAA;QAE3B,MAAM,QAAQ,CAAC;eAAG,iBAAiB,IAAA,CAAK,CAAC;SAAA;QASzC,OAAQ,kBAAkB;YACxB,KAAK;gBACH,IAAA,mWAAA,EACE,MAAM,MAAA,KAAW,KAAK,KAAA,CAAM,CAAC,CAAA,KAAM,UACnC;gBAEF,+OAAA,IAAA,EAAK,UAAQ,IAAA,CAAK,KAAK,iBAAiB,GAAA,CAAI,QAAQ,CAAC,CAAC;gBACtD;YACF,KAAK;gBACH,IAAA,mWAAA,EACE,MAAM,MAAA,KAAW,KAAK,KAAA,CAAM,CAAC,CAAA,KAAM,OACnC;gBAEF,+OAAA,IAAA,EAAK,UAAQ,IAAA,CAAK,KAAK,iBAAiB,GAAA,CAAI,KAAK,CAAC,CAAC;gBACnD;YACF,KAAK;gBAAQ;oBACX,IAAA,mWAAA,EACE,MAAM,KAAA,CACJ,CAAA,OAAQ,SAAS,SAAS,SAAS,YAAY,SAAS,SAE1D;oBAEF,MAAM,YAAY,iBAAiB,GAAA,CAAI,KAAK;oBAC5C,MAAM,eAAe,iBAAiB,GAAA,CAAI,QAAQ;oBAClD,MAAM,aAAa,iBAAiB,GAAA,CAAI,MAAM;oBAI9C,IAAI,YAAY;wBACd,+OAAA,IAAA,EAAK,UAAQ,IAAA,CAAK,UAAU;wBAC5B;oBACF;oBAmBA,IAAI,aAAa,cAAc;wBAC7B,+OAAA,IAAA,EAAK,UAAQ,IAAA,CAAK;4BAChB,MAAM;4BACN,MAAM,UAAU,IAAA;4BAChB,SAAS,aAAa,IAAA;wBACxB,CAAU;wBACV;oBACF;oBAEA,+OAAA,IAAA,EAAK,UAAQ,IAAA,CAAK,kDAAK,YAAa,YAAY,CAAC;oBACjD;gBACF;YACA,KAAK;gBAAS;oBACZ,IAAA,mWAAA,EACE,MAAM,KAAA,CACJ,CAAA,OACE,SAAS,SAAA,2CAAA;wBACT,SAAS,YAAA,2CAAA;wBACT,SAAS,UAEb;oBAEF,IAAA,mWAAA,EACE,MAAM,MAAA,IAAU,GAChB;oBAIF,MAAM,cAAc,iBAAiB,GAAA,CAAI,OAAO;oBAChD,IAAI,aAAa;wBACf,+OAAA,IAAA,EAAK,UAAQ,IAAA,CAAK,WAAW;wBAC7B;oBACF;oBAEA,MAAM,YAAY,iBAAiB,GAAA,CAAI,KAAK;oBAC5C,MAAM,eAAe,iBAAiB,GAAA,CAAI,QAAQ;oBAElD,IAAA,mWAAA,EACE,cAAc,KAAA,KAAa,iBAAiB,KAAA,GAC5C;oBAGF,+OAAA,IAAA,EAAK,UAAQ,IAAA,CAAK,KAAK,yDAAa,YAAY,CAAC;oBACjD;gBACF;YACA;gBACE;QACJ;IACF;IAxKA,YAAY,MAAA,EAAgB,MAAA,CAAuB;QAL1C;;;;;;;;8PAET;;mBAAwB;;8PACxB;;mBAA+B,CAAC,CAAA;;6PAGzB,SAAU;6PACV,SAAU,OAAO,SAAA,CAAU;QAChC,KAAA,MAAW,SAAS,OAAQ;YAC1B,MAAM,eAAA,CAAgB,IAAI;YAC1B,IAAA,mWAAA,iPAAO,IAAA,EAAK,aAAY,MAAM,SAAA,CAAU,GAAG,0BAA2B;QACxE;IACF;AAkKF;;AC3LO,IAAM,4KAAN,MAAuC;IAW5C,SAAS,KAAA,EAAc;6PAChB,QAAS;IAChB;IAEA,gBAAgB,MAAA,EAA4B;QAC1C,+OAAA,IAAA,EAAK,UAAS,IAAA,CAAK,MAAM;IAC3B;IAEA,UAAgB;QACd,mPAAI,IAAA,EAAK,gQAAgB,IAAA,EAAK,UAAS,MAAA,EAAQ;YAC7C,mPAAI,IAAA,EAAK,mBAAkB,GAAG;gBAC5B,+OAAA,IAAA,EAAK,SAAO,OAAA,CAAQ;YACtB;YACA,oPAAE,IAAA,EAAK;QACT,OAAO;YACL,MAAM,IAAI,MAAM,+CAA+C;QACjE;IACF;IAEA,YAAY;QACV,sPAAO,IAAA,EAAK,SAAO,SAAA,CAAU;IAC/B;IAEA,OAAO,IAAA,EAAY,OAAA,EAA2B;QAC5C,IAAI,SAAS;QACb,KAAA,MAAW,yPAAU,IAAA,EAAK,UAAU;YAClC,SAAS,OAAO,MAAA,CAAO,MAAM,OAAO,KAAK;YAGzC,IAAI,CAAC,WAAW,QAAQ;gBACtB,OAAO;YACT;QACF;QACA,OAAO;IACT;IAEA,KAAK,MAAA,EAAgB;QACnB,KAAA,MAAW,sPAAO,IAAA,EAAK,UAAU;YAC/B,IAAI,IAAA,CAAK,MAAM;QACjB;QACA,oPACE,IAAA,EAAK,SACL,iDACA,8BAAA,CAA+B,OAAO,IAAI;IAC9C;IAjDA,YAAY,KAAA,CAAoB;;;;;8PAJvB;;mBAA2B,CAAC,CAAA;;;;wBACrC;;8PACA;;mBAAwB;;6PAGjB,SAAS;QACd,MAAM,eAAA,CAAgB,IAAI;IAC5B;AA+CF;;AC9DO,SAAS,4BACd,MAAA,EACA,SAAA,EACA,MAAA,EACA;IACA,MAAM,gBAAgB,UAAU,OAAO,OAAA,CAAQ,GAAG;IAClD,MAAM,eAAe,UAAU,OAAO,IAAA,CAAK,GAAG;IAE9C,IAAI,iBAAiB,cAAc;QACjC,OAAO,IAAA,CAAK,MAAM;IACpB,OAAA,IAAW,iBAAiB,CAAC,cAAc;QACzC,OAAO,IAAA,CAAK;YACV,MAAM;YACN,MAAM,OAAO,OAAA;QACf,CAAC;IACH,OAAA,IAAW,CAAC,iBAAiB,cAAc;QACzC,OAAO,IAAA,CAAK;YACV,MAAM;YACN,MAAM,OAAO,IAAA;QACf,CAAC;IACH;AACF;;ACxBO,SAAS,WACd,MAAA,EACA,MAAA,EACA,SAAA,EACA;IACA,IAAI,CAAC,WAAW;QACd,OAAO,IAAA,CAAK,MAAM;QAClB;IACF;IACA,OAAQ,OAAO,IAAA,EAAM;QACnB,KAAK;QACL,KAAK;YACH,IAAI,UAAU,OAAO,IAAA,CAAK,GAAG,GAAG;gBAC9B,OAAO,IAAA,CAAK,MAAM;YACpB;YACA;QACF,KAAK;YACH,IAAI,UAAU,OAAO,IAAA,CAAK,GAAG,GAAG;gBAC9B,OAAO,IAAA,CAAK,MAAM;YACpB;YACA;QACF,KAAK;YACH,4BAA4B,QAAQ,WAAW,MAAM;YACrD;QACF;YACE,IAAA,wWAAA,EAAY,MAAM;IACtB;AACF;;AChBO,IAAM,mIAAN,MAAuC;IAY5C,OAAO,IAAA,EAAY,OAAA,EAA2B;QAC5C,0PAAO,EAAK,iBAAL,IAAA,EAAgB,KAAK,GAAG,oPAAK,IAAA,EAAK,UAAQ,MAAA,CAAO,MAAM,OAAO;IACvE;IAEA,gBAAgB,MAAA,EAAsB;6PAC/B,UAAU;IACjB;IAEA,UAAgB;QACd,+OAAA,IAAA,EAAK,SAAO,OAAA,CAAQ;IACtB;IAEA,YAA0B;QACxB,sPAAO,IAAA,EAAK,SAAO,SAAA,CAAU;IAC/B;IAEA,KAAK,MAAA,EAAgB;QACnB,WAAW,uPAAQ,IAAA,EAAK,0PAAS,IAAA,EAAK,UAAU;IAClD;IAxBA,YAAY,KAAA,EAAoB,SAAA,CAAkC;;;;;;;wBAJzD;;;;mBAEe;;6PAGjB,SAAS;6PACT,YAAa;QAClB,MAAM,eAAA,CAAgB,IAAI;IAC5B;AAqBF;;ACDO,IAAM,qoBAAN,MAA4B;IAyDjC,UAAgB;QACd,+OAAA,IAAA,EAAK,SAAQ,OAAA,CAAQ;QACrB,+OAAA,IAAA,EAAK,QAAO,OAAA,CAAQ;IACtB;IAEA,UAAU,MAAA,EAAsB;6PACzB,UAAU;IACjB;IAEA,YAA0B;QACxB,sPAAO,IAAA,EAAK;IACd;IAEA,CAAC,MAAM,GAAA,EAAiC;QACtC,KAAA,MAAW,6PAAc,IAAA,EAAK,SAAQ,KAAA,CAAM,GAAG,EAAG;YAChD,0PAAM,sBAAK,wBAAL,IAAA,EACJ,WAAW,GAAA,EACX,WAAW,aAAA,EACX;QAEJ;IACF;IAEA,CAAC,QAAQ,GAAA,EAAiC;QACxC,KAAA,MAAW,6PAAc,IAAA,EAAK,SAAQ,OAAA,CAAQ,GAAG,EAAG;YAClD,0PAAM,sBAAK,wBAAL,IAAA,EACJ,WAAW,GAAA,EACX,WAAW,aAAA,EACX;QAEJ;IACF;IA3EA,YAAY,EACV,MAAA,EACA,KAAA,EACA,OAAA,EACA,SAAA,EACA,QAAA,EACA,gBAAA,EACA,MAAA,EACA,MAAA,EACF,CAAS;QAoET;QA+DA;;QA+JA;QAkFA;;;;;;;wBAxYS;;;;wBACA;;;;wBACA;;;;wBACA;;;;wBACA;;;;wBACA;;8PAET;;mBAAkB;;;;;;QAchB,IAAA,mWAAA,EAAO,WAAW,OAAO,8CAA8C;QACvE,IAAA,mWAAA,EACE,UAAU,MAAA,KAAW,SAAS,MAAA,EAC9B;6PAEG,SAAU;6PACV,QAAS;6PACT,WAAW;6PACX,YAAa;6PACb,WAAY;6PACZ,oBAAoB;QAEzB,MAAM,eAAe,OAAO,SAAA,CAAU;QACtC,MAAM,cAAc,MAAM,SAAA,CAAU;6PAC/B,UAAU;YACb,GAAG,YAAA;YACH,eAAe;gBACb,GAAG,aAAa,aAAA;gBAChB,CAAC,gBAAgB,CAAA,EAAG;oBAClB,GAAG,WAAA;oBACH,UAAU;oBACV;gBACF;YACF;QACF;QAEA,OAAO,SAAA,CAAU;YACf,MAAM,CAAC,6PAAmB,eAAK,iBAAL,IAAA,EAAiB,MAAM;QACnD,CAAC;QACD,MAAM,SAAA,CAAU;YACd,MAAM,CAAC,yPAAmB,IAAA,cAAK,oBAAL,EAAgB,MAAM;QAClD,CAAC;IACH;AA2VF;AAKO,SAAS,wBAAwB,MAAA,EAAkC;IACxE,MAAM,OAAO,KAAK,SAAA,CAAU;QAAC,WAAW;WAAG,MAAM;KAAC;IAClD,OAAO,KAAK,SAAA,CAAU,GAAG,KAAK,MAAA,GAAS,CAAC,IAAI;AAC9C;AAGO,SAAS,qBAAqB,GAAA,EAAU,GAAA,EAA0B;IACvE,OAAO,wBAAwB,IAAI,GAAA,CAAI,CAAA,IAAK,GAAA,CAAI,CAAC,CAAC,CAAC;AACrD;AAMO,SAAS,eACd,GAAA,EACA,UAAA,EACA,GAAA,EACQ;IACR,MAAM,SAAkB,IAAI,GAAA,CAAI,CAAA,IAAK,GAAA,CAAI,CAAC,CAAC;IAC3C,KAAA,MAAWE,QAAO,WAAY;QAC5B,OAAO,IAAA,CAAK,GAAA,CAAIA,IAAG,CAAC;IACtB;IACA,OAAO,wBAAwB,MAAM;AACvC;AAEA,SAAS,wBAAwB,CAAA,EAAQ,CAAA,EAAQ,GAAA,EAA2B;IAC1E,IAAA,IAAS,IAAI,GAAG,IAAI,IAAI,MAAA,EAAQ,IAAK;QACnC,IAAI,cAAc,CAAA,CAAE,GAAA,CAAI,CAAC,CAAC,CAAA,EAAG,CAAA,CAAE,GAAA,CAAI,CAAC,CAAC,CAAC,MAAM,GAAG;YAC7C,OAAO;QACT;IACF;IACA,OAAO;AACT;;AC/cO,IAAM,wKA0BV,kJA1BI,MAA+B;IAcpC,YAA0B;QACxB,sPAAO,IAAA,EAAK,SAAO,SAAA,CAAU;IAC/B;IAEA,MAAM,GAAA,EAAiC;QACrC,uPAAO,IAAA,mBAAK,yBAAL,EAAqB,SAAS,GAAG;IAC1C;IAEA,QAAQ,GAAA,EAAiC;QACvC,2PAAO,mBAAK,qBAAL,IAAA,EAAqB,SAAS,GAAG;IAC1C;IAoBA,UAAU,MAAA,EAAsB;6PACzB,UAAU;IACjB;IAEA,UAAgB;QACd,+OAAA,IAAA,EAAK,SAAO,OAAA,CAAQ;IACtB;IAOA,KAAK,MAAA,EAAsB;QACzB,MAAM,mBAAkB,CAAC,0PAAa,oBAAK,sBAAL,IAAA,EAAsB,GAAG;QAC/D,IAAI,OAAO,IAAA,KAAS,QAAQ;YAC1B,4BAA4B,QAAQ,iQAAiB,IAAA,EAAK,OAAO;YACjE;QACF;QAEA;QAEA,IAAI,iBAAgB,OAAO,IAAA,CAAK,GAAG,GAAG;YACpC,+OAAA,IAAA,EAAK,UAAQ,IAAA,CAAK,MAAM;QAC1B;IACF;IA9DA,YAAY,KAAA,EAAc,KAAA,CAAc;;;+PAgExC;;;;;;;wBArES;;;;wBACA;;;;mBAES;;6PAGX,SAAS;6PACT,QAAS;6PACT,aAAc,MAAM,SAAA,CAAU,EAAE,WAAA;QACrC,MAAM,SAAA,CAAU,IAAI;IACtB;AAuHF;;ACvIA,IAAM,gBAAgB;AA4Bf,IAAM,0WAgKX,mNAhKK,MAA+B;IA+BpC,UAAU,MAAA,EAAsB;6PACzB,UAAU;IACjB;IAEA,YAA0B;QACxB,sPAAO,IAAA,EAAK,SAAO,SAAA,CAAU;IAC/B;IAEA,CAAC,MAAM,GAAA,EAAiC;QACtC,IACE,gPAAC,IAAA,EAAK,kBACL,IAAI,UAAA,IACH,8BAA8B,IAAI,UAAA,iPAAY,IAAA,EAAK,aAAa,IAClE;YACA,MAAM,eAAe,+PAAgB,IAAA,EAAK,gBAAe,IAAI,UAAU;YACvE,MAAM,2PAAY,IAAA,EAAK,WAAS,GAAA,CAAI,YAAY;YAChD,IAAI,CAAC,WAAW;gBACd,uPAAO,IAAA,iBAAK,uBAAL,EAAmB,GAAG;gBAC7B;YACF;YACA,IAAI,UAAU,KAAA,KAAU,KAAA,GAAW;gBACjC;YACF;YACA,KAAA,MAAW,4PAAa,IAAA,EAAK,SAAO,KAAA,CAAM,GAAG,EAAG;gBAC9C,IAAI,IAAA,CAAK,SAAA,CAAU,EAAE,WAAA,CAAY,UAAU,KAAA,EAAO,UAAU,GAAG,IAAI,GAAG;oBACpE;gBACF;gBACA,mPACE,IAAA,EAAK,wBACL,IAAA,CAAK,SAAA,CAAU,EAAE,WAAA,gPACf,IAAA,EAAK,sBACL,UAAU,GAAA,MACN,GACN;oBACA;gBACF;gBACA,MAAM;YACR;YACA;QACF;QAOA,MAAM,WAAW,mPAAA,EAAK,WAAS,GAAA,CAAI,aAAa;QAChD,IAAI,aAAa,KAAA,GAAW;YAC1B;QACF;QACA,KAAA,MAAW,4PAAa,IAAA,EAAK,SAAO,KAAA,CAAM,GAAG,EAAG;YAC9C,IAAI,IAAA,CAAK,SAAA,CAAU,EAAE,WAAA,CAAY,UAAU,GAAA,EAAK,QAAQ,IAAI,GAAG;gBAC7D;YACF;YACA,MAAM,eAAe,+PAAgB,IAAA,EAAK,gBAAe,UAAU,GAAG;YACtE,MAAM,2PAAY,IAAA,EAAK,WAAS,GAAA,CAAI,YAAY;YAChD,2DACE,UAAW,KAAA,MAAU,KAAA,KACrB,IAAA,CAAK,SAAA,CAAU,EAAE,WAAA,CAAY,UAAU,KAAA,EAAO,UAAU,GAAG,KAAK,GAChE;gBACA,MAAM;YACR;QACF;IACF;IAmDA,CAAC,QAAQ,GAAA,EAAiC;QACxC,IAAA,mWAAA,EAAO,IAAI,KAAA,KAAU,KAAA,CAAS;QAC9B,IAAA,mWAAA,EAAO,8BAA8B,IAAI,UAAA,iPAAY,IAAA,EAAK,aAAa,CAAC;QACxE,MAAM,eAAe,+PAAgB,IAAA,EAAK,gBAAe,IAAI,UAAU;QACvE,+OAAA,IAAA,EAAK,WAAS,GAAA,CAAI,YAAY;QAC9B,IAAI,OAAO;QACX,KAAA,MAAW,4PAAa,IAAA,EAAK,SAAO,OAAA,CAAQ,GAAG,EAAG;YAChD,IAAI,wPAAS,IAAA,EAAK,SAAQ;gBACxB;YACF;YACA;YACA,MAAM;QACR;IACF;IA+BA,KAAK,MAAA,EAAsB;QACzB,IAAI,OAAO,IAAA,KAAS,QAAQ;YAC1B,gPAAA,IAAA,mBAAK,qBAAL,IAAA,EAAqB,MAAM;YAC3B;QACF;QAEA,MAAM,EAAC,SAAA,EAAW,YAAA,EAAc,QAAA,EAAU,UAAA,CAAU,CAAA,uPAClD,0BAAK,4BAAL,IAAA,EAA4B,OAAO,IAAA,CAAK,GAAG;QAC7C,IAAI,CAAC,WAAW;YACd;QACF;QAEA,MAAM,EAAC,WAAA,CAAW,CAAA,GAAI,IAAA,CAAK,SAAA,CAAU;QAErC,IAAI,OAAO,IAAA,KAAS,OAAO;YACzB,IAAI,UAAU,IAAA,kPAAO,IAAA,EAAK,SAAQ;gBAChC,gPAAA,IAAA,iBAAK,mBAAL,IAAA,EACE,cACA,UAAU,IAAA,GAAO,GACjB,UAAU,KAAA,KAAU,KAAA,KAClB,YAAY,UAAU,KAAA,EAAO,OAAO,IAAA,CAAK,GAAG,IAAI,IAC9C,OAAO,IAAA,CAAK,GAAA,GACZ,UAAU,KAAA,EACd;gBAEF,+OAAA,IAAA,EAAK,UAAQ,IAAA,CAAK,MAAM;gBACxB;YACF;YAEA,IACE,UAAU,KAAA,KAAU,KAAA,KACpB,YAAY,OAAO,IAAA,CAAK,GAAA,EAAK,UAAU,KAAK,KAAK,GACjD;gBACA;YACF;YAEA,IAAI;YACJ,IAAI;YACJ,mPAAI,IAAA,EAAK,YAAW,GAAG;gBACrB,YAAY,KACV,qPACE,IAAA,EAAK,SAAO,KAAA,CAAM;oBAChB,OAAO;wBACL,KAAK,UAAU,KAAA;wBACf,OAAO;oBACT;oBACA;gBACF,CAAC;YAGP,OAAO;gBACL,CAAC,WAAW,eAAe,CAAA,GAAI,oPAC7B,IAAA,EAAK,SAAO,KAAA,CAAM;oBAChB,OAAO;wBACL,KAAK,UAAU,KAAA;wBACf,OAAO;oBACT;oBACA;oBACA,SAAS;gBACX,CAAC,GACD;YAEJ;YACA,MAAM,eAA6B;gBACjC,MAAM;gBACN,MAAM;YACR;YAGA,gPAAA,IAAA,iBAAK,mBAAL,IAAA,EACE,cACA,UAAU,IAAA,EACV,oBAAoB,KAAA,KAClB,YAAY,OAAO,IAAA,CAAK,GAAA,EAAK,gBAAgB,GAAG,IAAI,IAClD,OAAO,IAAA,CAAK,GAAA,GACZ,gBAAgB,GAAA,EACpB;YAEF,gPAAA,IAAA,2BAAK,6BAAL,IAAA,EAA6B,OAAO,IAAA,CAAK,GAAA,EAAK,MAAM;gBAClD,+OAAA,IAAA,EAAK,UAAQ,IAAA,CAAK,YAAY;YAChC,CAAC;YACD,+OAAA,IAAA,EAAK,UAAQ,IAAA,CAAK,MAAM;QAC1B,OAAA,IAAW,OAAO,IAAA,KAAS,UAAU;YACnC,IAAI,UAAU,KAAA,KAAU,KAAA,GAAW;gBAEjC;YACF;YACA,MAAM,cAAc,YAAY,OAAO,IAAA,CAAK,GAAA,EAAK,UAAU,KAAK;YAChE,IAAI,cAAc,GAAG;gBAEnB;YACF;YACA,MAAM,CAAC,eAAe,CAAA,GAAI,oPACxB,IAAA,EAAK,SAAO,KAAA,CAAM;gBAChB,OAAO;oBACL,KAAK,UAAU,KAAA;oBACf,OAAO;gBACT;gBACA;gBACA,SAAS;YACX,CAAC,GACD;YAGF,IAAI;YACJ,IAAI,iBAAiB;gBACnB,MAAM,OAAO,YAAY,gBAAgB,GAAA,EAAK,UAAU,KAAK,IAAI;gBACjE,WAAW;oBACT,MAAM;oBACN;gBACF;YACF;YACA,IAAI,sDAAC,SAAU,IAAA,GAAM;gBACnB,KAAA,MAAW,uPAAQ,IAAA,EAAK,SAAO,KAAA,CAAM;oBACnC,OAAO;wBACL,KAAK,UAAU,KAAA;wBACf,OAAO;oBACT;oBACA;gBACF,CAAC,EAAG;oBACF,MAAM,OAAO,YAAY,KAAK,GAAA,EAAK,UAAU,KAAK,IAAI;oBACtD,WAAW;wBACT;wBACA;oBACF;oBACA,IAAI,MAAM;wBACR;oBACF;gBACF;YACF;YAEA,wDAAI,SAAU,IAAA,EAAM;gBAClB,+OAAA,IAAA,EAAK,UAAQ,IAAA,CAAK,MAAM;gBACxB,gPAAA,IAAA,iBAAK,mBAAL,IAAA,EACE,cACA,UAAU,IAAA,EACV,SAAS,IAAA,CAAK,GAAA,EACd;gBAEF,+OAAA,IAAA,EAAK,UAAQ,IAAA,CAAK;oBAChB,MAAM;oBACN,MAAM,SAAS,IAAA;gBACjB,CAAC;gBACD;YACF;YACA,gPAAA,IAAA,iBAAK,mBAAL,IAAA,EACE,cACA,UAAU,IAAA,GAAO,GACjB,6DAAU,IAAA,CAAK,GAAA,EACf;YAEF,+OAAA,IAAA,EAAK,UAAQ,IAAA,CAAK,MAAM;QAC1B,OAAA,IAAW,OAAO,IAAA,KAAS,SAAS;YAGlC,IACE,UAAU,KAAA,IACV,YAAY,OAAO,IAAA,CAAK,GAAA,EAAK,UAAU,KAAK,KAAK,GACjD;gBACA,+OAAA,IAAA,EAAK,UAAQ,IAAA,CAAK,MAAM;YAC1B;QACF;IACF;IA+OA,UAAgB;QACd,+OAAA,IAAA,EAAK,SAAO,OAAA,CAAQ;IACtB;IArkBA,YACE,KAAA,EACA,OAAA,EACA,KAAA,EACA,YAAA,CACA;QAgFF,uPAAC;;;;;;;;;;;wBA9FQ;;;;wBACA;;;;wBACA;;8PACA;;;;;;wBAET;;8PAEA;;mBAAkB;;QAQhB,IAAA,mWAAA,EAAO,SAAS,CAAC;QACjB,yBACE,MAAM,SAAA,CAAU,EAAE,IAAA,EAClB,MAAM,SAAA,CAAU,EAAE,UAAA;QAEpB,MAAM,SAAA,CAAU,IAAI;6PACf,SAAS;6PACT,WAAW;6PACX,QAAS;6PACT,eAAgB;6PAChB,yBACH,gBAAgB,2BAA2B,YAAY;IAC3D;AAojBF;AAEA,SAAS,gBACP,YAAA,EACA,eAAA,EACQ;IAGR,MAAM,kBAA2B,CAAC,CAAA;IAElC,IAAI,gBAAgB,iBAAiB;QACnC,KAAA,MAAW,OAAO,aAAc;YAC9B,gBAAgB,IAAA,CAAK,eAAA,CAAgB,GAAG,CAAC;QAC3C;IACF;IAEA,OAAO,KAAK,SAAA,CAAU;QAAC,QAAQ;WAAG,eAAe;KAAC;AACpD;AAEA,SAAS,8BACP,UAAA,EACA,YAAA,EACS;IACT,IAAI,eAAe,KAAA,KAAa,iBAAiB,KAAA,GAAW;QAC1D,OAAO,eAAe;IACxB;IACA,IAAI,aAAa,MAAA,KAAW,OAAO,IAAA,CAAK,UAAU,EAAE,MAAA,EAAQ;QAC1D,OAAO;IACT;IACA,KAAA,MAAW,OAAO,aAAc;QAC9B,IAAI,KAAC,mWAAA,EAAO,YAAY,GAAG,GAAG;YAC5B,OAAO;QACT;IACF;IACA,OAAO;AACT;AAEA,SAAS,2BAA2B,YAAA,EAAwC;IAC1E,OAAO,CAAC,GAAG,MAAM;QACf,KAAA,MAAW,OAAO,aAAc;YAC9B,MAAME,OAAM,cAAc,CAAA,CAAE,GAAG,CAAA,EAAG,CAAA,CAAE,GAAG,CAAC;YACxC,IAAIA,SAAQ,GAAG;gBACb,OAAOA;YACT;QACF;QACA,OAAO;IACT;AACF;;ACloBO,IAAM,qBAIF,uCAJJ,MAGL;IAgBA,IAAI,KAAK;QACP,OAAO,IAAA;IACT;IAoBA,IACE,KAAA,EACA,SAAA,EACA,KAAA,EACW;QACX,OAAO,IAAI,OAAO,WAAW,KAAK;IACpC;IAEA,OACE,IAAA,EACA,EAAA,EACA,KAAA,EACW;QACX,OAAO;YACL,MAAM;YACN,MAAM,qBAAqB,IAAI,IAC3B,IAAA,CAAK,aAAa,CAAA,CAAE,IACpB;gBAAC,MAAM;gBAAW,OAAO;YAAI;YACjC,OAAO,qBAAqB,KAAK,IAC7B,KAAA,CAAM,aAAa,CAAA,CAAE,IACrB;gBAAC,MAAM;gBAAW,OAAO;YAAK;YAClC;QACF;IACF;IAvDA,YACE,MAAA,CAIA;;;;;qPAoDF,OAAM;qPACN,MAAK;qPACL,OAAM;qPAEN,UAAS,CACP,cACA,oPAGc,IAAA,EAAK,kBAAL,EAAa,cAAc,EAAE;6PA5DtC,SAAU;QACf,IAAA,CAAK,MAAA,GAAS,IAAA,CAAK,MAAA,CAAO,IAAA,CAAK,IAAI;IACrC;AA2DF;AAEO,SAAS;IAAA,IAAA,IAAA,OAAA,UAAA,QAAA,aAAA,UAAA,OAAA,OAAA,GAAA,OAAA,MAAA;QAAO,WAAP,QAAA,SAAA,CAAA,KAAO,EAAkD;;IACvE,MAAM,cAAc,WAAW,gBAAgB,UAAU,CAAC;IAE1D,IAAI,YAAY,MAAA,KAAW,GAAG;QAC5B,OAAO,WAAA,CAAY,CAAC,CAAA;IACtB;IAEA,IAAI,YAAY,IAAA,CAAK,aAAa,GAAG;QACnC,OAAO;IACT;IAEA,OAAO;QAAC,MAAM;QAAO,YAAY;IAAW;AAC9C;AAEO,SAAS;IAAA,IAAA,IAAA,OAAA,UAAA,QAAA,aAAA,UAAA,OAAA,OAAA,GAAA,OAAA,MAAA;QAAM,WAAN,QAAA,SAAA,CAAA,KAAM,EAAkD;;IACtE,MAAM,cAAc,YAAY,gBAAgB,UAAU,CAAC;IAE3D,IAAI,YAAY,MAAA,KAAW,GAAG;QAC5B,OAAO,WAAA,CAAY,CAAC,CAAA;IACtB;IAEA,IAAI,YAAY,IAAA,CAAK,YAAY,GAAG;QAClC,OAAO;IACT;IAEA,OAAO;QAAC,MAAM;QAAM,YAAY;IAAW;AAC7C;AAEO,SAAS,IAAI,UAAA,EAAkC;IACpD,OAAQ,WAAW,IAAA,EAAM;QACvB,KAAK;YACH,OAAO;gBACL,MAAM;gBACN,YAAY,WAAW,UAAA,CAAW,GAAA,CAAI,GAAG;YAC3C;QACF,KAAK;YACH,OAAO;gBACL,MAAM;gBACN,YAAY,WAAW,UAAA,CAAW,GAAA,CAAI,GAAG;YAC3C;QACF,KAAK;YACH,OAAO;gBACL,MAAM;gBACN,SAAS,WAAW,OAAA;gBACpB,IAAI,eAAe,WAAW,EAAE;YAClC;QACF,KAAK;YACH,OAAO;gBACL,MAAM;gBACN,IAAI,eAAe,WAAW,EAAE;gBAChC,MAAM,WAAW,IAAA;gBACjB,OAAO,WAAW,KAAA;YACpB;IACJ;AACF;AAEO,SAAS,IACd,KAAA,EACA,SAAA,EACA,KAAA,EACW;IACX,IAAI;IACJ,IAAI,UAAU,KAAA,GAAW;QACvB,QAAQ;QACR,KAAK;IACP,OAAO;QACL,KAAK;IACP;IAEA,OAAO;QACL,MAAM;QACN,MAAM;YAAC,MAAM;YAAU,MAAM;QAAK;QAClC,OAAO,qBAAqB,KAAK,IAC7B,KAAA,CAAM,aAAa,CAAA,CAAE,IACrB;YAAC,MAAM;YAAW;QAAK;QAC3B;IACF;AACF;AAEA,SAAS,qBACP,KAAA,EAC6B;IAC7B,OACE,UAAU,QAAQ,OAAO,UAAU,YAAa,KAAA,CAAc,aAAa,CAAA;AAE/E;AAEO,IAAM,OAAkB;IAC7B,MAAM;IACN,YAAY,CAAC,CAAA;AACf;AAEA,IAAM,QAAmB;IACvB,MAAM;IACN,YAAY,CAAC,CAAA;AACf;AAEA,SAAS,aAAa,SAAA,EAA+B;IACnD,OAAO,UAAU,IAAA,KAAS,SAAS,UAAU,UAAA,CAAW,MAAA,KAAW;AACrE;AAEA,SAAS,cAAc,SAAA,EAA+B;IACpD,OAAO,UAAU,IAAA,KAAS,QAAQ,UAAU,UAAA,CAAW,MAAA,KAAW;AACpE;AAEO,SAAS,kBAAkB,CAAA,EAAyB;IACzD,IAAI,EAAE,IAAA,KAAS,YAAY,EAAE,IAAA,KAAS,sBAAsB;QAC1D,OAAO;IACT;IACA,IAAI,EAAE,UAAA,CAAW,MAAA,KAAW,GAAG;QAC7B,OAAO,kBAAkB,EAAE,UAAA,CAAW,CAAC,CAAC;IAC1C;IACA,MAAM,aAAa,QAAQ,EAAE,IAAA,EAAM,EAAE,UAAA,CAAW,GAAA,CAAI,iBAAiB,CAAC;IACtE,IAAI,EAAE,IAAA,KAAS,SAAS,WAAW,IAAA,CAAK,aAAa,GAAG;QACtD,OAAO;IACT;IACA,IAAI,EAAE,IAAA,KAAS,QAAQ,WAAW,IAAA,CAAK,YAAY,GAAG;QACpD,OAAO;IACT;IACA,OAAO;QACL,MAAM,EAAE,IAAA;QACR;IACF;AACF;AAEO,SAAS,QACd,IAAA,EACA,UAAA,EACa;IACb,MAAMC,aAAyB,CAAC,CAAA;IAChC,KAAA,MAAW,KAAK,WAAY;QAC1B,IAAI,EAAE,IAAA,KAAS,MAAM;YACnBA,WAAU,IAAA,CAAK,GAAG,EAAE,UAAU;QAChC,OAAO;YACLA,WAAU,IAAA,CAAK,CAAC;QAClB;IACF;IAEA,OAAOA;AACT;AAEA,IAAM,0BAA0B;IAC9B,CAAC,GAAG,CAAA,EAAG;IACP,CAAC,IAAI,CAAA,EAAG;IACR,CAAC,GAAG,CAAA,EAAG;IACP,CAAC,GAAG,CAAA,EAAG;IACP,CAAC,IAAI,CAAA,EAAG;IACR,CAAC,IAAI,CAAA,EAAG;IACR,CAAC,IAAI,CAAA,EAAG;IACR,CAAC,QAAQ,CAAA,EAAG;IACZ,CAAC,MAAM,CAAA,EAAG;IACV,CAAC,UAAU,CAAA,EAAG;IACd,CAAC,OAAO,CAAA,EAAG;IACX,CAAC,WAAW,CAAA,EAAG;IACf,CAAC,IAAI,CAAA,EAAG;IACR,CAAC,QAAQ,CAAA,EAAG;AACd;AAEA,IAAM,oBAAoB;IACxB,GAAG,uBAAA;IACH,CAAC,QAAQ,CAAA,EAAG;IACZ,CAAC,YAAY,CAAA,EAAG;AAClB;AAEO,SAAS,eACd,EAAA,EACgC;IAChC,OAAO,KAAK,iBAAA,CAAkB,EAAE,CAAC;AACnC;AAEA,SAAS,gBAAmBC,MAAAA,EAA+B;IACzD,OAAOA,OAAM,MAAA,CAAO,CAAA,IAAK,MAAM,KAAA,CAAS;AAC1C;AAEA,SAAS,WAAW,UAAA,EAAsC;IACxD,OAAO,WAAW,MAAA,CAAO,CAAA,IAAK,CAAC,aAAa,CAAC,CAAC;AAChD;AAEA,SAAS,YAAY,UAAA,EAAsC;IACzD,OAAO,WAAW,MAAA,CAAO,CAAA,IAAK,CAAC,cAAc,CAAC,CAAC;AACjD;;AC7SO,SAAS,iBACd,OAAA,EACA,KAAA,EACuB;IACvB,MAAM,KAAK,UAAU,OAAO,OAAO,GAAG,KAAK;IAC3C,OAAO,CAAC,QAAsB;QAC5B,IAAA,yWAAA,EAAa,GAAG;QAChB,OAAO,GAAG,OAAO,GAAG,CAAC;IACvB;AACF;AAEA,SAAS,UAAU,OAAA,EAAiB,KAAA,EAA2C;IAO7E,IAAI,CAAC,SAAS,IAAA,CAAK,OAAO,GAAG;QAC3B,IAAI,UAAU,KAAK;YACjB,MAAM,WAAW,QAAQ,WAAA,CAAY;YACrC,OAAO,CAAC,MAAgB,IAAI,WAAA,CAAY,MAAM;QAChD;QACA,OAAO,CAAC,MAAgB,QAAQ;IAClC;IACA,MAAM,KAAK,gBAAgB,SAAS,KAAK;IACzC,OAAO,CAAC,MAAgB,GAAG,IAAA,CAAK,GAAG;AACrC;AAEA,IAAM,iBAAiB;AAEvB,SAAS,gBAAgB,MAAA;gBAAgB,iEAAkB,IAAY;IAMrE,IAAI,UAAU;IACd,IAAA,IAAS,IAAI,GAAG,IAAI,OAAO,MAAA,EAAQ,IAAK;QACtC,IAAI,IAAI,MAAA,CAAO,CAAC,CAAA;QAChB,OAAQ,GAAG;YACT,KAAK;gBACH,WAAW;gBACX;YACF,KAAK;gBACH,WAAW;gBACX;YAAA,+BAAA;YAGF,KAAK;gBACH,IAAI,MAAM,OAAO,MAAA,GAAS,GAAG;oBAC3B,MAAM,IAAI,MAAM,iDAAiD;gBACnE;gBACA;gBACA,IAAI,MAAA,CAAO,CAAC,CAAA;YAAA,eAAA;YAGd;gBACE,IAAI,eAAe,IAAA,CAAK,CAAC,GAAG;oBAC1B,WAAW;gBACb;gBACA,WAAW;gBAEX;QACJ;IACF;IACA,OAAO,IAAI,OAAO,UAAU,KAAK,QAAQ,GAAG;AAC9C;;AC7CO,SAAS,gBACd,SAAA,EACuB;IACvB,IAAI,UAAU,IAAA,KAAS,UAAU;QAC/B,MAAM,aAAa,UAAU,UAAA,CAAW,GAAA,CAAI,CAAA,IAAK,gBAAgB,CAAC,CAAC;QACnE,OAAO,UAAU,IAAA,KAAS,QACtB,CAAC,QAAa;YAEZ,KAAA,MAAW,aAAa,WAAY;gBAClC,IAAI,CAAC,UAAU,GAAG,GAAG;oBACnB,OAAO;gBACT;YACF;YACA,OAAO;QACT,IACA,CAAC,QAAa;YAEZ,KAAA,MAAW,aAAa,WAAY;gBAClC,IAAI,UAAU,GAAG,GAAG;oBAClB,OAAO;gBACT;YACF;YACA,OAAO;QACT;IACN;IACA,MAAM,EAAC,IAAA,CAAI,CAAA,GAAI;IACf,MAAM,EAAC,KAAA,CAAK,CAAA,GAAI;IAChB,IAAA,mWAAA,EACE,MAAM,IAAA,KAAS,UACf;IAEF,IAAA,mWAAA,EACE,KAAK,IAAA,KAAS,UACd;IAGF,OAAQ,UAAU,EAAA,EAAI;QACpB,KAAK;QACL,KAAK;YAAU;gBACb,MAAMC,QAAO,kBAAkB,MAAM,KAAA,EAAO,UAAU,EAAE;gBACxD,IAAI,KAAK,IAAA,KAAS,WAAW;oBAC3B,MAAM,SAASA,MAAK,KAAK,KAAK;oBAC9B,OAAO,IAAM;gBACf;gBACA,OAAO,CAAC,MAAaA,MAAK,GAAA,CAAI,KAAK,IAAI,CAAC;YAC1C;IACF;IAEA,IAAI,MAAM,KAAA,KAAU,QAAQ,MAAM,KAAA,KAAU,KAAA,GAAW;QACrD,OAAO,CAAC,OAAc;IACxB;IAEA,MAAM,OAAO,oBAAoB,MAAM,KAAA,EAAO,UAAU,EAAE;IAC1D,IAAI,KAAK,IAAA,KAAS,WAAW;QAC3B,IAAI,KAAK,KAAA,KAAU,QAAQ,KAAK,KAAA,KAAU,KAAA,GAAW;YACnD,OAAO,CAAC,OAAc;QACxB;QACA,MAAM,SAAS,KAAK,KAAK,KAAK;QAC9B,OAAO,IAAM;IACf;IAEA,OAAO,CAAC,QAAa;QACnB,MAAM,MAAM,GAAA,CAAI,KAAK,IAAI,CAAA;QACzB,IAAI,QAAQ,QAAQ,QAAQ,KAAA,GAAW;YACrC,OAAO;QACT;QACA,OAAO,KAAK,GAAG;IACjB;AACF;AAEA,SAAS,kBACP,GAAA,EACA,QAAA,EACiB;IACjB,OAAQ,UAAU;QAChB,KAAK;YACH,OAAO,CAAA,MAAO,QAAQ;QACxB,KAAK;YACH,OAAO,CAAA,MAAO,QAAQ;IAC1B;AACF;AAEA,SAAS,oBACP,GAAA,EACA,QAAA,EACuB;IACvB,OAAQ,UAAU;QAChB,KAAK;YACH,OAAO,CAAA,MAAO,QAAQ;QACxB,KAAK;YACH,OAAO,CAAA,MAAO,QAAQ;QACxB,KAAK;YACH,OAAO,CAAA,MAAO,MAAM;QACtB,KAAK;YACH,OAAO,CAAA,MAAO,OAAO;QACvB,KAAK;YACH,OAAO,CAAA,MAAO,MAAM;QACtB,KAAK;YACH,OAAO,CAAA,MAAO,OAAO;QACvB,KAAK;YACH,OAAO,iBAAiB,KAAK,EAAE;QACjC,KAAK;YACH,OAAOC,KAAI,iBAAiB,KAAK,EAAE,CAAC;QACtC,KAAK;YACH,OAAO,iBAAiB,KAAK,GAAG;QAClC,KAAK;YACH,OAAOA,KAAI,iBAAiB,KAAK,GAAG,CAAC;QACvC,KAAK;YAAM;gBACT,IAAA,mWAAA,EAAO,MAAM,OAAA,CAAQ,GAAG,CAAC;gBACzB,MAAM,MAAM,IAAI,IAAI,GAAG;gBACvB,OAAO,CAAA,MAAO,IAAI,GAAA,CAAI,GAAG;YAC3B;QACA,KAAK;YAAU;gBACb,IAAA,mWAAA,EAAO,MAAM,OAAA,CAAQ,GAAG,CAAC;gBACzB,MAAM,MAAM,IAAI,IAAI,GAAG;gBACvB,OAAO,CAAA,MAAO,CAAC,IAAI,GAAA,CAAI,GAAG;YAC5B;QACA;YACE;YACA,MAAM,IAAI,MAAM,wBAAgC,CAAE,MAAV,QAAQ;IACpD;AACF;AAEA,SAASA,KAAO,CAAA,EAAwB;IACtC,OAAO,CAAC,MAAW,CAAC,EAAE,GAAG;AAC3B;AAWO,SAAS,iBAAiB,OAAA,EAG/B;IACA,IAAI,CAAC,SAAS;QACZ,OAAO;YAAC,SAAS,KAAA;YAAW,mBAAmB;QAAK;IACtD;IACA,OAAQ,QAAQ,IAAA,EAAM;QACpB,KAAK;YACH,OAAO;gBAAC;gBAAS,mBAAmB;YAAK;QAC3C,KAAK;YACH,OAAO;gBAAC,SAAS,KAAA;gBAAW,mBAAmB;YAAI;QACrD,KAAK;QACL,KAAK;YAAM;gBACT,MAAM,wBAA+C,CAAC,CAAA;gBACtD,IAAI,oBAAoB;gBACxB,KAAA,MAAW,QAAQ,QAAQ,UAAA,CAAY;oBACrC,MAAM,cAAc,iBAAiB,IAAI;oBAGzC,IAAI,YAAY,OAAA,KAAY,KAAA,KAAa,QAAQ,IAAA,KAAS,MAAM;wBAC9D,OAAO;4BAAC,SAAS,KAAA;4BAAW,mBAAmB;wBAAI;oBACrD;oBACA,oBAAoB,qBAAqB,YAAY,iBAAA;oBACrD,IAAI,YAAY,OAAA,EAAS;wBACvB,sBAAsB,IAAA,CAAK,YAAY,OAAO;oBAChD;gBACF;gBACA,OAAO;oBACL,SAAS,kBAAkB;wBACzB,MAAM,QAAQ,IAAA;wBACd,YAAY;oBACd,CAAC;oBACD;gBACF;YACF;QACA;YACE,IAAA,wWAAA,EAAY,OAAO;IACvB;AACF;;ACjGO,SAAS,cACd,GAAA,EACA,QAAA,EACA,OAAA,EACO;IACP,OAAO,sBACL,SAAS,MAAA,GAAS,SAAS,MAAA,CAAO,GAAG,IAAI,KACzC,UACA,SACA;AAEJ;AA+EA,SAAS,sBACP,GAAA,EACA,QAAA,EACA,OAAA,EACA,IAAA,EACA,YAAA,EACO;IACP,MAAM,SAAS,SAAS,SAAA,CAAU,IAAI,KAAK;IAC3C,IAAI,CAAC,QAAQ;QACX,MAAM,IAAI,MAAM,qBAA8B,CAAE,MAAX,IAAI,KAAK;IAChD;IACA,MAAM,2CAA2C,GAAG;IAEpD,MAAM,oBAAoB,6CACxB,IAAI,KAAA;IAEN,MAAM,gBAA6B,eAC/B,IAAI,IAAI,YAAY,IACpB,aAAA,GAAA,IAAI,IAAI;IACZ,MAAM,UAAU,aAAA,GAAA,IAAI,IAAY;IAChC,KAAA,MAAW,OAAO,kBAAmB;QACnC,QAAQ,GAAA,CAAI,IAAI,QAAA,CAAS,KAAA,IAAS,EAAE;QACpC,KAAA,MAAW,OAAO,IAAI,WAAA,CAAY,WAAA,CAAa;YAC7C,cAAc,GAAA,CAAI,GAAG;QACvB;IACF;IACA,IAAI,IAAI,OAAA,EAAS;QACf,KAAA,MAAW,OAAO,IAAI,OAAA,CAAS;YAC7B,KAAA,MAAW,OAAO,IAAI,WAAA,CAAY,WAAA,CAAa;gBAC7C,cAAc,GAAA,CAAI,GAAG;YACvB;QACF;IACF;IACA,MAAM,OAAO,OAAO,OAAA,CAClB,KAAK,IAAI,OAAO,GAChB,IAAI,KAAA,EACJ,eACA,SAAS,KAAA;IAGX,IAAI,MAAa,SAAS,mBAAA,CAAoB,MAAM,OAAO;IAC3D,MAAM,SAAS,aAAA,CAAc,KAAK,UAAG,IAAI,EAAA,YAAoB,OAAT,IAAI,KAAK,EAAA,EAAG;IAChE,MAAM,EAAC,mBAAA,CAAmB,CAAA,GAAI;IAE9B,IAAI,IAAI,KAAA,EAAO;QACb,MAAM,OAAO,IAAI,KAAK,KAAK,IAAI,KAAK;QACpC,SAAS,OAAA,CAAQ,KAAK,IAAI;QAC1B,MAAM,SAAS,aAAA,CAAc,MAAM,GAAO,OAAJ,IAAI,EAAA,OAAQ;IACpD;IAEA,KAAA,MAAW,OAAO,kBAAmB;QACnC,MAAM,wBAAwB,KAAK,UAAU,SAAS,KAAK,MAAM,IAAI;IACvE;IAEA,IAAI,IAAI,KAAA,IAAA,CAAU,CAAC,uBAAuB,SAAS,kBAAA,GAAqB;QACtE,MAAM,WAAW,KAAK,IAAI,KAAA,EAAO,UAAU,IAAI;IACjD;IAEA,IAAI,IAAI,KAAA,KAAU,KAAA,GAAW;QAC3B,MAAM,WAAW,GAAO,OAAJ,IAAI,EAAA;QACxB,MAAMC,QAAO,IAAI,KACf,KACA,SAAS,aAAA,CAAc,QAAQ,GAC/B,IAAI,KAAA,EACJ;QAEF,SAAS,OAAA,CAAQ,KAAKA,KAAI;QAC1B,MAAM,SAAS,aAAA,CAAcA,OAAM,QAAQ;IAC7C;IAEA,IAAI,IAAI,OAAA,EAAS;QACf,KAAA,MAAW,OAAO,IAAI,OAAA,CAAS;YAC7B,MAAM,wBAAwB,KAAK,UAAU,SAAS,KAAK,MAAM,KAAK;QACxE;IACF;IAEA,OAAO;AACT;AAEA,SAAS,WACP,KAAA,EACA,SAAA,EACA,QAAA,EACA,IAAA,EACO;IACP,OAAO,oBAAoB,OAAO,UAAU,CAAA,cAC1C,YAAY,aAAa,WAAW,UAAU,IAAI;AAEtD;AAEA,SAAS,YACP,KAAA,EACA,SAAA,EACA,QAAA,EACA,IAAA,EACA;IACA,OAAQ,UAAU,IAAA,EAAM;QACtB,KAAK;YACH,OAAO,SAAS,OAAO,WAAW,UAAU,IAAI;QAClD,KAAK;YACH,OAAO,QAAQ,OAAO,WAAW,UAAU,IAAI;QACjD,KAAK;YACH,OAAO,iCAAiC,OAAO,WAAW,UAAU,IAAI;QAC1E,KAAK;YACH,OAAO,qBAAqB,OAAO,UAAU,SAAS;IAC1D;AACF;AAEA,SAAS,SACP,KAAA,EACA,SAAA,EACA,QAAA,EACA,IAAA,EACa;IACb,KAAA,MAAW,gBAAgB,UAAU,UAAA,CAAY;QAC/C,QAAQ,YAAY,OAAO,cAAc,UAAU,IAAI;IACzD;IACA,OAAO;AACT;AAEO,SAAS,QACd,KAAA,EACA,SAAA,EACA,QAAA,EACA,IAAA,EACa;IACb,MAAM,CAAC,oBAAoB,eAAe,CAAA,GACxC,wBAAwB,SAAS;IAEnC,IAAI,mBAAmB,MAAA,KAAW,GAAG;QACnC,MAAM,SAAS,IAAI,OACjB,OACA,gBAAgB;YACd,MAAM;YACN,YAAY;QACd,CAAC;QAEH,SAAS,OAAA,CAAQ,OAAO,MAAM;QAC9B,OAAO;IACT;IAEA,MAAM,SAAS,IAAI,OAAO,KAAK;IAC/B,SAAS,OAAA,CAAQ,OAAO,MAAM;IAC9B,MAAM,WAAW,mBAAmB,GAAA,CAAI,CAAA,eACtC,YAAY,QAAQ,cAAc,UAAU,IAAI;IAElD,IAAI,gBAAgB,MAAA,GAAS,GAAG;QAC9B,MAAM,SAAS,IAAI,OACjB,QACA,gBAAgB;YACd,MAAM;YACN,YAAY;QACd,CAAC;QAEH,SAAS,OAAA,CAAQ,QAAQ,MAAM;QAC/B,SAAS,IAAA,CAAK,MAAM;IACtB;IACA,MAAM,MAAM,IAAI,MAAM,QAAQ,QAAQ;IACtC,KAAA,MAAW,UAAU,SAAU;QAC7B,SAAS,OAAA,CAAQ,QAAQ,GAAG;IAC9B;IACA,OAAO,QAAA,CAAS,GAAG;IACnB,OAAO;AACT;AAEO,SAAS,wBAAwB,SAAA,EAAwB;IAC9D,MAAM,cAGF;QAAC,CAAC,CAAA;QAAG,CAAC,CAAC;KAAA;IACX,KAAA,MAAW,gBAAgB,UAAU,UAAA,CAAY;QAC/C,IAAI,+BAA+B,YAAY,GAAG;YAChD,WAAA,CAAY,CAAC,CAAA,CAAE,IAAA,CAAK,YAAY;QAClC,OAAO;YACL,WAAA,CAAY,CAAC,CAAA,CAAE,IAAA,CAAK,YAAY;QAClC;IACF;IACA,OAAO;AACT;AAEO,SAAS,+BACd,SAAA,EACkC;IAClC,IAAI,UAAU,IAAA,KAAS,sBAAsB;QAC3C,OAAO;IACT;IACA,IAAI,UAAU,IAAA,KAAS,UAAU;QAC/B,OAAO;IACT;IACA,OAAO,UAAU,UAAA,CAAW,KAAA,CAAM,8BAA8B;AAClE;AAEA,SAAS,qBACP,KAAA,EACA,QAAA,EACA,SAAA,EACa;IACb,MAAM,SAAS,IAAI,OAAO,OAAO,gBAAgB,SAAS,CAAC;IAC3D,SAAS,mBAAA,CACP,QACA,UAAG,aAAa,UAAU,IAAI,CAAC,EAAA,YAAI,UAAU,EAAE,EAAA,KAAiC,OAA7B,aAAa,UAAU,KAAK,CAAC;IAElF,SAAS,OAAA,CAAQ,OAAO,MAAM;IAC9B,OAAO;AACT;AAEA,SAAS,aAAa,IAAA,EAAqB;IACzC,OAAQ,KAAK,IAAA,EAAM;QACjB,KAAK;YACH,OAAO,KAAK,KAAA;QACd,KAAK;YACH,OAAO,KAAK,KAAA;QACd,KAAK;YACH,OAAO,KAAK,IAAA;IAChB;AACF;AAEA,SAAS,wBACP,EAAA,EACA,QAAA,EACA,OAAA,EACA,GAAA,EACA,IAAA,EACA,aAAA,EACA;IAGA,IAAI,GAAG,QAAA,CAAS,KAAA,KAAU,KAAK,eAAe;QAC5C,OAAO;IACT;IAEA,IAAA,mWAAA,EAAO,GAAG,QAAA,CAAS,KAAA,EAAO,6BAA6B;IACvD,MAAM,QAAQ,sBACZ,GAAG,QAAA,EACH,UACA,SACA,GAAW,OAAR,IAAI,EAAA,KAAqB,UAAd,QAAA,CAAS,KAAK,GAC5B,GAAG,WAAA,CAAY,UAAA;IAEjB,MAAM,WAAW,UAAG,IAAI,EAAA,UAA0B,OAAjB,GAAG,QAAA,CAAS,KAAK,EAAA;;IAClD,MAAM,OAAO,IAAI,KAAK;QACpB,QAAQ;QACR;QACA,SAAS,SAAS,aAAA,CAAc,QAAQ;QACxC,WAAW,GAAG,WAAA,CAAY,WAAA;QAC1B,UAAU,GAAG,WAAA,CAAY,UAAA;QACzB,kBAAkB,GAAG,QAAA,CAAS,KAAA;QAC9B,yBAAW,MAAA,cAAH,qCAAa;QACrB,sBAAQ,GAAG,MAAA,mDAAU;IACvB,CAAC;IACD,SAAS,OAAA,CAAQ,KAAK,IAAI;IAC1B,SAAS,OAAA,CAAQ,OAAO,IAAI;IAC5B,OAAO,SAAS,aAAA,CAAc,MAAM,QAAQ;AAC9C;AAEA,SAAS,iCACP,KAAA,EACA,SAAA,EACA,QAAA,EACA,IAAA,EACa;IACb,IAAA,mWAAA,EAAO,UAAU,EAAA,KAAO,YAAY,UAAU,EAAA,KAAO,YAAY;IACjE,IAAI,UAAU,OAAA,CAAQ,QAAA,CAAS,KAAA,KAAU,GAAG;QAC1C,IAAI,UAAU,EAAA,KAAO,UAAU;YAC7B,MAAMC,UAAS,IAAI,OAAO,OAAO,IAAM,KAAK;YAC5C,SAAS,OAAA,CAAQ,OAAOA,OAAM;YAC9B,OAAOA;QACT;QACA,MAAM,SAAS,IAAI,OAAO,OAAO,IAAM,IAAI;QAC3C,SAAS,OAAA,CAAQ,OAAO,MAAM;QAC9B,OAAO;IACT;IACA,MAAM,aAAa,UAAG,IAAI,EAAA,YAA2C,OAAhC,UAAU,OAAA,CAAQ,QAAA,CAAS,KAAK,EAAA;IACrE,MAAM,SAAS,IAAI,OACjB,OACA,SAAS,aAAA,CAAc,UAAU,GACjC,KAAK,UAAU,OAAA,CAAQ,QAAA,CAAS,KAAK,GACrC,UAAU,OAAA,CAAQ,WAAA,CAAY,WAAA,EAC9B,UAAU,EAAA;IAEZ,SAAS,OAAA,CAAQ,OAAO,MAAM;IAC9B,OAAO,SAAS,mBAAA,CAAoB,QAAQ,UAAU;AACxD;AAEA,SAAS,6CACP,SAAA,EACA;IACA,MAAM,OAA6B,CAAC,CAAA;IACpC,MAAM,SAAS,CAACC,eAAyB;QACvC,IAAIA,WAAU,IAAA,KAAS,sBAAsB;YAC3C,IAAA,mWAAA,EAAOA,WAAU,EAAA,KAAO,YAAYA,WAAU,EAAA,KAAO,YAAY;YACjE,KAAK,IAAA,CAAK;gBACR,GAAGA,WAAU,OAAA;gBACb,UAAU;oBACR,GAAGA,WAAU,OAAA,CAAQ,QAAA;oBACrB,OACEA,WAAU,OAAA,CAAQ,MAAA,KAAW,gBACzB,2BACA;gBACR;YACF,CAAC;YACD;QACF;QACA,IAAIA,WAAU,IAAA,KAAS,SAASA,WAAU,IAAA,KAAS,MAAM;YACvD,KAAA,MAAW,KAAKA,WAAU,UAAA,CAAY;gBACpC,OAAO,CAAC;YACV;YACA;QACF;IACF;IACA,IAAI,WAAW;QACb,OAAO,SAAS;IAClB;IACA,OAAO;AACT;AAEA,IAAM,eAAe;AACrB,IAAM,2BAA2B;AAE1B,SAAS,yBACd,QAAA,EACA,EAAA,EACM;IACN,MAAM,iBAAiB,SAAS,GAAA,CAAI;YAAC,CAAC,KAAK,CAAA;eAAM,KAAK;;IACtD,MAAM,gBAAgB,GAAG,MAAA,CAAO,CAAA,UAAW,CAAC,eAAe,QAAA,CAAS,OAAO,CAAC;IAE5E,IAAI,cAAc,MAAA,GAAS,GAAG;QAC5B,MAAM,IAAI,MACR,0DAEC,OAFyD,cAAc,IAAA,CACtE,OACD;IAML;AACF;AAEA,SAAS,2CAA2C,GAAA,EAAe;IACjE,IAAI,CAAC,IAAI,KAAA,EAAO;QACd,OAAO;IACT;IACA,MAAM,EAAC,KAAA,CAAK,CAAA,GAAI;IAChB,IAAI,MAAM,IAAA,KAAS,SAAS,MAAM,IAAA,KAAS,MAAM;QAC/C,OAAO;IACT;IAEA,IAAI,QAAQ;IACZ,MAAM,6BAA6B,CAAC;;eAAuC;YACzE,GAAG,IAAA;YACH,SAAS;gBACP,GAAG,KAAK,OAAA;gBACR,UAAU;oBACR,GAAG,KAAK,OAAA,CAAQ,QAAA;oBAChB,OAAA,sCAAa,OAAA,CAAQ,QAAA,CAAS,KAAA,wDAAtB,+BAA+B,EAAA,IAAM,MAAM;gBACrD;YACF;QACF;;IAEA,MAAM,WAAW,CAAC,SAA+B;QAC/C,IAAI,KAAK,IAAA,KAAS,UAAU;YAC1B,OAAO;QACT,OAAA,IAAW,KAAK,IAAA,KAAS,sBAAsB;YAC7C,OAAO,2BAA2B,IAAI;QACxC;QACA,MAAM,aAAa,CAAC,CAAA;QACpB,KAAA,MAAW,KAAK,KAAK,UAAA,CAAY;YAC/B,WAAW,IAAA,CAAK,SAAS,CAAC,CAAC;QAC7B;QACA,OAAO;YACL,MAAM,KAAK,IAAA;YACX;QACF;IACF;IAEA,MAAM,SAAS;QACb,GAAG,GAAA;QACH,OAAO,SAAS,KAAK;IACvB;IACA,OAAO;AACT;;AC9jBO,IAAM,sBAAN,cAAkC,MAAM;IAC7C,YAAY,OAAA,CAAiB;QAC3B,KAAA,CAAM,OAAO;QACb,IAAA,CAAK,IAAA,GAAO;IACd;AACF;;ACgBO,IAAM,6KAQF,2SARJ,MAAgE;IAwCrE,IAAI,OAAO;QACT,sPAAO,IAAA,EAAK,MAAA,CAAM,EAAE,CAAA;IACtB;IAEA,YAAY,QAAA,EAAuB;QACjC,IAAA,mWAAA,EAAO,gPAAC,IAAA,EAAK,YAAW,GAAA,CAAI,QAAQ,GAAG,6BAA6B;QACpE,+OAAA,IAAA,EAAK,YAAW,GAAA,CAAI,QAAQ;QAE5B,gPAAA,IAAA,iBAAK,mBAAL,IAAA,EAAmB,QAAQ;QAE3B,OAAO,MAAM;YACX,+OAAA,IAAA,EAAK,YAAW,MAAA,CAAO,QAAQ;QACjC;IACF;IAeA,UAAU;YACR,iBAAA;SAAA,kBAAA,CAAA,QAAA,IAAA,EAAK,SAAA,GAAY,WAAjB,sCAAA,qBAAA;IACF;IAgBA,KAAK,MAAA,EAAsB;6PACpB,QAAS;QACd,2PAAY,IAAA,EAAK,QAAO,uPAAQ,IAAA,EAAK,WAAS,mPAAI,IAAA,EAAK,OAAO;IAChE;IAEA,QAAQ;QACN,IAAI,gPAAC,IAAA,EAAK,SAAQ;YAChB;QACF;6PACK,QAAS;QACd,gPAAA,IAAA,kBAAK,eAAe,KAApB,IAAA;IACF;IAEA,UAAU,GAAA,EAAU;QAClB,+OAAA,IAAA,EAAK,iBAAL,IAAA,EAAgB,GAAG;IACrB;IArFA,YACE,KAAA,EACA,MAAA,EACA,aAAA,EACA,SAAA,CACA;;;;;;mBApBO;;8PACA;;mBAAa,aAAA,GAAA,IAAI,IAAiB;;;;wBAClC;;;;wBACA;;;;;;kQAMT;8PAEA;;mBAAS;;8PACT;;mBAAY;;;;wBACH;;6PAQF,SAAS;6PACT,UAAU,MAAM,SAAA,CAAU;6PAC1B,SAAU;6PACV,YAAa;6PACb,OAAQ;YAAC,IAAI,OAAO,QAAA,GAAW,KAAA,IAAY,CAAC,CAAA;QAAC;QAClD,MAAM,SAAA,CAAU,IAAI;QAEpB,IAAI,kBAAkB,MAAM;iQACrB,WAAY;QACnB,OAAO;YACL,KAAK,cAAc,IAAA,CAAK,MAAM;qQACvB,WAAY;gBACjB,gPAAA,IAAA,kBAAK,eAAe,KAApB,IAAA;YACF,CAAC;QACH;QACA,gPAAA,IAAA,YAAK,SAAS,KAAd,IAAA;IACF;AAgEF;;AC1GO,SAAS,kBAAkB,SAAA,EAA4B;IAC5D,OAAQ,UAAU,IAAA,EAAM;QACtB,KAAK;YAEH;QAEF,KAAK;YACH,IAAI,UAAU,EAAA,KAAO,cAAc;gBACjC,MAAM,IAAI,MACR;YAEJ;YAEA,IAAI,UAAU,OAAA,CAAQ,QAAA,CAAS,KAAA,EAAO;gBACpC,kBAAkB,UAAU,OAAA,CAAQ,QAAA,CAAS,KAAK;YACpD;YACA;QAEF,KAAK;QACL,KAAK;YACH,KAAA,MAAW,KAAK,UAAU,UAAA,CAAY;gBACpC,kBAAkB,CAAC;YACrB;YACA;QACF;YACE,IAAA,wWAAA,EAAY,SAAS;IACzB;AACF;;ApBeO,SAAS,YACd,KAAA,EACA,QAAA,EACA,gBAAA,EAIA,YAAA,EACA;IACA,IAAI,OAAO,qBAAqB,YAAY;QAC1C,OACG,KAAA,CAEE,cAAc,CAAA,CAAE,QAAQ,EACxB,WAAA,CAAY,8EAAkB,aAAc,GAAG;IAEtD;IACA,OACG,KAAA,CAEE,cAAc,CAAA,CAAE,QAAQ,EACxB,WAAA,qEAAY,iBAAkB,GAAG;AAExC;AAEA,IAAM,YAAY,OAAO;AAMlB,SAAS,SAId,QAAA,EACA,MAAA,EACA,KAAA,EACwB;IACxB,OAAO,IAAI,UACT,UACA,QACA,OACA;QAAC;IAAK,GACN,eACA,KAAA;AAEJ;AAEO,SAAS,YACd,WAAA,EACA,KAAA,EACW;IACX,OAAO;QACL,MAAM;QACN,QAAQ;QAAA,8BAAA;QAER,OAAO,MAAM,MAAA,KAAW,IAAI,KAAA,CAAM,CAAC,CAAA,GAAI;IACzC;AACF;AAEO,IAAM,cAAc;AAEpB,IAAM,gBAAgB;IAAC,UAAU;IAAO,eAAe,CAAC;AAAC;AAEzD,IAAM,iBAAiB,OAAO;AAE9B,IAAe,sUAAf,MAKP;IA+BE,CAAC,cAAc,EAAA,CAAE,QAAA,EAA0D;QACzE,OAAO,IAAA,CAAK,cAAc,CAAA,CACxB,yPACA,IAAA,EAAK,0PACL,IAAA,EAAK,aACL,IAAA,CAAK,IAAA,EACL,IAAA,CAAK,MAAA,EACL,IAAA,CAAK,aAAA,iPACL,IAAA,EAAK;IAET;IAEA,YACE,IAAA,EACA,IAAA,EACiC;QACjC,OAAO,IAAA,CAAK,cAAc,CAAA,CACxB,IAAA,CAAK,SAAA,iPACL,IAAA,EAAK,0PACL,IAAA,EAAK,aACL,IAAA,CAAK,IAAA,EACL,IAAA,CAAK,MAAA,EACL;YACE;YACA;QACF,kPACA,IAAA,EAAK;IAET;IAEA,IAAA,CAAK,SAAS,EAAA,GAAS;QACrB,OAAO,IAAA,CAAK,IAAA;IACd;IAEA,IAAI,MAAM;QACR,OAAO,IAAA,CAAK,YAAA,CAAa;IAC3B;IAEA,OAAe;QACb,IAAI,gPAAC,IAAA,EAAK,QAAO;iQACV,OAAQ,UAAU,IAAA,CAAK,YAAA,CAAa,CAAC;QAC5C;QACA,sPAAO,IAAA,EAAK;IACd;IA2aU,eAAoB;QAC5B,IAAI,gPAAC,IAAA,EAAK,gBAAe;YACvB,MAAM,eAAe,8PACnB,IAAA,EAAK,UAAQ,MAAA,gPAAO,IAAA,EAAK,UAAU,EAAA,EACnC,IAAA,CAAK,IAAA,CAAK,OAAA;YAEZ,IAAI,IAAA,CAAK,IAAA,CAAK,KAAA,EAAO;gBACnB,MAAM,EAAC,GAAA,CAAG,CAAA,GAAI,IAAA,CAAK,IAAA,CAAK,KAAA;gBACxB,MAAM,cAAgC,CAAC;gBACvC,KAAA,MAAW,CAAC,KAAK,CAAA,IAAK,aAAc;oBAClC,WAAA,CAAY,KAAK,CAAA,GAAI,GAAA,CAAI,KAAK,CAAA;gBAChC;qQACK,eAAgB;oBACnB,GAAG,IAAA,CAAK,IAAA;oBACR,OAAO;wBACL,GAAG,IAAA,CAAK,IAAA,CAAK,KAAA;wBACb,KAAK;oBACP;oBACA,SAAS;gBACX;YACF,OAAO;qQACA,eAAgB;oBACnB,GAAG,IAAA,CAAK,IAAA;oBACR,SAAS,8PACP,IAAA,EAAK,UAAQ,MAAA,gPAAO,IAAA,EAAK,UAAU,EAAA,EACnC,IAAA,CAAK,IAAA,CAAK,OAAA;gBAEd;YACF;QACF;QACA,sPAAO,IAAA,EAAK;IACd;IAEA,KACE,WAAA,EAIA,UAAA,EAIkC;QAClC,OAAO,IAAA,CAAK,GAAA,CAAI,EAAE,IAAA,CAAK,aAAa,UAAU;IAChD;IAthBA,YACE,QAAA,EACA,MAAA,EACA,SAAA,EACA,GAAA,EACA,MAAA,EACA,MAAA,EACA,aAAA,EACA,eAAA,CACA;;;;;;kQAlBiB;;;wBACV;;kQACA;oQACA;;;mBACO;;;;wBACP;;;;wBACA;;2QACA;QAkFT,oPAAM,IACJ,IAAA,CAAK,cAAc,CAAA,CACjB,IAAA,CAAK,SAAA,iPACL,IAAA,EAAK,0PACL,IAAA,EAAK,aACL;gBACE,GAAG,IAAA,CAAK,IAAA;gBACR,OAAO;YACT,GACA;gBACE,GAAG,IAAA,CAAK,MAAA;gBACR,UAAU;YACZ,GACA,IAAA,CAAK,aAAA,iPACL,IAAA,EAAK;qPAGT,eAAc,CACZ,cACA,KAEA,IAAA,CAAK,KAAA,CAAM;oBAAC,EAAC,MAAA,CAAM,CAAA;uBAAM,OAAO,cAAc,EAAE,CAAC;;qPAEnD,WAAU,CACR,cACA,OACa;YACb,IAAI,aAAa,UAAA,CAAW,WAAW,GAAG;gBACxC,MAAM,IAAI,MACR,0CAAqD,OAAX,WAAW,EAAA;YAEzD;YACA,oCAAK,KAAO,CAAA,IAAK;YAEjB,MAAM,yPAAU,IAAA,EAAK,UAAQ,aAAA,gPAAc,IAAA,EAAK,UAAU,EAAA,CAAE,YAAY,CAAA;YACxE,IAAA,mWAAA,EAAO,SAAS,sBAAsB;YACtC,IAAI,SAAS,OAAO,GAAG;gBACrB,MAAM,EAAC,UAAA,EAAY,SAAA,EAAW,WAAA,EAAa,WAAA,CAAW,CAAA,GAAI,OAAA,CAAQ,CAAC,CAAA;gBACnE,IAAI,IAAc,IAAA,CAAK,cAAc,CAAA,CACnC,IAAA,CAAK,SAAA,iPACL,IAAA,EAAK,WACL,YACA;oBACE,OAAO;oBACP,OAAO;gBACT,GACA;oBACE,eAAe,CAAC;oBAChB,UAAU,gBAAgB;gBAC5B,GACA,IAAA,CAAK,aAAA,EACL,KAAA;gBAEF,IAAI,gBAAgB,OAAO;oBACzB,IAAI,EAAE,GAAA,CAAI;gBACZ;gBACA,MAAM,KAAK,GAAG,CAAC;gBACf,IAAA,mWAAA,EACE,cAAc,WAAW,GACzB;gBAEF,IAAA,mWAAA,EACE,cAAc,SAAS,GACvB;gBAEF,IAAA,mWAAA,EACE,YAAY,MAAA,KAAW,UAAU,MAAA,EACjC;oBAUQ;gBAPV,OAAO,IAAA,CAAK,cAAc,CAAA,CACxB,IAAA,CAAK,SAAA,iPACL,IAAA,EAAK,0PACL,IAAA,EAAK,aACL;oBACE,GAAG,IAAA,CAAK,IAAA;oBACR,SAAS;qDACH,CAAK,IAAA,CAAK,OAAA,mEAAW,CAAC,CAAA;wBAC1B;4BACE,MAAA,iPAAQ,IAAA,EAAK;4BACb,aAAa;gCACX,aAAa;gCACb,YAAY;4BACd;4BACA,UAAU,mQACR,IAAA,EAAK,UAAQ,MAAA,CAAO,UAAU,CAAA,EAC9B,GAAG,IAAA;wBAEP;qBACF;gBACF,GACA;oBACE,GAAG,IAAA,CAAK,MAAA;oBACR,eAAe;wBACb,GAAG,IAAA,CAAK,MAAA,CAAO,aAAA;wBACf,CAAC,YAAY,CAAA,EAAG,GAAG,MAAA;oBACrB;gBACF,GACA,IAAA,CAAK,aAAA,iPACL,IAAA,EAAK;YAET;YAEA,IAAI,SAAS,OAAO,GAAG;gBACrB,MAAM,CAAC,eAAe,cAAc,CAAA,GAAI;gBACxC,MAAM,EAAC,UAAA,CAAU,CAAA,GAAI;gBACrB,MAAM,iBAAiB,cAAc,UAAA;gBACrC,MAAM,KAAK,GACT,IAAA,CAAK,cAAc,CAAA,CACjB,IAAA,CAAK,SAAA,iPACL,IAAA,EAAK,WACL,YACA;oBACE,OAAO;oBACP,OAAO;gBACT,GACA;oBACE,eAAe,CAAC;oBAChB,UAAU,eAAe,WAAA,KAAgB;gBAC3C,GACA,IAAA,CAAK,aAAA,EACL;gBAIJ,IAAA,mWAAA,EAAO,cAAc,cAAc,WAAW,GAAG,sBAAsB;gBACvE,IAAA,mWAAA,EAAO,cAAc,cAAc,SAAS,GAAG,sBAAsB;gBACrE,IAAA,mWAAA,EAAO,cAAc,eAAe,WAAW,GAAG,sBAAsB;gBACxE,IAAA,mWAAA,EAAO,cAAc,eAAe,SAAS,GAAG,sBAAsB;oBAS5D;gBAPV,OAAO,IAAA,CAAK,cAAc,CAAA,CACxB,IAAA,CAAK,SAAA,iPACL,IAAA,EAAK,0PACL,IAAA,EAAK,aACL;oBACE,GAAG,IAAA,CAAK,IAAA;oBACR,SAAS;sDACH,CAAK,IAAA,CAAK,OAAA,qEAAW,CAAC,CAAA;wBAC1B;4BACE,MAAA,iPAAQ,IAAA,EAAK;4BACb,aAAa;gCACX,aAAa,cAAc,WAAA;gCAC3B,YAAY,cAAc,SAAA;4BAC5B;4BACA,QAAQ;4BACR,UAAU;gCACR,OAAO;gCACP,OAAO;gCACP,SAAS,8PACP,IAAA,EAAK,UAAQ,MAAA,CAAO,cAAc,CAAA,EAClC,KAAA;gCAEF,SAAS;oCACP;wCACE,MAAA,iPAAQ,IAAA,EAAK;wCACb,aAAa;4CACX,aAAa,eAAe,WAAA;4CAC5B,YAAY,eAAe,SAAA;wCAC7B;wCACA,UAAU,mQACR,IAAA,EAAK,UAAQ,MAAA,CAAO,UAAU,CAAA,EAC9B,GAAG,IAAA;oCAEP;iCACF;4BACF;wBACF;qBACF;gBACF,GACA;oBACE,GAAG,IAAA,CAAK,MAAA;oBACR,eAAe;wBACb,GAAG,IAAA,CAAK,MAAA,CAAO,aAAA;wBACf,CAAC,YAAY,CAAA,EAAG,GAAG,MAAA;oBACrB;gBACF,GACA,IAAA,CAAK,aAAA,iPACL,IAAA,EAAK;YAET;YAEA,MAAM,IAAI,MAAM,wBAAoC,CAAE,MAAd,YAAY;QACtD;qPAEA,SAAQ,CACN,0BACA,WACA,UACoC;YACpC,IAAI;YAEJ,IAAI,OAAO,6BAA6B,YAAY;gBAClD,OAAO,yBACL,IAAI,kBAAkB,IAAA,CAAK,OAAO;YAKtC,OAAO;gBACL,IAAA,mWAAA,EAAO,cAAc,KAAA,GAAW,mBAAmB;gBACnD,OAAO,IAAI,0BAA0B,WAAW,KAAK;YACvD;YAEA,MAAM,gBAAgB,IAAA,CAAK,IAAA,CAAK,KAAA;YAChC,IAAI,eAAe;gBACjB,OAAO,IAAI,eAAe,IAAI;YAChC;YAEA,MAAM,QAAQ,kBAAkB,IAAI;YAEpC,mPAAI,IAAA,EAAK,aAAY,UAAU;gBAG7B,kBAAkB,KAAK;YACzB;YAEA,OAAO,IAAA,CAAK,cAAc,CAAA,CACxB,IAAA,CAAK,SAAA,iPACL,IAAA,EAAK,0PACL,IAAA,EAAK,aACL;gBACE,GAAG,IAAA,CAAK,IAAA;gBACR;YACF,GACA,IAAA,CAAK,MAAA,EACL,IAAA,CAAK,aAAA,iPACL,IAAA,EAAK;QAET;qPAEA,SAAQ,CACN,KACA,OAEA,IAAA,CAAK,cAAc,CAAA,CACjB,IAAA,CAAK,SAAA,iPACL,IAAA,EAAK,0PACL,IAAA,EAAK,aACL;gBACE,GAAG,IAAA,CAAK,IAAA;gBACR,OAAO;oBACL;oBACA,WAAW,8CAAC,KAAM,SAAA;gBACpB;YACF,GACA,IAAA,CAAK,MAAA,EACL,IAAA,CAAK,aAAA,iPACL,IAAA,EAAK;qPAGT,SAAQ,CAAC,UAAmD;YAC1D,IAAI,QAAQ,GAAG;gBACb,MAAM,IAAI,MAAM,4BAA4B;YAC9C;YACA,IAAA,CAAK,QAAQ,CAAA,MAAO,OAAO;gBACzB,MAAM,IAAI,MAAM,0BAA0B;YAC5C;YACA,mPAAI,IAAA,EAAK,mBAAkB;gBACzB,MAAM,IAAI,oBACR,+UACE,IAAA,EAAK;YAEX;YAEA,OAAO,IAAA,CAAK,cAAc,CAAA,CACxB,IAAA,CAAK,SAAA,iPACL,IAAA,EAAK,0PACL,IAAA,EAAK,aACL;gBACE,GAAG,IAAA,CAAK,IAAA;gBACR;YACF,GACA,IAAA,CAAK,MAAA,EACL,IAAA,CAAK,aAAA,iPACL,IAAA,EAAK;QAET;qPAEA,WAAU,CACR,OACA,cACoC;YACpC,mPAAI,IAAA,EAAK,mBAAkB;gBACzB,MAAM,IAAI,oBACR,kVACE,IAAA,EAAK;YAEX;gBAOkB;YANlB,OAAO,IAAA,CAAK,cAAc,CAAA,CACxB,IAAA,CAAK,SAAA,iPACL,IAAA,EAAK,0PACL,IAAA,EAAK,aACL;gBACE,GAAG,IAAA,CAAK,IAAA;gBACR,SAAS,CAAC;iDAAI,CAAK,IAAA,CAAK,OAAA,mEAAW,CAAC,CAAA;oBAAI;wBAAC;wBAAiB,SAAS;qBAAC;iBAAA;YACtE,GACA,IAAA,CAAK,MAAA,EACL,IAAA,CAAK,aAAA,iPACL,IAAA,EAAK;QAET;qPAEU,WAAU,SAClB;gBACA,sEAAoC,CAAA,IAAK,MAC3B;YACd,MAAM,UAAU,sPAAK,UAAQ,aAAA,CAAc,sPAAK,UAAU,EAAA,CAAE,YAAY,CAAA;YACxE,IAAA,mWAAA,EAAO,SAAS,sBAAsB;YAEtC,IAAI,SAAS,OAAO,GAAG;gBACrB,MAAM,EAAC,UAAA,EAAY,WAAA,EAAa,SAAA,CAAS,CAAA,GAAI,OAAA,CAAQ,CAAC,CAAA;gBACtD,IAAA,mWAAA,EAAO,cAAc,WAAW,GAAG,sBAAsB;gBACzD,IAAA,mWAAA,EAAO,cAAc,SAAS,GAAG,sBAAsB;gBAEvD,MAAM,KAAK,GACT,KAAA,CAAK,cAAc,CAAA,CACjB,MAAK,SAAA,wPACA,WACL,YACA;oBACE,OAAO;oBACP,OAAO,UAAG,WAAW,EAAe,OAAZ,YAAY;gBACtC,GACA,eACA,MAAK,aAAA,EACL,KAAA;gBAGJ,OAAO;oBACL,MAAM;oBACN,SAAS;wBACP,MAAA,EAAQ,sPAAK;wBACb,aAAa;4BACX,aAAa;4BACb,YAAY;wBACd;wBACA,UAAU,oBACR,sPAAK,UAAQ,MAAA,CAAO,UAAU,CAAA,EAC9B,GAAG,IAAA;oBAEP;oBACA,IAAI;gBACN;YACF;YAEA,IAAI,SAAS,OAAO,GAAG;gBACrB,MAAM,CAAC,eAAe,cAAc,CAAA,GAAI;gBACxC,IAAA,mWAAA,EAAO,cAAc,cAAc,WAAW,GAAG,sBAAsB;gBACvE,IAAA,mWAAA,EAAO,cAAc,cAAc,SAAS,GAAG,sBAAsB;gBACrE,IAAA,mWAAA,EAAO,cAAc,eAAe,WAAW,GAAG,sBAAsB;gBACxE,IAAA,mWAAA,EAAO,cAAc,eAAe,SAAS,GAAG,sBAAsB;gBACtE,MAAM,EAAC,UAAA,CAAU,CAAA,GAAI;gBACrB,MAAM,iBAAiB,cAAc,UAAA;gBACrC,MAAM,cAAc,GAClB,KAAA,CAAK,cAAc,CAAA,CACjB,MAAK,SAAA,wPACA,WACL,YACA;oBACE,OAAO;oBACP,OAAO,UAAG,WAAW,EAAA,YAAuB,OAAZ,YAAY;gBAC9C,GACA,eACA,MAAK,aAAA,EACL;gBAIJ,OAAO;oBACL,MAAM;oBACN,SAAS;wBACP,MAAA,EAAQ,sPAAK;wBACb,aAAa;4BACX,aAAa,cAAc,WAAA;4BAC3B,YAAY,cAAc,SAAA;wBAC5B;wBACA,UAAU;4BACR,OAAO;4BACP,OAAO,UAAG,WAAW,EAAe,OAAZ,YAAY;4BACpC,SAAS,eACP,sPAAK,UAAQ,MAAA,CAAO,cAAc,CAAA,EAClC,KAAA;4BAEF,OAAO;gCACL,MAAM;gCACN,SAAS;oCACP,MAAA,EAAQ,sPAAK;oCACb,aAAa;wCACX,aAAa,eAAe,WAAA;wCAC5B,YAAY,eAAe,SAAA;oCAC7B;oCAEA,UAAU,oBACR,sPAAK,UAAQ,MAAA,CAAO,UAAU,CAAA,EAC7B,YAAoC,IAAA;gCAEzC;gCACA,IAAI;4BACN;wBACF;oBACF;oBACA,IAAI;gBACN;YACF;YAEA,MAAM,IAAI,MAAM,wBAAoC,CAAE,MAAd,YAAY;QACtD;;;mBAEA;;6PA9dO,UAAU;QACf,IAAA,CAAK,SAAA,GAAY;6PACZ,YAAa;QAClB,IAAA,CAAK,IAAA,GAAO;QACZ,IAAA,CAAK,MAAA,GAAS;6PACT,SAAU;6PACV,kBAAmB;QACxB,IAAA,CAAK,aAAA,GAAgB;IACvB;AAohBF;AAEA,IAAM,qBAAqB,OAAO;AAM3B,IAAM,aAKF,oHALJ,MAAM,mBAIH,cAAwC;IA0BhD,IAAA,qBAAuB,GAAS;QAC9B,OAAO,IAAA,CAAK,YAAA,CAAa;IAC3B;IAEA,iBAAyB,CAKvB,QAAA,EACA,MAAA,EACA,SAAA,EACA,GAAA,EACA,MAAA,EACA,aAAA,EACA,eAAA,EACqC;QACrC,OAAO,IAAI,WACT,UACA,QACA,WACA,KACA,uPACA,IAAA,EAAK,WACL,eACA;IAEJ;IAEA,YACE,YAAA,EAEG;kBADH,iEAAW;QAEX,MAAM,WAAW,KACf,IAAA,CAAK,SAAA,EACL;QAEF,IAAI;QACJ,IAAI,OAAO,iBAAiB,YAAY;YACtC,UAAU;QACZ,OAAO;YACL,yDAAM,eAAgB;QACxB;QACA,MAAM,MAAM,IAAA,CAAK,YAAA,CAAa;QAC9B,MAAM,UAAU,IAAA,CAAK,aAAA,GACjB,kBAAkB,IAAA,CAAK,aAAA,CAAc,IAAA,EAAM,IAAA,CAAK,aAAA,CAAc,IAAI,IAClE,IAAA,CAAK,IAAA,CAAK;QACd,MAAM,4BAAwB,2OAAA,CAAe;QAC7C,IAAI,gBAAgB,SAAS,oBAAA;QAC7B,MAAM,YAAY,CAAC,WAAgB;YACjC,IAAA,CAAK,aAAA,GACD,SAAS,iBAAA,CAAkB,IAAA,CAAK,aAAA,EAAe,MAAM,IACrD,SAAS,iBAAA,CAAkB,KAAK,MAAM;QAC5C;QAEA,MAAM,cAA2B,CAAA,QAAO;YACtC,IAAI,KAAK;gBACP,SAAS,SAAA,CACP,oCACA,YAAY,GAAA,CAAI,IAAI,IACpB,SACA;gBAEF,gBAAgB;gBAChB,sBAAsB,OAAA,CAAQ,IAAI;YACpC;QACF;QAEA,IAAI;QACJ,MAAM,YAAY,MAAM;YACtB,MAAM,OAAA,CAAQ;YACd,iCAAA,2CAAA,uBAAuB;YACvB,iBAAiB;QACnB;QAEA,MAAM,KAAK,YAAY,GAAA,CAAI;QAE3B,MAAM,mBAAmB,IAAA,CAAK,aAAA,GAC1B,SAAS,cAAA,CAAe,KAAK,IAAA,CAAK,aAAA,EAAe,KAAK,WAAW,IACjE,SAAS,cAAA,CAAe,KAAK,KAAK,WAAW;QAEjD,MAAM,QAAQ,cAAc,KAAK,UAAU,OAAO;QAElD,MAAM,OAAO,SAAS,gBAAA,CAAiB,IAAA,0CACpC,UAAW,gBAAA,EACV,IAAA,EACA,OACA,IAAA,CAAK,MAAA,EACL,WACA,CAAA,OAAM;gBACJ,uBAAuB,SAAS,mBAAA,CAAoB,EAAE;YACxD,GACA,iBAAiB,sBAAsB,OAAA,EACvC;QAIJ,SAAS,SAAA,CACP,gCACA,YAAY,GAAA,CAAI,IAAI,IACpB;QAGF,OAAO;IACT;IAEA,IAAI,OAAA,EAAuD;QACzD,MAAM,WAAW,KACf,IAAA,CAAK,SAAA,EACL;QAEF,SAAS,qBAAA,CAAsB,OAAO;QACtC,MAAMC,KAAuC,IAAA,CAAK,WAAA,CAAY,0DAAS,GAAG;QAC1E,uDAAI,QAAS,IAAA,MAAS,YAAY;YAChC,OAAO,IAAI,QAAQ,CAAA,YAAW;gBAC5BA,GAAE,WAAA,CAAY,CAAC,MAAM,SAAS;oBAC5B,IAAI,SAAS,YAAY;wBACvBA,GAAE,OAAA,CAAQ;wBACV,QAAQ,IAA8B;oBACxC;gBACF,CAAC;YACH,CAAC;QACH;QAEA,oBAAA,8BAAA,QAAS,IAAA;QAET,MAAM,MAAMA,GAAE,IAAA;QACdA,GAAE,OAAA,CAAQ;QACV,OAAO,QAAQ,OAAA,CAAQ,GAAG;IAC5B;IAEA,QAAQ,OAAA,EAGN;QACA,MAAM,WAAW,KACf,IAAA,CAAK,SAAA,EACL;;QAEF,MAAM,sBAAM,0DAAS,GAAA,uDAAO;QAC5B,MAAM,MAAM,IAAA,CAAK,YAAA,CAAa;QAC9B,MAAM,EAAC,OAAA,EAAS,SAAS,QAAA,CAAQ,CAAA,OAAI,2OAAA,CAAe;QACpD,IAAI,IAAA,CAAK,aAAA,EAAe;YACtB,MAAMC,WAAU,SAAS,cAAA,CACvB,KACA,IAAA,CAAK,aAAA,EACL,KACA,CAAA,QAAO;gBACL,IAAI,KAAK;oBACP,QAAQ;gBACV;YACF;YAEF,OAAO;gBACL,SAAAA;gBACA;YACF;QACF;QAEA,MAAM,UAAU,SAAS,cAAA,CAAe,KAAK,KAAK,CAAA,QAAO;YACvD,IAAI,KAAK;gBACP,QAAQ;YACV;QACF,CAAC;QACD,OAAO;YACL;YACA;QACF;IACF;IA/LA,YACE,QAAA,EACA,MAAA,EACA,SAAA,EACA,MAAW;QAAC,OAAO;IAAS,CAAA,EAC5B,SAAiB,aAAA,EACjB,SAAiB,QAAA,EACjB,aAAA,EACA,eAAA,CACA;QACA,KAAA,CACE,UACA,QACA,WACA,KACA,QACA,QACA,eACA;;;;6PAEG,UAAU;IACjB;AA2KF;AAEA,SAAS,eACP,MAAA,EACA,OAAA,EACU;IACV,mDAAU,UAAW,CAAC,CAAA;IACtB,MAAM,EAAC,UAAA,CAAU,CAAA,GAAI;IACrB,MAAM,mBAAmB,IAAI,IAAI,UAAU;IAE3C,KAAA,MAAW,CAAC,KAAK,CAAA,IAAK,QAAS;QAC7B,iBAAiB,MAAA,CAAO,KAAK;IAC/B;IAEA,IAAI,iBAAiB,IAAA,KAAS,GAAG;QAC/B,OAAO;IACT;IAEA,OAAO;WACF;WACA,CAAC;eAAG,gBAAgB;SAAA,CAAE,GAAA,CAAI,CAAA,MAAO;gBAAC;gBAAK,KAAK;aAAoB;KACrE;AACF;AAEA,SAAS,oBAAoB,MAAA,EAAqB,GAAA,EAAe;IAC/D,OAAO;QACL,GAAG,GAAA;QACH,SAAS,eAAe,QAAQ,IAAI,OAAO;IAC7C;AACF;AAEA,SAAS,iBAKP,MAAA,EACA,KAAA,EACA,MAAA,EACA,SAAA,EACA,mBAAA,EACA,aAAA,EACA,SAAA,EACmC;IACnC,MAAMD,KAAI,IAAI,UACZ,OACA,QACA,eACA;IAEFA,GAAE,SAAA,GAAY;IACd,oBAAoB,MAAM;QACxBA,GAAE,KAAA,CAAM;IACV,CAAC;IACD,OAAOA;AACT;AAEA,SAAS,cAAc,KAAA,EAAgD;IACrE,OAAO,MAAM,OAAA,CAAQ,KAAK,KAAK,MAAM,MAAA,IAAU;AACjD;;SzC1nBE,OACE,IAAA,EACA,KAAA,EACA,WAAA;IAAA,IAAA,IAAA,OAAA,UAAA,QAAA,QAAA,UAAA,OAAA,IAAA,OAAA,QAAA,OAAA,GAAA,OAAA,MAAA;QACG,MADH,OAAA,KAAA,SAAA,CAAA,KACG,EACW;;IACd,IAAI,IAAA,CAAK,SAAA,EAAW;QAClB,IAAA,CAAK,OAAA,CAAQ,MAAA,CAAO,OAAO,aAAa,GAAG,KAAK;QAChD,IAAA,CAAK,WAAA,CAAY,IAAI;QACrB,OAAO,IAAA;IACT;IAEA,MAAM,UAAU,eAAe,IAAA,CAAK,OAAA,EAAS,OAAO,aAAa,GAAG,KAAK;IACzE,OAAO,KAAK,eAAA,CAAgB,OAAO;AACrC;iCA2FE,IAAA,EACA,CAAA,EACA,SAAA,EAC2B;IAC3B,MAAM,QAAQ,IAAA,CAAK,KAAA,GAAQ;IAC3B,MAAM,cAAc,IAAA,CAAK,OAAA;IAIzB,IAAI;IACJ,IAAI;IACJ,IAAI;IACJ,IAAI,IAAI,GAAG;QACT,MAAM9D,QAAO,WAAA,CAAY,IAAI,CAAC,CAAA,CAAE,CAAC,CAAA;QACjC,MAAM,kBAAkB,MAAM,KAAK,OAAA,CAAQA,KAAI;QAC/C,SAAS,cACP,gBAAgB,OAAA,EAChB,UAAU,OAAA;QAEZ,aAAa,IAAI;QACjB,cAAc;IAChB,OAAA,IAAW,IAAI,YAAY,MAAA,GAAS,GAAG;QACrC,MAAMA,QAAO,WAAA,CAAY,IAAI,CAAC,CAAA,CAAE,CAAC,CAAA;QACjC,MAAM,cAAc,MAAM,KAAK,OAAA,CAAQA,KAAI;QAC3C,SAAS,cACP,UAAU,OAAA,EACV,YAAY,OAAA;QAEd,aAAa;QACb,cAAc;IAChB,OAAO;QACL,SAAS,UAAU,OAAA;QACnB,aAAa;QACb,cAAc;IAChB;IAEA,MAAM,aAAa,UACjB,QACA,CAAA,QAAS,KAAA,CAAM,CAAC,CAAA,EAChB,KAAK,OAAA,GAAU,KAAK,eAAA,EACpB,KAAK,OAAA,GAAU,KAAK,eAAA;IAKtB,MAAM,aAA4B,CAAC,CAAA;IACnC,KAAA,MAAWG,YAAW,WAAY;QAChC,MAAM,OAAO,KAAK,WAAA,CAAYA,UAAS,KAAK;QAC5C,MAAM,eAAe,8BACnB,MACA,KAAK,YAAA;QAEP,WAAW,IAAA,CAAK,YAAY;IAC9B;IAEA,IAAI,IAAA,CAAK,SAAA,EAAW;QAClB,IAAA,CAAK,OAAA,CAAQ,MAAA,CAAO,YAAY,aAAa,GAAG,UAAU;QAC1D,IAAA,CAAK,WAAA,CAAY,IAAI;QACrB,OAAO,IAAA;IACT;IAEA,MAAM,UAAU,eACd,aACA,YACA,gBACG;IAGL,OAAO,KAAK,mBAAA,CAAoB,SAAS,IAAA,CAAK,KAAK;AACrD;sBAGE,IAAA,EACA,KAAA,EACA,QAAA,EACkB;IAClB,IAAI,IAAA,CAAK,SAAA,EAAW;QAClB,IAAA,CAAK,OAAA,CAAQ,MAAA,CAAO,OAAO,GAAG,QAAQ;QACtC,IAAA,CAAK,WAAA,CAAY,IAAI;QACrB,OAAO,IAAA;IACT;IACA,MAAM,UAAU,eAAe,IAAA,CAAK,OAAA,EAAS,OAAO,GAAG,QAAQ;IAC/D,OAAO,KAAK,mBAAA,CAAoB,SAAS,IAAA,CAAK,KAAK;AACrD;Sc/bA,cAAe,IAAA,EAA6C;IAC1D,IAAA,mWAAA,EAAO,KAAK,SAAS;IACrB,+OAAA,IAAA,EAAK,WAAU,GAAA,CAAI,KAAK,IAAA,EAAM,IAAI;IAClC,IAAA,CAAK,MAAA,CAAO,GAAA,CAAI,KAAK,IAAA,EAAM,IAAI;AACjC;6BGuHqB,UAAA,EAAsD;IACzE,MAAM,WAAW,IAAI,SAAS;IAC9B,IAAI,CAAC,WAAW,kBAAA,CAAmB,GAAG;QACpC,OAAO;IACT;IAEA,IAAI,YAA0B,CAAC,CAAA;IAC/B,mPAAI,IAAA,EAAK,SAAQ;QACf,MAAM,WAAW,IAAI,yPACnB,IAAA,EAAK,2PACL,IAAA,EAAK,gQACL,IAAA,EAAK,QAAO,SAAA;QAEd,YAAY,MAAM,KAAK,UAAU,IAAA,CAAK,GAAG;IAC3C;IACA,SAAS,GAAA,CAAI,IAAI,SAAS;IAC1B,IAAI;IACJ,mPAAI,IAAA,EAAK,SAAQ;QACf,eAAe,kQACb,IAAA,EAAK,wPACL,IAAA,EAAK,2PACL,IAAA,EAAK;IAET,OAAO;QACL,eAAe,aAAA,GAAA,IAAI,IAAI;IACzB;IAEA,KAAA,MAAW,CAAC,MAAM,KAAK,CAAA,IAAK,IAAA,CAAK,OAAA,CAAS;QACxC,IAAI,CAAC,WAAW,0BAAA,CAA2B,IAAI,GAAG;YAChD;QACF;QACA,MAAM,aAAa,aAAa,GAAA,CAAI,IAAI;QACxC,IAAA,mWAAA,EAAO,UAAU,UAAU;QAE3B,MAAM,kBAAkB,MAAA,CAAO,aAC3B,KAAK,WAAW,GAAA,EAAK,MAAM,GAAG,IAAA,8BAAA;QAE9B,iBAAiB,MAAM,GAAA,EAAK,KAAK,CAAA;QACrC,SAAS,GAAA,CAAI,MAAM,eAAe;IACpC;IAIA,KAAA,MAAW,CAAC,MAAM,UAAU,CAAA,IAAK,aAAc;QAC7C,IACE,CAAC,IAAA,CAAK,OAAA,CAAQ,GAAA,CAAI,IAAI,KACtB,WAAW,0BAAA,CAA2B,IAAI,GAC1C;YACA,MAAM,kBAAkB,MAAM,iBAAiB,WAAW,GAAA,EAAK,KAAK;YACpE,SAAS,GAAA,CAAI,MAAM,eAAe;QACpC;IACF;IACA,OAAO;AACT;;IqBtIE,mPACE,IAAA,EAAK,cAAa,MAAA,GAAS,oPAC3B,IAAA,EAAK,YAAW,MAAA,kPAAS,IAAA,EAAK,gBAC9B;QAEA,+OAAA,IAAA,EAAK,cAAa,IAAA,CAAK,kPAAG,IAAA,EAAK,UAAU;QACzC,gQAAiB,IAAA,EAAK,YAAY;QAGlC,+OAAA,IAAA,EAAK,YAAW,MAAA,GAAS;QACzB,+OAAA,IAAA,EAAK,YAAW,IAAA,gPAAK,IAAA,EAAK,aAAA,CAAa,CAAC,CAAC;8fAEzC,IAAA,EAAK,mQAAoB,IAAA,EAAK;6PACzB,oBAAqB;QAC1B,IAAI,uPAAQ,IAAA,EAAK,aAAA,CAAa,CAAC,CAAA,CAAE,MAAA;QACjC,IAAI,uPAAQ,IAAA,EAAK,wQAAmB,gBAAK,kBAAL,IAAA,EAAkB,CAAC;QACvD,IAAA,IAAS,IAAI,GAAG,mPAAI,IAAA,EAAK,cAAa,MAAA,EAAQ,IAAK;YACjD,MAAM,0PAAW,IAAA,EAAK,aAAA,CAAa,CAAC,CAAA;YACpC,MAAM,YAAY,QAAQ,SAAS,MAAA;YACnC,IAAI,aAAa,OAAO;gBACtB,QAAQ;gBACR,+OAAA,IAAA,EAAK,WAAA,gPAAW,IAAA,EAAK,YAAW,MAAA,GAAS,CAAC,CAAA,CAAE,GAAA,CAAI,QAAQ;YAC1D,OAAO;gBACL,MAAM,yPAAK,uBAAK,yBAAL,IAAA,EAAyB,uPAAQ,IAAA,EAAK,gBAAgB;gBACjE,uPAAQ,IAAA,EAAK,wQAAmB,EAAK,gCAAL,IAAA,EAAkB,KAAK,CAAC;gBACxD,SAAS,SAAS,MAAA;gBAClB,+OAAA,IAAA,EAAK,YAAW,IAAA,CAAK,QAAQ;YAC/B;QACF;6PACK,MAAO,KAAK,GAAA,gPAAI,IAAA,EAAK,sPAAM,IAAA,EAAK,WAAA,CAAW,CAAC,CAAA,CAAE,IAAI;6PAClD,MAAO,KAAK,GAAA,gPACf,IAAA,EAAK,OACL,mPAAA,EAAK,WAAA,gPAAW,IAAA,EAAK,YAAW,MAAA,GAAS,CAAC,CAAA,CAAE,IAAA;QAE9C,+OAAA,IAAA,EAAK,cAAa,MAAA,GAAS;IAC7B;AACF;SAmCA,oBAAoB;IAIlB,mPACE,IAAA,EAAK,aAAY,MAAA,GAAS,oPAC1B,IAAA,EAAK,YAAA,gPAAY,IAAA,EAAK,aAAY,MAAA,GAAS,CAAC,CAAA,oPAAM,IAAA,EAAK,mBACvD;QACA;IACF;IACA,MAAM,mPAAI,IAAA,EAAK,YAAW,MAAA,GAAS;IACnC,IAAI,mPAAA,EAAK,aAAY,MAAA,GAAS,GAAG;QAC/B,+OAAA,IAAA,EAAK,aAAY,MAAA,GAAS;IAC5B;IAEA,IAAI,OAAO;IACX,IAAA,IAAS,IAAI,GAAG,mPAAI,IAAA,EAAK,YAAW,MAAA,EAAQ,IAAK;QAC/C,MAAM,0PAAW,IAAA,EAAK,WAAA,CAAW,CAAC,CAAA;QAClC,MAAM,MAAM,SAAS,MAAA;QACrB,+OAAA,IAAA,EAAK,YAAA,CAAY,CAAC,CAAA,GAAI,OAAO,MAAM;QACnC,QAAQ;IACV;IACA,+OAAA,IAAA,EAAK,YAAA,gPAAY,IAAA,EAAK,YAAW,MAAM,CAAA,GAAI;AAC7C;SAgIA,YAAa,CAAA,EAAmB;IAC9B,OAAA,CACG,KAAK,GAAA,CACH,KAAK,GAAA,CAAI,GAAG,IAAA,CAAK,WAAW,IAAI,KAAK,EAAA,GAAM,IAAA,CAAK,WAAA,GAC/C,KAAK,EAAA,GAAK,KAEZ,CAAA,IACF;AAEJ;SAEA,mBAAoB,CAAA,EAAmB;IACrC,OAAQ,IAAA,CAAK,WAAA,GAAA,CAAe,KAAK,IAAA,CAAK,IAAI,IAAI,CAAC,IAAI,KAAK,EAAA,GAAK,CAAA,IAAM,KAAK,EAAA;AAC1E;gBQ3GQ,IAAA,EAAY,IAAA,EAAwB;IAC1C,MAAM,SAAA,oCAAU,2PAAQ,mBAAK,qBAAL,IAAA,EAAqB,IAAI,CAAA,IAAK;IACtD,sPAAO,IAAA,EAAK,QAAO,CAAC,SAAS;AAC/B;SAKA,eAAgB,MAAA,EAAgB,IAAA,EAAqB;IACnD,wPAAI,EAAK,sBAAL,IAAA,EAAa,OAAO,IAAA,EAAM,IAAI,GAAG;QACnC,+OAAA,IAAA,EAAK,UAAQ,IAAA,CAAK,MAAM;IAC1B;AACF;SAEA,QAAS,IAAA,EAAgC;IACvC,sPAAO,IAAA,EAAK,UAAS,GAAA,qPAAI,uBAAK,yBAAL,IAAA,EAAyB,IAAI,CAAC;AACzD;SAEA,QAAS,IAAA,EAAY,IAAA,EAAc;IACjC,+OAAA,IAAA,EAAK,UAAS,GAAA,qPAAI,uBAAK,yBAAL,IAAA,EAAyB,IAAI,GAAG,IAAI;AACxD;SAEA,QAAS,IAAA,EAAY;IACnB,+OAAA,IAAA,EAAK,UAAS,GAAA,qPAAI,uBAAK,yBAAL,IAAA,EAAyB,IAAI,CAAC;AAClD;wBAEgB,IAAA,EAAoB;IAClC,MAAM,2PAAO,YAAK,cAAL,IAAA,EAAc,IAAI;IAC/B,IAAI,SAAS,KAAA,GAAW;QACtB,OAAO;IACT;IACA,2PAAO,cAAK,gBAAL,IAAA,EAAgB,IAAI;AAC7B;mBAEW,IAAA,EAAoB;IAC7B,IAAI,gPAAC,IAAA,EAAK,iBAAgB,gPAAC,IAAA,EAAK,UAAS;QACvC,MAAM,kBAAkB,MACtB,mPAAA,EAAK,UAAS,IAAA,CAAK;YACjB,4PAAQ,6BAAK,+BAAL,IAAA,EAA+B,IAAI;QAC7C,CAAC;QAEH,IAAI,oBAAoB,KAAA,GAAW;YACjC,gPAAA,IAAA,YAAK,cAAL,IAAA,EAAc,MAAM,eAAA,CAAgB,CAAC,CAAC;YACtC,OAAO,eAAA,CAAgB,CAAC,CAAA;QAC1B;IACF;IAEA,MAAM,eAAe,KAAK,aAAA,gPAAc,IAAA,EAAK,iBAAiB,EAAA;IAC9D,IAAA,mWAAA,EAAO,YAAY;IACnB,IAAI,OAAO;IACX,KAAA,MAAW,gBAAgB,aAAa,EAAG;QACzC;IACF;IAEA,gPAAA,IAAA,YAAK,cAAL,IAAA,EAAc,MAAM,IAAI;IACxB,OAAO;AACT;kCAE0B,IAAA,EAAkC;IAC1D,OAAO,OAIP,sPAHE,IAAA,EAAK,gBACD,KACA,KAAK,SAAA,qPAAU,iBAAK,mBAAL,IAAA,EAAmB,qPAAM,IAAA,EAAK,cAAc,CAAC,CAClE,GAAA;AACF;SAEA,mBAAoB,IAAA,EAA4B;IAC9C,OAAO,8PAAG,6BAAK,+BAAL,IAAA,EAA+B,IAAI,CAAC,EAE7C,OAFgD,KAAK,SAAA,qPACpD,iBAAK,mBAAL,IAAA,EAAmB,qPAAM,IAAA,EAAK,SAAO,SAAA,CAAU,EAAE,UAAU;AAE/D;SAEA,aAAc,IAAA,EAAY,GAAA,EAAqC;IAC7D,MAAM,SAA4B,CAAC,CAAA;IACnC,KAAA,MAAW,OAAO,IAAK;QACrB,OAAO,IAAA,CAAK,mBAAmB,KAAK,GAAA,CAAI,GAAG,CAAC,CAAC;IAC/C;IACA,OAAO;AACT;oBMhLY,MAAA,EAAsB;IAChC,OAAQ,OAAO,IAAA,EAAM;QACnB,KAAK;YACH,+OAAA,IAAA,EAAK,UAAQ,IAAA,CAAK;gBAChB,MAAM;gBACN,0PAAM,sBAAK,wBAAL,IAAA,EACJ,OAAO,IAAA,CAAK,GAAA,EACZ,OAAO,IAAA,CAAK,aAAA,EACZ;YAEJ,CAAC;YACD;QACF,KAAK;YACH,+OAAA,IAAA,EAAK,UAAQ,IAAA,CAAK;gBAChB,MAAM;gBACN,0PAAM,sBAAK,wBAAL,IAAA,EACJ,OAAO,IAAA,CAAK,GAAA,EACZ,OAAO,IAAA,CAAK,aAAA,EACZ;YAEJ,CAAC;YACD;QACF,KAAK;YACH,+OAAA,IAAA,EAAK,UAAQ,IAAA,CAAK;gBAChB,MAAM;gBACN,0PAAM,sBAAK,wBAAL,IAAA,EACJ,OAAO,IAAA,CAAK,GAAA,EACZ,OAAO,IAAA,CAAK,aAAA,EACZ;gBAEF,OAAO,OAAO,KAAA;YAChB,CAAC;YACD;QACF,KAAK;YAAQ;gBAEX,IAAA,mWAAA,EACE,wBACE,OAAO,OAAA,CAAQ,GAAA,EACf,OAAO,IAAA,CAAK,GAAA,iPACZ,IAAA,EAAK,cAEP;gBAEF,+OAAA,IAAA,EAAK,UAAQ,IAAA,CAAK;oBAChB,MAAM;oBACN,6PAAS,EAAK,4CAAL,IAAA,EACP,OAAO,OAAA,CAAQ,GAAA,EACf,OAAO,OAAA,CAAQ,aAAA,EACf;oBAEF,0PAAM,sBAAK,wBAAL,IAAA,EACJ,OAAO,IAAA,CAAK,GAAA,EACZ,OAAO,IAAA,CAAK,aAAA,EACZ;gBAEJ,CAAC;gBACD;YACF;QACA;YACE,IAAA,wWAAA,EAAY,MAAM;IACtB;AACF;mBAEW,MAAA,EAAsB;IAC/B,MAAM,kBAAkB,CAAC,UAAegD,YAAmB;6PACpD,wBAAyB;YAC5B,QAAAA;YACA,UAAU,KAAA;QACZ;QACA,IAAI;YACF,MAAM,cAAc,mPAAA,EAAK,SAAQ,KAAA,CAAM;gBACrC,YAAY,OAAO,WAAA,gPACjB,IAAA,EAAK,YAAW,GAAA,CAAI,CAAC,KAAK,IAAM;wBAAC;wBAAK,QAAA,CAAS,mPAAA,EAAK,UAAA,CAAU,CAAC,CAAC,CAAC;qBAAC;YAEtE,CAAC;YAED,KAAA,MAAW,cAAc,YAAa;gBACpC,+OAAA,IAAA,EAAK,wBAAuB,QAAA,GAAW,WAAW,GAAA;gBAClD,MAAM,cAA2B;oBAC/B,MAAM;oBACN,MAAM,oPAAA,sBAAK,4BAAL,EACJ,WAAW,GAAA,EACX,WAAW,aAAA,EACX;oBAEF,OAAO;wBACL,gBAAA,iPAAkB,IAAA,EAAK;wBACvB,QAAAA;oBACF;gBACF;gBACA,+OAAA,IAAA,EAAK,UAAQ,IAAA,CAAK,WAAW;YAC/B;QACF,SAAE;iQACK,wBAAyB,KAAA;QAChC;IACF;IAEA,OAAQ,OAAO,IAAA,EAAM;QACnB,KAAK;QACL,KAAK;YACH,gBAAgB,OAAO,IAAA,CAAK,GAAA,EAAK,MAAM;YACvC;QACF,KAAK;YACH,gBAAgB,OAAO,IAAA,CAAK,GAAA,EAAK,MAAM;YACvC;QACF,KAAK;YAAQ;gBACX,MAAM,WAAW,OAAO,IAAA,CAAK,GAAA;gBAC7B,MAAM,cAAc,OAAO,OAAA,CAAQ,GAAA;gBAEnC,IAAA,mWAAA,EACE,wBAAwB,aAAa,yPAAU,IAAA,EAAK,SAAS,IAC7D;gBAEF,gBAAgB,UAAU,MAAM;gBAChC;YACF;QAEA;YACE,IAAA,wWAAA,EAAY,MAAM;IACtB;AACF;UAEA,+BACE,MAAA,EACA,OAAA,EACc;IACd,IAAI,UAAU;IACd,IAAI,iBAAiB;IACrB,IAAI,iBAAiB;IACrB,KAAA,MAAW,SAAS,OAAQ;QAC1B,IAAI,aAAa;QACjB,IAAI,CAAC,SAAS;YACZ,OAAQ,QAAQ,IAAA,EAAM;gBACpB,KAAK;oBAAO;wBACV,mPACE,IAAA,EAAK,QACF,SAAA,CAAU,EACV,WAAA,CAAY,QAAQ,IAAA,CAAK,GAAA,EAAK,MAAM,GAAG,MAAM,GAChD;4BACA,UAAU;4BACV,aAAa;wBACf;wBACA;oBACF;gBACA,KAAK;oBAAU;wBACb,IACE,mPAAA,EAAK,QAAO,SAAA,CAAU,EAAE,WAAA,CAAY,QAAQ,IAAA,CAAK,GAAA,EAAK,MAAM,GAAG,IAC/D,GACA;4BACA,UAAU;4BACV,MAAM,QAAQ,IAAA;wBAChB;wBACA;oBACF;gBACA,KAAK;oBAAQ;wBACX,mPACE,IAAA,EAAK,QACF,SAAA,CAAU,EACV,WAAA,CAAY,QAAQ,OAAA,CAAQ,GAAA,EAAK,MAAM,GAAG,IAAI,GACjD;4BACA,iBAAiB;4BACjB,IAAI,gBAAgB;gCAClB,UAAU;4BACZ;4BACA,MAAM,QAAQ,OAAA;wBAChB;wBACA,mPACE,IAAA,EAAK,QACF,SAAA,CAAU,EACV,WAAA,CAAY,QAAQ,IAAA,CAAK,GAAA,EAAK,MAAM,GAAG,MAAM,GAChD;4BACA,iBAAiB;4BACjB,IAAI,gBAAgB;gCAClB,UAAU;4BACZ;4BACA,aAAa;wBACf;wBACA;oBACF;gBACA,KAAK;oBAAS;wBACZ,mPACE,IAAA,EAAK,QACF,SAAA,CAAU,EACV,WAAA,CAAY,QAAQ,IAAA,CAAK,GAAA,EAAK,MAAM,GAAG,MAAM,GAChD;4BACA,UAAU;4BACV,MAAM;gCACJ,KAAK,MAAM,GAAA;gCACX,eAAe;oCACb,GAAG,MAAM,aAAA;oCACT,CAAC,QAAQ,KAAA,CAAM,gBAAgB,CAAA,EAAG,wPAChC,mCAAK,qCAAL,IAAA,EACE,MAAM,aAAA,CAAc,QAAQ,KAAA,CAAM,gBAAgB,CAAA,CAAE,GACpD,QAAQ,KAAA,CAAM,MAAA;gCAEpB;4BACF;4BACA,aAAa;wBACf;wBACA;oBACF;YACF;QACF;QACA,IAAI,YAAY;YACd,MAAM;QACR;IACF;IACA,IAAI,CAAC,SAAS;QACZ,IAAI,QAAQ,IAAA,KAAS,UAAU;YAC7B,UAAU;YACV,MAAM,QAAQ,IAAA;QAChB,OAAA,IAAW,QAAQ,IAAA,KAAS,QAAQ;YAClC,IAAA,mWAAA,EAAO,cAAc;YACrB,iBAAiB;YACjB,UAAU;YACV,MAAM,QAAQ,OAAA;QAChB;IACF;IAEA,IAAA,mWAAA,EAAO,OAAO;AAChB;2BAGE,aAAA,EACA,mBAAA,EACA,IAAA,EACM;IACN,IAAI,SAA4B;IAChC,IAAI,iBAAiB;IACrB,MAAM,cAAc,MAAM;QACxB,IAAI,CAAC,gBAAgB;YACnB,IAAI,SAAS,WAAW;gBACtB,+OAAA,IAAA,EAAK,WAAS,GAAA,CACZ,8PACE,IAAA,EAAK,4PACL,IAAA,EAAK,SAAQ,SAAA,CAAU,EAAE,UAAA,EACzB;gBAGJ,MAAM,QACJ;uBACK,oPACD,IAAA,EAAK,WAAS,IAAA,CAAK;wBACjB,QAAQ,qBAAqB,8PAAe,IAAA,EAAK,UAAU;oBAC7D,CAAC,GACD;iBAEJ,CAAE,MAAA,KAAW;gBACf,SAAS,QAAQ,YAAY;YAC/B;YAEA,iBAAiB;YAGjB,IAAI,SAAS,SAAS;gBACpB,+OAAA,IAAA,EAAK,WAAS,GAAA,CACZ,8PACE,IAAA,EAAK,4PACL,IAAA,EAAK,SAAQ,SAAA,CAAU,EAAE,UAAA,EACzB,gBAEF;YAEJ;QACF;QAEA,MAAM,wPAAS,IAAA,EAAK,OAAA,CAAO,MAAM,CAAA,CAAE;YACjC,YAAY,OAAO,WAAA,gPACjB,IAAA,EAAK,WAAU,GAAA,CAAI,CAAC,KAAK,IAAM;oBAC7B;oBACA,aAAA,gPAAc,IAAA,EAAK,WAAA,CAAW,CAAC,CAAC,CAAA;iBACjC;QAEL,CAAC;QAED,IACE,mPAAA,EAAK,+QACL,gBAAK,kBAAL,IAAA,EACE,8PACA,IAAA,EAAK,wBAAuB,MAAA,CAAO,IAAA,CAAK,GAAA,oPAE1C,IAAA,EAAK,wBAAuB,QAAA,mPAC5B,IAAA,EAAK,UAAQ,WAAA,CACX,eACA,mPAAA,EAAK,wBAAuB,QAAA,IAC1B,GACJ;YACA,2PAAO,mCAAK,qCAAL,IAAA,EACL,uPACA,IAAA,EAAK,wBAAuB,MAAA;QAEhC;QACA,OAAO;IACT;IAEA,OAAO;QACL,KAAK;QACL,eAAe;YACb,GAAG,mBAAA;YACH,gPAAC,IAAA,EAAK,iBAAiB,GAAA,EAAG;QAC5B;IACF;AACF;qBAEa,MAAA,EAAa,KAAA,EAAY;IACpC,IAAA,IAAS,IAAI,GAAG,mPAAI,IAAA,EAAK,YAAW,MAAA,EAAQ,IAAK;QAC/C,IAAI,CAAC,YAAY,MAAA,gPAAO,IAAA,EAAK,WAAA,CAAW,CAAC,CAAC,CAAA,EAAG,KAAA,gPAAM,IAAA,EAAK,UAAA,CAAU,CAAC,CAAC,CAAC,GAAG;YACtE,OAAO;QACT;IACF;IACA,OAAO;AACT;UC9YA,eAAiB,MAAA,EAA6B,GAAA,EAAmB;IAC/D,MAAM,4PAAQ,aAAK,eAAL,IAAA,EAAe,GAAG;IAChC,IAAI,UAAU,SAAS;QACrB;IACF;IACA,MAAM,uPAAQ,IAAA,EAAK,QAAA,CAAO,MAAM,CAAA,CAAE;QAAC,GAAG,GAAA;QAAK;IAAK,CAAC;IACjD,IAAI,CAAC,IAAI,OAAA,EAAS;QAChB,OAAO;QACP;IACF;IACA,KAAA,MAAW,QAAQ,MAAO;QACxB,IAAI,qPAAC,oBAAK,sBAAL,IAAA,EAAsB,KAAK,GAAG,GAAG;YACpC;QACF;QACA,MAAM;IACR;AACF;SAUA,gBAAiB,GAAA,EAAmB;IAClC,MAAME,0PAAM,EAAK,kBAAL,IAAA,iPAAiB,IAAA,EAAK,QAAO,GAAA,EAAK,GAAG;IACjD,OAAOA,OAAM,KAAMA,SAAQ,KAAK,gPAAC,IAAA,EAAK,QAAO,SAAA;AAC/C;kBAgBU,GAAA,EAAgD;IACxD,MAAM,aAAa;QACjB,oPAAK,IAAA,EAAK,QAAO,GAAA;QACjB,OAAO,mPAAA,EAAK,QAAO,SAAA,GAAY,UAAU;IAC3C;IAEA,IAAI,CAAC,IAAI,KAAA,EAAO;QACd,IAAI,IAAI,OAAA,EAAS;YACf,OAAO,KAAA;QACT;QACA,OAAO;IACT;IAEA,MAAMA,0PAAM,EAAK,kBAAL,IAAA,iPAAiB,IAAA,EAAK,QAAO,GAAA,EAAK,IAAI,KAAA,CAAM,GAAG;IAE3D,IAAI,CAAC,IAAI,OAAA,EAAS;QAIhB,IAAIA,OAAM,GAAG;YACX,OAAO;QACT;QAIA,IAAIA,SAAQ,GAAG;YACb,mPAAI,IAAA,EAAK,QAAO,SAAA,IAAa,IAAI,KAAA,CAAM,KAAA,KAAU,SAAS;gBACxD,OAAO;oBACL,oPAAK,IAAA,EAAK,QAAO,GAAA;oBACjB,OAAO;gBACT;YACF;YACA,OAAO;QACT;QAEA,OAAO,IAAI,KAAA;IACb;IAEA,IAAI,OAAA;IAIJ,IAAIA,OAAM,GAAG;QACX,OAAO;IACT;IAEA,IAAIA,SAAQ,GAAG;QAGb,IAAI,gPAAC,IAAA,EAAK,QAAO,SAAA,IAAa,IAAI,KAAA,CAAM,KAAA,KAAU,MAAM;YACtD,OAAO;QACT;QAGA,OAAO;IACT;IAGA,OAAO,IAAI,KAAA;AACb;uBCVe,GAAA,EAAiC;IAC9C,IAAA,mWAAA,EAAO,IAAI,KAAA,KAAU,KAAA,CAAS;IAC9B,IAAA,mWAAA,EAAO,CAAC,IAAI,OAAO;IACnB,IAAA,mWAAA,EAAO,8BAA8B,IAAI,UAAA,iPAAY,IAAA,EAAK,aAAa,CAAC;IAExE,mPAAI,IAAA,EAAK,YAAW,GAAG;QACrB;IACF;IAEA,MAAM,eAAe,+PAAgB,IAAA,EAAK,gBAAe,IAAI,UAAU;IACvE,IAAA,mWAAA,iPAAO,IAAA,EAAK,WAAS,GAAA,CAAI,YAAY,MAAM,KAAA,CAAS;IAEpD,IAAI,OAAO;IACX,IAAI;IACJ,IAAI,wBAAwB;IAC5B,IAAI,kBAAkB;IACtB,IAAI;QACF,KAAA,MAAW,4PAAa,IAAA,EAAK,SAAO,KAAA,CAAM,GAAG,EAAG;YAC9C,MAAM;YACN,QAAQ,UAAU,GAAA;YAClB;YACA,IAAI,wPAAS,IAAA,EAAK,SAAQ;gBACxB;YACF;QACF;QACA,wBAAwB;IAC1B,EAAA,OAAS,GAAG;QACV,kBAAkB;QAClB,MAAM;IACR,SAAE;QACA,IAAI,CAAC,iBAAiB;YACpB,gPAAA,IAAA,iBAAK,mBAAL,IAAA,EACE,cACA,MACA,sPACA,IAAA,EAAK,WAAS,GAAA,CAAI,aAAa;YAMjC,IAAA,mWAAA,EACE,CAAC,uBACD;QAEJ;IACF;AACF;+BAiBuB,GAAA,EAAU;IAC/B,MAAM,eAAe,+PAAgB,IAAA,EAAK,gBAAe,GAAG;IAC5D,MAAM,2PAAY,IAAA,EAAK,WAAS,GAAA,CAAI,YAAY;IAChD,IAAI;IACJ,IAAI;IACJ,IAAI,WAAW;QACb,0PAAW,IAAA,EAAK,WAAS,GAAA,CAAI,aAAa;QAC1C,4PACE,IAAA,EAAK,kBACL,OAAO,WAAA,gPACL,IAAA,EAAK,eAAc,GAAA,CAAI,CAAA,MAAO;gBAAC;gBAAK,GAAA,CAAI,GAAG,CAAC;aAAU;IAE5D;IAEA,OAAO;QAAC;QAAW;QAAc;QAAU;IAAU;AAavD;wBAsKgB,MAAA,EAA0B;IACxC,IAAA,mWAAA,EACE,gPAAC,IAAA,EAAK,+QACJ,EAAK,8BAAL,IAAA,EAA6B,OAAO,OAAA,CAAQ,GAAA,EAAK,OAAO,IAAA,CAAK,GAAG,MAAM,GACxE;IAGF,MAAM,EAAC,SAAA,EAAW,YAAA,EAAc,QAAA,EAAU,UAAA,CAAU,CAAA,mPAClD,IAAA,0BAAK,gCAAL,EAA4B,OAAO,OAAA,CAAQ,GAAG;IAChD,IAAI,CAAC,WAAW;QACd;IACF;IAEA,IAAA,mWAAA,EAAO,UAAU,KAAA,EAAO,qBAAqB;IAC7C,MAAM,EAAC,WAAA,CAAW,CAAA,GAAI,IAAA,CAAK,SAAA,CAAU;IACrC,MAAM,SAAS,YAAY,OAAO,OAAA,CAAQ,GAAA,EAAK,UAAU,KAAK;IAC9D,MAAM,SAAS,YAAY,OAAO,IAAA,CAAK,GAAA,EAAK,UAAU,KAAK;IAE3D,MAAM,+BAA+B,MAAM;QACzC,gPAAA,IAAA,iBAAK,mBAAL,IAAA,EACE,cACA,UAAU,IAAA,EACV,OAAO,IAAA,CAAK,GAAA,EACZ;QAEF,+OAAA,IAAA,EAAK,UAAQ,IAAA,CAAK,MAAM;IAC1B;IAGA,IAAI,WAAW,GAAG;QAEhB,IAAI,WAAW,GAAG;YAEhB,+OAAA,IAAA,EAAK,UAAQ,IAAA,CAAK,MAAM;YACxB;QACF;QAEA,IAAI,SAAS,GAAG;YACd,mPAAI,IAAA,EAAK,YAAW,GAAG;gBACrB,6BAA6B;gBAC7B;YACF;YAMA,MAAM,kBAAkB,KACtB,qPACE,IAAA,EAAK,SAAO,KAAA,CAAM;gBAChB,OAAO;oBACL,KAAK,UAAU,KAAA;oBACf,OAAO;gBACT;gBACA;gBACA,SAAS;YACX,CAAC;YAIL,gPAAA,IAAA,EAAK,kCAAL,IAAA,EACE,cACA,UAAU,IAAA,EACV,gBAAgB,GAAA,EAChB;YAEF,+OAAA,IAAA,EAAK,UAAQ,IAAA,CAAK,MAAM;YACxB;QACF;QAEA,IAAA,mWAAA,EAAO,SAAS,CAAC;QAEjB,MAAM,eAAe,KACnB,qPACE,IAAA,EAAK,SAAO,KAAA,CAAM;YAChB,OAAO;gBACL,KAAK,UAAU,KAAA;gBACf,OAAO;YACT;YACA;QACF,CAAC;QAML,IAAI,YAAY,aAAa,GAAA,EAAK,OAAO,IAAA,CAAK,GAAG,MAAM,GAAG;YACxD,6BAA6B;YAC7B;QACF;QAIA,gPAAA,IAAA,iBAAK,mBAAL,IAAA,EACE,cACA,UAAU,IAAA,EACV,aAAa,GAAA,EACb;QAEF,gPAAA,IAAA,2BAAK,6BAAL,IAAA,EAA6B,aAAa,GAAA,EAAK,MAAM;YACnD,+OAAA,IAAA,EAAK,UAAQ,IAAA,CAAK;gBAChB,MAAM;gBACN,MAAM,OAAO,OAAA;YACf,CAAC;QACH,CAAC;QACD,+OAAA,IAAA,EAAK,UAAQ,IAAA,CAAK;YAChB,MAAM;YACN,MAAM;QACR,CAAC;QACD;IACF;IAEA,IAAI,SAAS,GAAG;QACd,IAAA,mWAAA,EAAO,WAAW,GAAG,8CAA8C;QAGnE,IAAI,SAAS,GAAG;YACd;QACF;QAGA,IAAA,mWAAA,EAAO,SAAS,CAAC;QAEjB,MAAM,CAAC,cAAc,YAAY,CAAA,GAAI,oPACnC,IAAA,EAAK,SAAO,KAAA,CAAM;YAChB,OAAO;gBACL,KAAK,UAAU,KAAA;gBACf,OAAO;YACT;YACA;YACA,SAAS;QACX,CAAC,GACD;QAIF,gPAAA,IAAA,iBAAK,mBAAL,IAAA,EACE,cACA,UAAU,IAAA,EACV,aAAa,GAAA,EACb;QAEF,gPAAA,IAAA,2BAAK,6BAAL,IAAA,EAA6B,OAAO,IAAA,CAAK,GAAA,EAAK,MAAM;YAClD,+OAAA,IAAA,EAAK,UAAQ,IAAA,CAAK;gBAChB,MAAM;gBACN,MAAM;YACR,CAAC;QACH,CAAC;QACD,+OAAA,IAAA,EAAK,UAAQ,IAAA,CAAK;YAChB,MAAM;YACN,MAAM,OAAO,IAAA;QACf,CAAC;QAED;IACF;IAEA,IAAI,SAAS,GAAG;QACd,IAAA,mWAAA,EAAO,WAAW,GAAG,8CAA8C;QAGnE,IAAI,SAAS,GAAG;YACd,+OAAA,IAAA,EAAK,UAAQ,IAAA,CAAK,MAAM;YACxB;QACF;QAIA,IAAA,mWAAA,EAAO,SAAS,CAAC;QAIjB,MAAM,iBAAiB,KACrB,qPACE,IAAA,EAAK,SAAO,KAAA,CAAM;YAChB,OAAO;gBACL,KAAK,UAAU,KAAA;gBACf,OAAO;YACT;YACA;QACF,CAAC;QAKL,IAAI,YAAY,eAAe,GAAA,EAAK,OAAO,IAAA,CAAK,GAAG,MAAM,GAAG;YAC1D,6BAA6B;YAC7B;QACF;QAEA,+OAAA,IAAA,EAAK,UAAQ,IAAA,CAAK;YAChB,MAAM;YACN,MAAM,OAAO,OAAA;QACf,CAAC;QACD,gPAAA,IAAA,iBAAK,mBAAL,IAAA,EACE,cACA,UAAU,IAAA,EACV,eAAe,GAAA,EACf;QAEF,+OAAA,IAAA,EAAK,UAAQ,IAAA,CAAK;YAChB,MAAM;YACN,MAAM;QACR,CAAC;QACD;IACF;IAEA,IAAA,wWAAA,CAAY;AACd;SAEA,uBAAwB,GAAA,EAAU,EAAA,EAAgB;yPAC3C,qBAAsB;IAC3B,IAAI;QACF,GAAG;IACL,SAAE;6PACK,qBAAsB,KAAA;IAC7B;AACF;AAEA,sBACE,YAAA,EACA,IAAA,EACA,KAAA,EACA,QAAA,EACA;IACA,+OAAA,IAAA,EAAK,WAAS,GAAA,CAAI,cAAc;QAC9B;QACA;IACF,CAAC;IACD,IACE,UAAU,KAAA,KAAA,CACT,aAAa,KAAA,KACZ,IAAA,CAAK,SAAA,CAAU,EAAE,WAAA,CAAY,OAAO,QAAQ,IAAI,CAAA,GAClD;QACA,+OAAA,IAAA,EAAK,WAAS,GAAA,CAAI,eAAe,KAAK;IACxC;AACF;SMhjBA,iBAAiB;IACf,KAAA,MAAW,2PAAY,IAAA,EAAK,YAAY;QACtC,gPAAA,IAAA,iBAAK,mBAAL,IAAA,EAAmB,QAAQ;IAC7B;AACF;SAEA,aAAc,QAAA,EAAuB;IACnC,SACE,IAAA,CAAK,IAAA,iPACL,IAAA,EAAK,aAAY,aAAa;AAElC;SAMA,WAAW;yPACJ,QAAS;IACd,KAAA,MAAW,uPAAQ,IAAA,EAAK,SAAO,KAAA,CAAM,CAAC,CAAC,EAAG;QACxC,2PACE,IAAA,EAAK,QACL;YAAC,MAAM;YAAO;QAAI,kPAClB,IAAA,EAAK,WACL,mPACA,IAAA,EAAK;IAET;IACA,IAAA,CAAK,KAAA,CAAM;AACb","debugId":null}}]
}